{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Eclipse Dirigible \u2122 Samples This section collects various applications created to demonstrate the main use purposes and strengths of the cloud toolkit. They are built on scenarios with different complexity level, from exemplary samples targeting demonstration of single features to complete end-to-end applications. Simple Samples Decode a String from Base64 - how to decode a string from Base64 encoded input Encode a String to Base64 - how to encode a string with Base64 Console Log Levels - show how to use the built-in console object to print information in the standard output Database Dynamic Datasource - how to use dynamic datasources Database Statement - getting started with the low level Database API Database Procedure Call - call SQL Procedure through the low level Database API Database Procedure - Create & Execute - create & execute SQL Procedure through the Database Procedure API Database Query - using the simplified Query Database API Encrypt a Text with SHA512 - how to use SHA512 to encrypt an input byte array Decode a String from Hexadecimal Format - decoding string from HEX Encode a String to Hexadecimal Format - encoding a string to HEX HTTP Request - basic usage of the HTTP Request API Convert a String from JSON to XML - JSON to XML transformation Convert a String from XML to JSON - XML to JSON Mail Client - how to send mails using the Mail Client API Print Configuration Variables - prints configuration variables Print Environment Variables - prints environment variables Repository Manager - working with the Repository Manager API REST Call with Binary Response - how to retrieve the binary content from the response REST Calls - how to execute REST calls (GET, POST, PUT, DELETE) using the HTTP Client API REST Service - getting started with the REST framework Decoding of a URL - decoding of an encoded URL Encoding of a URL - encoding an URL Generate a Random UUID - generate a random UUID SOAP Client - building a client for calling a SOAP service SOAP Server - building a server side SOAP service FTP Client - getting started with the FTP Client Platform Lifecycle - getting started with the Platform Lifecycle API Liquibase - how to make use of the Liquibase's *.changelog descriptors Complex Samples Scheduled Job - create a Job definition, which triggers a JavaScript handler service Message Listener - create a Listener definition, which listens for events coming from a message queue and execute a JavaScript handler service BPMN Process - create a BPMN Process definition, with a simple Service step, which triggers a JavaScript handler service Bookstore Application - create a full-stack application for Books management - database, persistence, web service and user interface. Embedded Dirigible - embed Dirigible into an arbitrary Java application with specific requirements for the architecture, infrastructure and lifecycle management e.g. SpringBoot, Jakarta EE, etc. RBAC for CMS - how to enable the Role Based Access Management for the Content Management System Master Repository - how to run an application from a Zip file Shell Command - how to execute and arbitrary shell command File Upload - how to upload a file from HTML frontend and process the content at the backend Kafka Producer and Consumer - usage of Kafka client Tutorials Zeus on Kubernetes - installation and configuration of a Kubernetes Minikube cluster and Zeus deployment. Build a Custom Stack - how to combine Dirigible modules with pure Java based ones and how to fine-tune the distribution for production. Generate Application from Model - this tutorial will guide you through the creation of an entity data model and generation of a full-stack Dirigible application, from this model. Contributing to IDE Modules - this tutorial will guide you through the adding of changes in the IDE projects.","title":"Samples"},{"location":"#eclipse-dirigible-samples","text":"This section collects various applications created to demonstrate the main use purposes and strengths of the cloud toolkit. They are built on scenarios with different complexity level, from exemplary samples targeting demonstration of single features to complete end-to-end applications.","title":"Eclipse Dirigible&trade; Samples"},{"location":"#simple-samples","text":"Decode a String from Base64 - how to decode a string from Base64 encoded input Encode a String to Base64 - how to encode a string with Base64 Console Log Levels - show how to use the built-in console object to print information in the standard output Database Dynamic Datasource - how to use dynamic datasources Database Statement - getting started with the low level Database API Database Procedure Call - call SQL Procedure through the low level Database API Database Procedure - Create & Execute - create & execute SQL Procedure through the Database Procedure API Database Query - using the simplified Query Database API Encrypt a Text with SHA512 - how to use SHA512 to encrypt an input byte array Decode a String from Hexadecimal Format - decoding string from HEX Encode a String to Hexadecimal Format - encoding a string to HEX HTTP Request - basic usage of the HTTP Request API Convert a String from JSON to XML - JSON to XML transformation Convert a String from XML to JSON - XML to JSON Mail Client - how to send mails using the Mail Client API Print Configuration Variables - prints configuration variables Print Environment Variables - prints environment variables Repository Manager - working with the Repository Manager API REST Call with Binary Response - how to retrieve the binary content from the response REST Calls - how to execute REST calls (GET, POST, PUT, DELETE) using the HTTP Client API REST Service - getting started with the REST framework Decoding of a URL - decoding of an encoded URL Encoding of a URL - encoding an URL Generate a Random UUID - generate a random UUID SOAP Client - building a client for calling a SOAP service SOAP Server - building a server side SOAP service FTP Client - getting started with the FTP Client Platform Lifecycle - getting started with the Platform Lifecycle API Liquibase - how to make use of the Liquibase's *.changelog descriptors","title":"Simple Samples"},{"location":"#complex-samples","text":"Scheduled Job - create a Job definition, which triggers a JavaScript handler service Message Listener - create a Listener definition, which listens for events coming from a message queue and execute a JavaScript handler service BPMN Process - create a BPMN Process definition, with a simple Service step, which triggers a JavaScript handler service Bookstore Application - create a full-stack application for Books management - database, persistence, web service and user interface. Embedded Dirigible - embed Dirigible into an arbitrary Java application with specific requirements for the architecture, infrastructure and lifecycle management e.g. SpringBoot, Jakarta EE, etc. RBAC for CMS - how to enable the Role Based Access Management for the Content Management System Master Repository - how to run an application from a Zip file Shell Command - how to execute and arbitrary shell command File Upload - how to upload a file from HTML frontend and process the content at the backend Kafka Producer and Consumer - usage of Kafka client","title":"Complex Samples"},{"location":"#tutorials","text":"Zeus on Kubernetes - installation and configuration of a Kubernetes Minikube cluster and Zeus deployment. Build a Custom Stack - how to combine Dirigible modules with pure Java based ones and how to fine-tune the distribution for production. Generate Application from Model - this tutorial will guide you through the creation of an entity data model and generation of a full-stack Dirigible application, from this model. Contributing to IDE Modules - this tutorial will guide you through the adding of changes in the IDE projects.","title":"Tutorials"},{"location":"basic/base64-decode/","text":"Base64 - Decode Steps Create a project utils-base64 . Create a JavaScript service with the name base64-decode.js Enter the following content: var base64 = require ( \"utils/v4/base64\" ); var response = require ( \"http/v4/response\" ); var input = \"PT4/\" ; var result = base64 . decode ( input ); console . log ( \"decoded: \" + result ); response . println ( JSON . stringify ( \"decoded: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Base64 - Decode"},{"location":"basic/base64-decode/#base64-decode","text":"","title":"Base64 - Decode"},{"location":"basic/base64-decode/#steps","text":"Create a project utils-base64 . Create a JavaScript service with the name base64-decode.js Enter the following content: var base64 = require ( \"utils/v4/base64\" ); var response = require ( \"http/v4/response\" ); var input = \"PT4/\" ; var result = base64 . decode ( input ); console . log ( \"decoded: \" + result ); response . println ( JSON . stringify ( \"decoded: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/base64-encode/","text":"Base64 - Encode Steps Create a project utils-base64 . Create a JavaScript service with the name base64-encode.js . Enter the following content: var base64 = require ( \"utils/v4/base64\" ); var response = require ( \"http/v4/response\" ); var input = [ 61 , 62 , 63 ]; var result = base64 . encode ( input ); console . log ( \"encoded: \" + result ); response . println ( JSON . stringify ( \"encoded: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Base64 - Encode"},{"location":"basic/base64-encode/#base64-encode","text":"","title":"Base64 - Encode"},{"location":"basic/base64-encode/#steps","text":"Create a project utils-base64 . Create a JavaScript service with the name base64-encode.js . Enter the following content: var base64 = require ( \"utils/v4/base64\" ); var response = require ( \"http/v4/response\" ); var input = [ 61 , 62 , 63 ]; var result = base64 . encode ( input ); console . log ( \"encoded: \" + result ); response . println ( JSON . stringify ( \"encoded: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/console/","text":"Console Steps Create a project console . Then create a JavaScript service named console-test.js . Within the service code, enter the following content: console . info ( \"Info message: %s\" , \"Hello World!\" ); console . error ( \"Error message.\" ); console . warn ( \"Warning message.\" ); console . log ( \"Log message.\" ); console . trace ( \"Trace.\" ); For more information, see the API documentation.","title":"Console"},{"location":"basic/console/#console","text":"","title":"Console"},{"location":"basic/console/#steps","text":"Create a project console . Then create a JavaScript service named console-test.js . Within the service code, enter the following content: console . info ( \"Info message: %s\" , \"Hello World!\" ); console . error ( \"Error message.\" ); console . warn ( \"Warning message.\" ); console . log ( \"Log message.\" ); console . trace ( \"Trace.\" ); For more information, see the API documentation.","title":"Steps"},{"location":"basic/converting-json-xml/","text":"Converting JSON to XML Steps Create a project utils-xml . Create a JavaScript service with the name json-xml.js . Enter the following content: var xml = require ( \"utils/v4/xml\" ); var response = require ( \"http/v4/response\" ); var input = { a : { b : \"text_b\" , c : \"text_c\" , d : { e : \"text_e\" , }, }, }; var result = xml . fromJson ( input ); console . log ( \"XML: \" + result ); response . println ( JSON . stringify ( \"XML: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Converting JSON to XML"},{"location":"basic/converting-json-xml/#converting-json-to-xml","text":"","title":"Converting JSON to XML"},{"location":"basic/converting-json-xml/#steps","text":"Create a project utils-xml . Create a JavaScript service with the name json-xml.js . Enter the following content: var xml = require ( \"utils/v4/xml\" ); var response = require ( \"http/v4/response\" ); var input = { a : { b : \"text_b\" , c : \"text_c\" , d : { e : \"text_e\" , }, }, }; var result = xml . fromJson ( input ); console . log ( \"XML: \" + result ); response . println ( JSON . stringify ( \"XML: \" + result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/converting-xml-json/","text":"Converting XML to JSON Steps Create a project utils-xml . Create a JavaScript service with the name xml-json.js . Enter the following content: var xml2json = require ( \"utils/v4/xml\" ); var response = require ( \"http/v4/response\" ); var input = \"<a><b>text_b</b><c>text_c</c><d><e>text_e</e></d></a>\" ; var result = xml2json . toJson ( input ); var json = JSON . parse ( result ); console . log ( \"JSON: \" + JSON . stringify ( json )); response . println ( JSON . stringify ( json )); response . flush (); response . close (); For more information, see the API documentation.","title":"Converting XML to JSON"},{"location":"basic/converting-xml-json/#converting-xml-to-json","text":"","title":"Converting XML to JSON"},{"location":"basic/converting-xml-json/#steps","text":"Create a project utils-xml . Create a JavaScript service with the name xml-json.js . Enter the following content: var xml2json = require ( \"utils/v4/xml\" ); var response = require ( \"http/v4/response\" ); var input = \"<a><b>text_b</b><c>text_c</c><d><e>text_e</e></d></a>\" ; var result = xml2json . toJson ( input ); var json = JSON . parse ( result ); console . log ( \"JSON: \" + JSON . stringify ( json )); response . println ( JSON . stringify ( json )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/database-dynamic/","text":"Database - Dynamic Datasource Steps Create a project database . Then create a JavaScript service named database-dynamic.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var database = require ( \"db/v4/database\" ); database . createDataSource ( \"mydynamic\" , \"org.h2.Driver\" , \"jdbc:h2:~/mytest\" , \"sa\" , \"\" , null ); var connection = database . getConnection ( \"dynamic\" , \"mydynamic\" ); try { var statement = connection . prepareStatement ( \"select current_date from dual\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[date]: \" + resultSet . getString ( 1 )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); For more information, see the API documentation.","title":"Database - Dynamic Datasource"},{"location":"basic/database-dynamic/#database-dynamic-datasource","text":"","title":"Database - Dynamic Datasource"},{"location":"basic/database-dynamic/#steps","text":"Create a project database . Then create a JavaScript service named database-dynamic.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var database = require ( \"db/v4/database\" ); database . createDataSource ( \"mydynamic\" , \"org.h2.Driver\" , \"jdbc:h2:~/mytest\" , \"sa\" , \"\" , null ); var connection = database . getConnection ( \"dynamic\" , \"mydynamic\" ); try { var statement = connection . prepareStatement ( \"select current_date from dual\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[date]: \" + resultSet . getString ( 1 )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/database-procedure-call/","text":"Database - Procedure Call Steps Switch to the Database Perspective Execute the following SQL script: CREATE TABLE CUSTOMERS ( ID INTEGER PRIMARY KEY , NAME VARCHAR ( 50 ), COUNTRY VARCHAR ( 50 )); INSERT INTO CUSTOMERS VALUES ( 1 , 'Google' , 'USA' ); INSERT INTO CUSTOMERS VALUES ( 2 , 'SAP' , 'Germany' ); INSERT INTO CUSTOMERS VALUES ( 3 , 'DigitalLights' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 4 , 'Quanterall' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 5 , 'SyMetric' , 'India' ); Create CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS stored procedure: CREATE PROCEDURE CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS ( in country varchar ( 50 ), out customersByCountry CUSTOMERS , out allCustomers CUSTOMERS ) AS BEGIN customersByCountry = SELECT * FROM CUSTOMERS WHERE COUNTRY = : country ; allCustomers = SELECT * FROM CUSTOMERS ; END ; Create a project database-procedure . Then create a JavaScript service named database-procedure-call.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var database = require ( \"db/v4/database\" ); let connection = null ; try { connection = database . getConnection (); let hasMoreResults = false ; let sql = \"CALL CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS(COUNTRY => 'Bulgaria', customersByCountry => ?, allCustomers => ?)\" ; let callableStatement = connection . prepareCall ( sql ); let resultSet = callableStatement . executeQuery (); do { while ( resultSet . next ()) { response . println ( `Name: ${ resultSet . getString ( \"NAME\" ) } , Country: ${ resultSet . getString ( \"COUNTRY\" ) } ` ); } hasMoreResults = callableStatement . getMoreResults (); if ( hasMoreResults ) { resultSet . close (); resultSet = callableStatement . getResultSet (); response . println ( \"\\n---- End of ResultSet ----\\n\" ); } } while ( hasMoreResults ); callableStatement . close (); } finally { if ( connection != null ) { connection . close (); } } response . flush (); response . close (); For more information, see the API documentation.","title":"Database - Procedure Call"},{"location":"basic/database-procedure-call/#database-procedure-call","text":"","title":"Database - Procedure Call"},{"location":"basic/database-procedure-call/#steps","text":"Switch to the Database Perspective Execute the following SQL script: CREATE TABLE CUSTOMERS ( ID INTEGER PRIMARY KEY , NAME VARCHAR ( 50 ), COUNTRY VARCHAR ( 50 )); INSERT INTO CUSTOMERS VALUES ( 1 , 'Google' , 'USA' ); INSERT INTO CUSTOMERS VALUES ( 2 , 'SAP' , 'Germany' ); INSERT INTO CUSTOMERS VALUES ( 3 , 'DigitalLights' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 4 , 'Quanterall' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 5 , 'SyMetric' , 'India' ); Create CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS stored procedure: CREATE PROCEDURE CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS ( in country varchar ( 50 ), out customersByCountry CUSTOMERS , out allCustomers CUSTOMERS ) AS BEGIN customersByCountry = SELECT * FROM CUSTOMERS WHERE COUNTRY = : country ; allCustomers = SELECT * FROM CUSTOMERS ; END ; Create a project database-procedure . Then create a JavaScript service named database-procedure-call.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var database = require ( \"db/v4/database\" ); let connection = null ; try { connection = database . getConnection (); let hasMoreResults = false ; let sql = \"CALL CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS(COUNTRY => 'Bulgaria', customersByCountry => ?, allCustomers => ?)\" ; let callableStatement = connection . prepareCall ( sql ); let resultSet = callableStatement . executeQuery (); do { while ( resultSet . next ()) { response . println ( `Name: ${ resultSet . getString ( \"NAME\" ) } , Country: ${ resultSet . getString ( \"COUNTRY\" ) } ` ); } hasMoreResults = callableStatement . getMoreResults (); if ( hasMoreResults ) { resultSet . close (); resultSet = callableStatement . getResultSet (); response . println ( \"\\n---- End of ResultSet ----\\n\" ); } } while ( hasMoreResults ); callableStatement . close (); } finally { if ( connection != null ) { connection . close (); } } response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/database-procedure/","text":"Database Procedure - Create & Execute Steps Switch to the Database Perspective Execute the following SQL script: CREATE TABLE CUSTOMERS ( ID INTEGER PRIMARY KEY , NAME VARCHAR ( 50 ), COUNTRY VARCHAR ( 50 )); INSERT INTO CUSTOMERS VALUES ( 1 , 'Google' , 'USA' ); INSERT INTO CUSTOMERS VALUES ( 2 , 'SAP' , 'Germany' ); INSERT INTO CUSTOMERS VALUES ( 3 , 'DigitalLights' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 4 , 'Quanterall' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 5 , 'SyMetric' , 'India' ); Create a project database-procedure . Then create a JavaScript service named database-procedure-create.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var procedure = require ( \"db/v4/procedure\" ); let sql = \" \\ CREATE PROCEDURE CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS (in country varchar(50), out customersByCountry CUSTOMERS, out allCustomers CUSTOMERS) \\ AS \\ BEGIN \\ customersByCountry = SELECT * FROM CUSTOMERS WHERE COUNTRY = :country; \\ allCustomers = SELECT * FROM CUSTOMERS; \\ END; \\ \" ; procedure . create ( sql ); response . println ( \"Procedure created\" ); response . flush (); response . close (); Create a JavaScript service named database-procedure-execute.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var procedure = require ( \"db/v4/procedure\" ); let sql = \"CALL CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS(COUNTRY => ?, customersByCountry => ?, allCustomers => ?)\" ; let result = procedure . execute ( sql , [ \"Bulgaria\" ]); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Database Procedure - Create & Execute"},{"location":"basic/database-procedure/#database-procedure-create-execute","text":"","title":"Database Procedure - Create &amp; Execute"},{"location":"basic/database-procedure/#steps","text":"Switch to the Database Perspective Execute the following SQL script: CREATE TABLE CUSTOMERS ( ID INTEGER PRIMARY KEY , NAME VARCHAR ( 50 ), COUNTRY VARCHAR ( 50 )); INSERT INTO CUSTOMERS VALUES ( 1 , 'Google' , 'USA' ); INSERT INTO CUSTOMERS VALUES ( 2 , 'SAP' , 'Germany' ); INSERT INTO CUSTOMERS VALUES ( 3 , 'DigitalLights' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 4 , 'Quanterall' , 'Bulgaria' ); INSERT INTO CUSTOMERS VALUES ( 5 , 'SyMetric' , 'India' ); Create a project database-procedure . Then create a JavaScript service named database-procedure-create.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var procedure = require ( \"db/v4/procedure\" ); let sql = \" \\ CREATE PROCEDURE CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS (in country varchar(50), out customersByCountry CUSTOMERS, out allCustomers CUSTOMERS) \\ AS \\ BEGIN \\ customersByCountry = SELECT * FROM CUSTOMERS WHERE COUNTRY = :country; \\ allCustomers = SELECT * FROM CUSTOMERS; \\ END; \\ \" ; procedure . create ( sql ); response . println ( \"Procedure created\" ); response . flush (); response . close (); Create a JavaScript service named database-procedure-execute.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var procedure = require ( \"db/v4/procedure\" ); let sql = \"CALL CUSTOMERS_BY_COUNTRY_AND_ALL_CUSTOMERS(COUNTRY => ?, customersByCountry => ?, allCustomers => ?)\" ; let result = procedure . execute ( sql , [ \"Bulgaria\" ]); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/database-query/","text":"Database - Query Steps Create a project database . Then create a JavaScript service named database-query.js . Within the service code, enter the following content: var query = require ( \"db/v4/query\" ); var response = require ( \"http/v4/response\" ); var sql = \"SELECT * FROM DIRIGIBLE_EXTENSIONS WHERE EXTENSION_EXTENSIONPOINT_NAME = ?\" ; var resultset = query . execute ( sql , [ \"ide-view\" ]); response . setContentType ( \"application/json\" ); response . println ( JSON . stringify ( resultset , null , 2 )); response . flush (); response . close (); For more information, see the API documentation.","title":"Database - Query"},{"location":"basic/database-query/#database-query","text":"","title":"Database - Query"},{"location":"basic/database-query/#steps","text":"Create a project database . Then create a JavaScript service named database-query.js . Within the service code, enter the following content: var query = require ( \"db/v4/query\" ); var response = require ( \"http/v4/response\" ); var sql = \"SELECT * FROM DIRIGIBLE_EXTENSIONS WHERE EXTENSION_EXTENSIONPOINT_NAME = ?\" ; var resultset = query . execute ( sql , [ \"ide-view\" ]); response . setContentType ( \"application/json\" ); response . println ( JSON . stringify ( resultset , null , 2 )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/database-statement/","text":"Database - Statement Steps Create a project database . Then create a JavaScript service named database-basic.js . Within the service code, enter the following content: var database = require ( \"db/v4/database\" ); var response = require ( \"http/v4/response\" ); var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from DIRIGIBLE_EXTENSIONS where EXTENSION_EXTENSIONPOINT_NAME = ?\" ); var i = 0 ; statement . setString ( ++ i , \"ide-view\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[location]: \" + resultSet . getString ( \"EXTENSION_LOCATION\" ) ); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); For more information, see the API documentation.","title":"Database - Statement"},{"location":"basic/database-statement/#database-statement","text":"","title":"Database - Statement"},{"location":"basic/database-statement/#steps","text":"Create a project database . Then create a JavaScript service named database-basic.js . Within the service code, enter the following content: var database = require ( \"db/v4/database\" ); var response = require ( \"http/v4/response\" ); var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from DIRIGIBLE_EXTENSIONS where EXTENSION_EXTENSIONPOINT_NAME = ?\" ); var i = 0 ; statement . setString ( ++ i , \"ide-view\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[location]: \" + resultSet . getString ( \"EXTENSION_LOCATION\" ) ); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/digest/","text":"Encrypy - SHA-512 Steps Create a project digest . Create a JavaScript service with the name digest-sha512.js . Enter the following content: var digest = require ( \"utils/v4/digest\" ); var response = require ( \"http/v4/response\" ); var input = [ 61 , 62 , 63 ]; var result = digest . sha512 ( input ); console . log ( result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Encrypt - SHA-512"},{"location":"basic/digest/#encrypy-sha-512","text":"","title":"Encrypy - SHA-512"},{"location":"basic/digest/#steps","text":"Create a project digest . Create a JavaScript service with the name digest-sha512.js . Enter the following content: var digest = require ( \"utils/v4/digest\" ); var response = require ( \"http/v4/response\" ); var input = [ 61 , 62 , 63 ]; var result = digest . sha512 ( input ); console . log ( result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/documents-pdf/","text":"Generate PDF Steps Create a project generate-pdf . Create a JavaScript service with the name pdf-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var pdfDocuments = require ( \"documents/v4/pdf\" ); var data = { title : \"Lorem Ipsum\" , description : \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus lacinia fermentum magna, sit amet accumsan felis auctor ac.\" , columns : [ { name : \"Id\" , key : \"id\" , }, { name : \"First Name\" , key : \"firstName\" , }, { name : \"Last Name\" , key : \"lastName\" , }, { name : \"Age\" , key : \"age\" , }, ], rows : [ { id : 1001 , firstName : \"John\" , lastName : \"Doe\" , age : 29 , }, { id : 1002 , firstName : \"Jane\" , lastName : \"Doe\" , age : 26 , }, { id : 1003 , firstName : \"Joe\" , lastName : \"Doe\" , age : 44 , }, { id : 1004 , firstName : \"Jill\" , lastName : \"Doe\" , age : 40 , }, ], }; var pdf = pdfDocuments . generateTable ( data ); response . setContentType ( \"application/pdf\" ); response . setHeader ( \"Content-Disposition\" , 'filename=\"data.pdf\"' ); response . write ( pdf ); response . flush (); response . close (); Expected result: Create a project generate-pdf . Create a JavaScript service with the name pdf-service-advanced.js . Enter the following content: var response = require ( \"http/v4/response\" ); var pdfDocuments = require ( \"documents/v4/pdf\" ); var data = { title : \"Lorem Ipsum\" , description : \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\" , columns : [ { name : \"Id\" , key : \"id\" , }, { name : \"Name\" , key : \"name\" , }, { name : \"Position\" , key : \"position\" , }, ], rows : [], }; for ( let i = 0 ; i < 100 ; i ++ ) { data . rows . push ({ id : \"\" + i , name : \"John\" , position : \"Software Developer\" , highlight : i % 2 == 0 , breakAfter : ( i + 1 ) % 10 == 0 , }); } var config = { size : \"A3\" , alignColumns : \"center\" , alignRows : \"end\" , }; var pdf = pdfDocuments . generateTable ( data , config ); response . setContentType ( \"application/pdf\" ); response . setHeader ( \"Content-Disposition\" , 'filename=\"data.pdf\"' ); response . write ( pdf ); response . flush (); response . close (); Expected result: For more information, see the API documentation.","title":"Generate PDF"},{"location":"basic/documents-pdf/#generate-pdf","text":"","title":"Generate PDF"},{"location":"basic/documents-pdf/#steps","text":"Create a project generate-pdf . Create a JavaScript service with the name pdf-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var pdfDocuments = require ( \"documents/v4/pdf\" ); var data = { title : \"Lorem Ipsum\" , description : \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus lacinia fermentum magna, sit amet accumsan felis auctor ac.\" , columns : [ { name : \"Id\" , key : \"id\" , }, { name : \"First Name\" , key : \"firstName\" , }, { name : \"Last Name\" , key : \"lastName\" , }, { name : \"Age\" , key : \"age\" , }, ], rows : [ { id : 1001 , firstName : \"John\" , lastName : \"Doe\" , age : 29 , }, { id : 1002 , firstName : \"Jane\" , lastName : \"Doe\" , age : 26 , }, { id : 1003 , firstName : \"Joe\" , lastName : \"Doe\" , age : 44 , }, { id : 1004 , firstName : \"Jill\" , lastName : \"Doe\" , age : 40 , }, ], }; var pdf = pdfDocuments . generateTable ( data ); response . setContentType ( \"application/pdf\" ); response . setHeader ( \"Content-Disposition\" , 'filename=\"data.pdf\"' ); response . write ( pdf ); response . flush (); response . close (); Expected result: Create a project generate-pdf . Create a JavaScript service with the name pdf-service-advanced.js . Enter the following content: var response = require ( \"http/v4/response\" ); var pdfDocuments = require ( \"documents/v4/pdf\" ); var data = { title : \"Lorem Ipsum\" , description : \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\" , columns : [ { name : \"Id\" , key : \"id\" , }, { name : \"Name\" , key : \"name\" , }, { name : \"Position\" , key : \"position\" , }, ], rows : [], }; for ( let i = 0 ; i < 100 ; i ++ ) { data . rows . push ({ id : \"\" + i , name : \"John\" , position : \"Software Developer\" , highlight : i % 2 == 0 , breakAfter : ( i + 1 ) % 10 == 0 , }); } var config = { size : \"A3\" , alignColumns : \"center\" , alignRows : \"end\" , }; var pdf = pdfDocuments . generateTable ( data , config ); response . setContentType ( \"application/pdf\" ); response . setHeader ( \"Content-Disposition\" , 'filename=\"data.pdf\"' ); response . write ( pdf ); response . flush (); response . close (); Expected result: For more information, see the API documentation.","title":"Steps"},{"location":"basic/ftp-client/","text":"FTP Client Steps Create a project ftp-client . Then create a JavaScript service named ftp-client.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var ftp = require ( \"io/v4/ftp\" ); var host = \"test.rebex.net\" ; var port = 21 ; var userName = \"demo\" ; var password = \"password\" ; var ftpClient = ftp . getClient ( host , port , userName , password ); var file = ftpClient . getFileText ( \"/\" , \"readme.txt\" ); response . println ( file ); For more information, see the API documentation.","title":"FTP Client"},{"location":"basic/ftp-client/#ftp-client","text":"","title":"FTP Client"},{"location":"basic/ftp-client/#steps","text":"Create a project ftp-client . Then create a JavaScript service named ftp-client.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var ftp = require ( \"io/v4/ftp\" ); var host = \"test.rebex.net\" ; var port = 21 ; var userName = \"demo\" ; var password = \"password\" ; var ftpClient = ftp . getClient ( host , port , userName , password ); var file = ftpClient . getFileText ( \"/\" , \"readme.txt\" ); response . println ( file ); For more information, see the API documentation.","title":"Steps"},{"location":"basic/hex-decode/","text":"Hex - Decode Steps Create a project utils-hex . Create a JavaScript service with the name hex-decode.js . Enter the following content: var hex = require ( \"utils/v4/hex\" ); var response = require ( \"http/v4/response\" ); var input = \"414243\" ; var result = hex . decode ( input ); console . log ( \"decoded: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Hex - Decode"},{"location":"basic/hex-decode/#hex-decode","text":"","title":"Hex - Decode"},{"location":"basic/hex-decode/#steps","text":"Create a project utils-hex . Create a JavaScript service with the name hex-decode.js . Enter the following content: var hex = require ( \"utils/v4/hex\" ); var response = require ( \"http/v4/response\" ); var input = \"414243\" ; var result = hex . decode ( input ); console . log ( \"decoded: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/hex-encode/","text":"Hex - Encode Steps Create a project utils-hex . Create a JavaScript service with the name hex-encode.js . Enter the following content: var hex = require ( \"utils/v4/hex\" ); var response = require ( \"http/v4/response\" ); var input = [ 65 , 66 , 67 ]; var result = hex . encode ( input ); console . log ( \"encoded: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Hex - Encode"},{"location":"basic/hex-encode/#hex-encode","text":"","title":"Hex - Encode"},{"location":"basic/hex-encode/#steps","text":"Create a project utils-hex . Create a JavaScript service with the name hex-encode.js . Enter the following content: var hex = require ( \"utils/v4/hex\" ); var response = require ( \"http/v4/response\" ); var input = [ 65 , 66 , 67 ]; var result = hex . encode ( input ); console . log ( \"encoded: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/http-client-binary/","text":"HTTP Client - Binary Response Steps Create a project rest-call-binary . Then create a JavaScript service named get-call-binary.js . Within the service code, enter the following content: var client = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = client . get ( \"https://raw.githubusercontent.com/eclipse/dirigible/master/NOTICE.txt\" , { binary : true , } ); response . println ( httpResponse . statusMessage ); response . println ( JSON . stringify ( httpResponse . data )); response . flush (); response . close (); For more information, see the API documentation.","title":"HTTP Client - Binary Response"},{"location":"basic/http-client-binary/#http-client-binary-response","text":"","title":"HTTP Client - Binary Response"},{"location":"basic/http-client-binary/#steps","text":"Create a project rest-call-binary . Then create a JavaScript service named get-call-binary.js . Within the service code, enter the following content: var client = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = client . get ( \"https://raw.githubusercontent.com/eclipse/dirigible/master/NOTICE.txt\" , { binary : true , } ); response . println ( httpResponse . statusMessage ); response . println ( JSON . stringify ( httpResponse . data )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/http-client-calls/","text":"HTTP Client - Calls Steps Create a project rest-calls . Then create a JavaScript service named get-call.js . Within the service code, enter the following content: GET Call var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = httpClient . get ( \"https://services.odata.org/V4/Northwind/Northwind.svc/\" ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named post-call.js . Within the service code, enter the following content: POST Call var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var bodyContent = JSON . stringify ({ firstName : \"John\" , lastName : \"Doe\" , age : 24 , }); var httpResponse = httpClient . post ( \"http://httpbin.org/post\" , { text : bodyContent , }); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named put-call.js . Within the service code, enter the following content: PUT Call var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var bodyContent = JSON . stringify ({ firstName : \"John\" , lastName : \"Doe\" , age : 24 , }); var httpResponse = httpClient . put ( \"http://httpbin.org/put\" , { text : bodyContent , }); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named delete-call.js . Within the service code, enter the following content: DELETE Call var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = httpClient . delete ( \"http://httpbin.org/delete\" ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); For more information, see the API documentation.","title":"HTTP Client - Calls"},{"location":"basic/http-client-calls/#http-client-calls","text":"","title":"HTTP Client - Calls"},{"location":"basic/http-client-calls/#steps","text":"Create a project rest-calls . Then create a JavaScript service named get-call.js . Within the service code, enter the following content:","title":"Steps"},{"location":"basic/http-client-calls/#get-call","text":"var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = httpClient . get ( \"https://services.odata.org/V4/Northwind/Northwind.svc/\" ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named post-call.js . Within the service code, enter the following content:","title":"GET Call"},{"location":"basic/http-client-calls/#post-call","text":"var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var bodyContent = JSON . stringify ({ firstName : \"John\" , lastName : \"Doe\" , age : 24 , }); var httpResponse = httpClient . post ( \"http://httpbin.org/post\" , { text : bodyContent , }); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named put-call.js . Within the service code, enter the following content:","title":"POST Call"},{"location":"basic/http-client-calls/#put-call","text":"var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var bodyContent = JSON . stringify ({ firstName : \"John\" , lastName : \"Doe\" , age : 24 , }); var httpResponse = httpClient . put ( \"http://httpbin.org/put\" , { text : bodyContent , }); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); Then create a JavaScript service named delete-call.js . Within the service code, enter the following content:","title":"PUT Call"},{"location":"basic/http-client-calls/#delete-call","text":"var httpClient = require ( \"http/v4/client\" ); var response = require ( \"http/v4/response\" ); var httpResponse = httpClient . delete ( \"http://httpbin.org/delete\" ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . text ); response . flush (); response . close (); For more information, see the API documentation.","title":"DELETE Call"},{"location":"basic/http-request/","text":"HTTP - Request Steps Create a project http-service . Then create a JavaScript service named http-service.js . Within the service code, enter the following content: Simple HTTP Service var request = require ( \"http/v4/request\" ); var response = require ( \"http/v4/response\" ); var method = request . getMethod (); response . println ( \"[Method]: \" + method ); response . flush (); response . close (); For more information, see the API documentation.","title":"HTTP - Request"},{"location":"basic/http-request/#http-request","text":"","title":"HTTP - Request"},{"location":"basic/http-request/#steps","text":"Create a project http-service . Then create a JavaScript service named http-service.js . Within the service code, enter the following content:","title":"Steps"},{"location":"basic/http-request/#simple-http-service","text":"var request = require ( \"http/v4/request\" ); var response = require ( \"http/v4/response\" ); var method = request . getMethod (); response . println ( \"[Method]: \" + method ); response . flush (); response . close (); For more information, see the API documentation.","title":"Simple HTTP Service"},{"location":"basic/liquibase-simple/","text":"Liquibase Liquibase is a tool for tracking, managing and applying database schema changes. Liquibase supports JSON, YAML, XML, SQL and etc. formats. More information about Liquibase can be found here Dirigible Dirigible are fully integrated with Liquibase. By changesets included in .changelog you can create, delete, update, insert tables and columns. You can even create rollback tags and rolback changes to desired point. Below you can see example for working with liquibase in Dirigible. Lets create a project and execute some .changelog file in our project. Jump to Workbench perspective. Here you need to create file with .changelog extension. { \"databaseChangeLog\" : [ { \"preConditions\" : [ { \"runningAs\" : { \"username\" : \"SA\" } } ] }, { \"changeSet\" : { \"id\" : \"1\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"createTable\" : { \"tableName\" : \"person\" , \"columns\" : [ { \"column\" : { \"name\" : \"id\" , \"type\" : \"int\" , \"autoIncrement\" : true , \"constraints\" : { \"primaryKey\" : true , \"nullable\" : false } } }, { \"column\" : { \"name\" : \"firstname\" , \"type\" : \"varchar(50)\" } }, { \"column\" : { \"name\" : \"lastname\" , \"type\" : \"varchar(50)\" , \"constraints\" : { \"nullable\" : false } } }, { \"column\" : { \"name\" : \"state\" , \"type\" : \"char(2)\" } } ] } } ] } }, { \"changeSet\" : { \"id\" : \"2\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"addColumn\" : { \"tableName\" : \"person\" , \"columns\" : [ { \"column\" : { \"name\" : \"username\" , \"type\" : \"varchar(8)\" } } ] } } ] } }, { \"changeSet\" : { \"id\" : \"3\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"addLookupTable\" : { \"existingTableName\" : \"person\" , \"existingColumnName\" : \"state\" , \"newTableName\" : \"state\" , \"newColumnName\" : \"id\" , \"newColumnDataType\" : \"char(2)\" } } ] } }, { \"changeSet\" : { \"id\" : \"5\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"createTable\" : { \"tableName\" : \"table_users\" , \"columns\" : [ { \"column\" : { \"name\" : \"id\" , \"type\" : \"int\" , \"autoIncrement\" : true , \"constraints\" : { \"primaryKey\" : true , \"nullable\" : false } } }, { \"column\" : { \"name\" : \"first_name\" , \"type\" : \"varchar(10)\" } }, { \"column\" : { \"name\" : \"last_name\" , \"type\" : \"varchar(50)\" , \"constraints\" : { \"nullable\" : false } } }, { \"column\" : { \"name\" : \"age\" , \"type\" : \"int\" } }, { \"column\" : { \"name\" : \"last_updated\" , \"type\" : \"timestamp\" } } ] } } ] } } ] } On saving the file Dirigible automatically detects and executes the .changelog file. Switching to DB perspective we can see that in our PUBLIC schema, are created three tables, as described in our changelog file: - Persons , - State - Table_Users and two more related to .changelog execution : - DATABASECHANGELOGLOCK DATABASECHANGELOG , by choosing see content of this table in Result View are changesets represented as entries: In SQL View we can execute several queries to check if everything works properly. INSERT INTO STATE VALUES ( 'RU' ); INSERT INTO STATE VALUES ( 'CH' ); INSERT INTO STATE VALUES ( 'FR' ); INSERT INTO PERSON VALUES ( 1 , 'IVAN' , 'PETROV' , 'RU' , 'ipetr88' ); INSERT INTO PERSON VALUES ( 2 , 'MAURICE' , 'LACROIX' , 'CH' , 'moris' ); INSERT INTO PERSON VALUES ( 3 , 'JEAN' , 'DE GAULLE' , 'FR' , 'jdg66' ); Note Scripts are executed by pressing: Windows : Ctrl + X Mac: Cmd + X Table data can de seen by choosing Show Content on table. Results are shown in the Result View .","title":"Liquibase"},{"location":"basic/liquibase-simple/#liquibase","text":"","title":"Liquibase"},{"location":"basic/liquibase-simple/#_1","text":"Liquibase is a tool for tracking, managing and applying database schema changes. Liquibase supports JSON, YAML, XML, SQL and etc. formats. More information about Liquibase can be found here","title":""},{"location":"basic/liquibase-simple/#dirigible","text":"Dirigible are fully integrated with Liquibase. By changesets included in .changelog you can create, delete, update, insert tables and columns. You can even create rollback tags and rolback changes to desired point. Below you can see example for working with liquibase in Dirigible. Lets create a project and execute some .changelog file in our project. Jump to Workbench perspective. Here you need to create file with .changelog extension. { \"databaseChangeLog\" : [ { \"preConditions\" : [ { \"runningAs\" : { \"username\" : \"SA\" } } ] }, { \"changeSet\" : { \"id\" : \"1\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"createTable\" : { \"tableName\" : \"person\" , \"columns\" : [ { \"column\" : { \"name\" : \"id\" , \"type\" : \"int\" , \"autoIncrement\" : true , \"constraints\" : { \"primaryKey\" : true , \"nullable\" : false } } }, { \"column\" : { \"name\" : \"firstname\" , \"type\" : \"varchar(50)\" } }, { \"column\" : { \"name\" : \"lastname\" , \"type\" : \"varchar(50)\" , \"constraints\" : { \"nullable\" : false } } }, { \"column\" : { \"name\" : \"state\" , \"type\" : \"char(2)\" } } ] } } ] } }, { \"changeSet\" : { \"id\" : \"2\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"addColumn\" : { \"tableName\" : \"person\" , \"columns\" : [ { \"column\" : { \"name\" : \"username\" , \"type\" : \"varchar(8)\" } } ] } } ] } }, { \"changeSet\" : { \"id\" : \"3\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"addLookupTable\" : { \"existingTableName\" : \"person\" , \"existingColumnName\" : \"state\" , \"newTableName\" : \"state\" , \"newColumnName\" : \"id\" , \"newColumnDataType\" : \"char(2)\" } } ] } }, { \"changeSet\" : { \"id\" : \"5\" , \"author\" : \"iwolkow\" , \"changes\" : [ { \"createTable\" : { \"tableName\" : \"table_users\" , \"columns\" : [ { \"column\" : { \"name\" : \"id\" , \"type\" : \"int\" , \"autoIncrement\" : true , \"constraints\" : { \"primaryKey\" : true , \"nullable\" : false } } }, { \"column\" : { \"name\" : \"first_name\" , \"type\" : \"varchar(10)\" } }, { \"column\" : { \"name\" : \"last_name\" , \"type\" : \"varchar(50)\" , \"constraints\" : { \"nullable\" : false } } }, { \"column\" : { \"name\" : \"age\" , \"type\" : \"int\" } }, { \"column\" : { \"name\" : \"last_updated\" , \"type\" : \"timestamp\" } } ] } } ] } } ] } On saving the file Dirigible automatically detects and executes the .changelog file. Switching to DB perspective we can see that in our PUBLIC schema, are created three tables, as described in our changelog file: - Persons , - State - Table_Users and two more related to .changelog execution : - DATABASECHANGELOGLOCK DATABASECHANGELOG , by choosing see content of this table in Result View are changesets represented as entries: In SQL View we can execute several queries to check if everything works properly. INSERT INTO STATE VALUES ( 'RU' ); INSERT INTO STATE VALUES ( 'CH' ); INSERT INTO STATE VALUES ( 'FR' ); INSERT INTO PERSON VALUES ( 1 , 'IVAN' , 'PETROV' , 'RU' , 'ipetr88' ); INSERT INTO PERSON VALUES ( 2 , 'MAURICE' , 'LACROIX' , 'CH' , 'moris' ); INSERT INTO PERSON VALUES ( 3 , 'JEAN' , 'DE GAULLE' , 'FR' , 'jdg66' ); Note Scripts are executed by pressing: Windows : Ctrl + X Mac: Cmd + X Table data can de seen by choosing Show Content on table. Results are shown in the Result View .","title":"Dirigible"},{"location":"basic/mail-client/","text":"Send Email Steps Create a project mail . Create a JavaScript service with the name mail-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var mail = require ( \"mail/v4/client\" ); var from = \"from@email.address\" ; var to = \"to@email.address\" ; var subject = \"Subject\" ; var content = \"<h1>Content<h1>\" ; var subType = \"html\" ; mail . send ( from , to , subject , content , subType ); response . println ( \"Mail sent\" ); Note: This sample leverages the default mail configuration provided through the environment variables Create a project mail-custom . Create a JavaScript service with the name mail-custom-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var mail = require ( \"mail/v4/client\" ); var mailConfig = { \"mail.user\" : \"<your-mailbox-user>\" , \"mail.password\" : \"<your-mailbox-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"smtp.gmail.com\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" , }; var mailClient = mail . getClient ( mailConfig ); var from = \"<your-mailbox-user>@gmail.com\" ; var recipients = { to : \"<your-mailbox-user>@gmail.com\" , cc : [ \"<your-mailbox-user>@gmail.com\" , \"<your-mailbox-user-2>@sap.com\" ], bcc : \"<your-mailbox-user>@sap.com\" , }; var subject = \"Subject\" ; var content = \"<h1>Content</h1>\" ; var subType = \"html\" ; mailClient . send ( from , recipients , subject , content , subType ); response . println ( \"Mail sent\" ); Note: This sample leverages Gmail SMTPS, to make this sample work, access from third party applications ( Less secure apps ) should be enabled, also Troubleshoot Problems could help For more information, see the API documentation.","title":"Send Email"},{"location":"basic/mail-client/#send-email","text":"","title":"Send Email"},{"location":"basic/mail-client/#steps","text":"Create a project mail . Create a JavaScript service with the name mail-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var mail = require ( \"mail/v4/client\" ); var from = \"from@email.address\" ; var to = \"to@email.address\" ; var subject = \"Subject\" ; var content = \"<h1>Content<h1>\" ; var subType = \"html\" ; mail . send ( from , to , subject , content , subType ); response . println ( \"Mail sent\" ); Note: This sample leverages the default mail configuration provided through the environment variables Create a project mail-custom . Create a JavaScript service with the name mail-custom-service.js . Enter the following content: var response = require ( \"http/v4/response\" ); var mail = require ( \"mail/v4/client\" ); var mailConfig = { \"mail.user\" : \"<your-mailbox-user>\" , \"mail.password\" : \"<your-mailbox-password>\" , \"mail.transport.protocol\" : \"smtps\" , \"mail.smtps.host\" : \"smtp.gmail.com\" , \"mail.smtps.port\" : \"465\" , \"mail.smtps.auth\" : \"true\" , }; var mailClient = mail . getClient ( mailConfig ); var from = \"<your-mailbox-user>@gmail.com\" ; var recipients = { to : \"<your-mailbox-user>@gmail.com\" , cc : [ \"<your-mailbox-user>@gmail.com\" , \"<your-mailbox-user-2>@sap.com\" ], bcc : \"<your-mailbox-user>@sap.com\" , }; var subject = \"Subject\" ; var content = \"<h1>Content</h1>\" ; var subType = \"html\" ; mailClient . send ( from , recipients , subject , content , subType ); response . println ( \"Mail sent\" ); Note: This sample leverages Gmail SMTPS, to make this sample work, access from third party applications ( Less secure apps ) should be enabled, also Troubleshoot Problems could help For more information, see the API documentation.","title":"Steps"},{"location":"basic/platform-lifecycle/","text":"Platform Lifecycle Steps Create a project platform-lifecycle . Then create a JavaScript service named platform-lifecycle.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var user = require ( \"security/v4/user\" ); var workspace = require ( \"workspace/v4/manager\" ); var lifecycle = require ( \"platform/v4/lifecycle\" ); var bytes = require ( \"io/v4/bytes\" ); var user = user . getName (); var workspaceName = \"workspace\" ; var projectName = \"project\" ; var myWorkspace = workspace . createWorkspace ( workspaceName ); var myProject = myWorkspace . createProject ( projectName ); var myFile = myProject . createFile ( \"file.js\" ); myFile . setContent ( bytes . textToByteArray ( \"console.log('Hello World!');\" )); var publishResult = lifecycle . publish ( user , workspaceName , projectName ); response . println ( \"publishResult: \" + publishResult ); For more information, see the API documentation.","title":"Platform Lifecycle"},{"location":"basic/platform-lifecycle/#platform-lifecycle","text":"","title":"Platform Lifecycle"},{"location":"basic/platform-lifecycle/#steps","text":"Create a project platform-lifecycle . Then create a JavaScript service named platform-lifecycle.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var user = require ( \"security/v4/user\" ); var workspace = require ( \"workspace/v4/manager\" ); var lifecycle = require ( \"platform/v4/lifecycle\" ); var bytes = require ( \"io/v4/bytes\" ); var user = user . getName (); var workspaceName = \"workspace\" ; var projectName = \"project\" ; var myWorkspace = workspace . createWorkspace ( workspaceName ); var myProject = myWorkspace . createProject ( projectName ); var myFile = myProject . createFile ( \"file.js\" ); myFile . setContent ( bytes . textToByteArray ( \"console.log('Hello World!');\" )); var publishResult = lifecycle . publish ( user , workspaceName , projectName ); response . println ( \"publishResult: \" + publishResult ); For more information, see the API documentation.","title":"Steps"},{"location":"basic/print-configurations/","text":"Print Configuration Variables Steps Create a new project and name it config-vars . Select the project folder and open the pop-up menu. Choose New -> JavaScript Service . Give it a meaningful name (e.g print-config-vars.js ). Replace the generated code in print-config-vars.js with the following: var configurations = require ( \"core/v4/configurations\" ); var response = require ( \"http/v4/response\" ); var keys = configurations . getKeys (); var dirigibleKeys = {}; for ( var i = 0 ; i < keys . length ; i ++ ) { var key = keys [ i ]; if ( key . startsWith ( \"DIRIGIBLE\" )) { var value = configurations . get ( key ); dirigibleKeys [ key ] = value ; } } response . print ( JSON . stringify ( dirigibleKeys )); For more information, see the API documentation.","title":"Print Configuration Variables"},{"location":"basic/print-configurations/#print-configuration-variables","text":"","title":"Print Configuration Variables"},{"location":"basic/print-configurations/#steps","text":"Create a new project and name it config-vars . Select the project folder and open the pop-up menu. Choose New -> JavaScript Service . Give it a meaningful name (e.g print-config-vars.js ). Replace the generated code in print-config-vars.js with the following: var configurations = require ( \"core/v4/configurations\" ); var response = require ( \"http/v4/response\" ); var keys = configurations . getKeys (); var dirigibleKeys = {}; for ( var i = 0 ; i < keys . length ; i ++ ) { var key = keys [ i ]; if ( key . startsWith ( \"DIRIGIBLE\" )) { var value = configurations . get ( key ); dirigibleKeys [ key ] = value ; } } response . print ( JSON . stringify ( dirigibleKeys )); For more information, see the API documentation.","title":"Steps"},{"location":"basic/print-env/","text":"Print Environment Variables Steps Create a new project and name it env-vars . Select the project folder and open the pop-up menu. Choose New -> JavaScript Service . Give it a meaningful name (e.g print-env-vars.js ). Replace the generated code in print-env-vars.js with the following: var env = require ( \"core/v4/env\" ); var response = require ( \"http/v4/response\" ); var envVarsList = JSON . parse ( env . list ()); var envVarValue ; for ( var envVarName in envVarsList ) { envVarValue = envVarsList [ envVarName ]; response . println ( envVarName + \"=\" + envVarValue ); } response . flush (); response . close (); For more information, see the API documentation.","title":"Print Environment Variables"},{"location":"basic/print-env/#print-environment-variables","text":"","title":"Print Environment Variables"},{"location":"basic/print-env/#steps","text":"Create a new project and name it env-vars . Select the project folder and open the pop-up menu. Choose New -> JavaScript Service . Give it a meaningful name (e.g print-env-vars.js ). Replace the generated code in print-env-vars.js with the following: var env = require ( \"core/v4/env\" ); var response = require ( \"http/v4/response\" ); var envVarsList = JSON . parse ( env . list ()); var envVarValue ; for ( var envVarName in envVarsList ) { envVarValue = envVarsList [ envVarName ]; response . println ( envVarName + \"=\" + envVarValue ); } response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/qrcode-generator/","text":"QR Code Generator Steps Create a project utils-qrcode . Then create a JavaScript service named qr-generator.js . Within the service code, enter the following content: var qrCodeGenerator = require ( \"utils/v4/qrcode\" ); var response = require ( \"http/v4/response\" ); let qrCodeBytes = qrCodeGenerator . generateQRCode ( \"https://www.dirigible.io\" ); console . log ( \"QR Code Bytes: \" + qrCodeBytes ); response . write ( qrCodeBytes ); response . flush (); response . close (); For more information, see the API documentation.","title":"QR Code Generator"},{"location":"basic/qrcode-generator/#qr-code-generator","text":"","title":"QR Code Generator"},{"location":"basic/qrcode-generator/#steps","text":"Create a project utils-qrcode . Then create a JavaScript service named qr-generator.js . Within the service code, enter the following content: var qrCodeGenerator = require ( \"utils/v4/qrcode\" ); var response = require ( \"http/v4/response\" ); let qrCodeBytes = qrCodeGenerator . generateQRCode ( \"https://www.dirigible.io\" ); console . log ( \"QR Code Bytes: \" + qrCodeBytes ); response . write ( qrCodeBytes ); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/repository-manager/","text":"Repository Manager Steps Create a project repository-manager . Then create a JavaScript service named repository-test.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var repositoryManager = require ( \"repository/v4/manager\" ); repositoryManager . createResource ( \"/registry/public/test/file.js\" , \"console.log('Hello World');\" , \"application/json\" ); var resource = repositoryManager . getResource ( \"/registry/public/test/file.js\" ); var content = resource . getText (); response . println ( content ); response . flush (); response . close (); For more information, see the API documentation.","title":"Repository Manager"},{"location":"basic/repository-manager/#repository-manager","text":"","title":"Repository Manager"},{"location":"basic/repository-manager/#steps","text":"Create a project repository-manager . Then create a JavaScript service named repository-test.js . Within the service code, enter the following content: var response = require ( \"http/v4/response\" ); var repositoryManager = require ( \"repository/v4/manager\" ); repositoryManager . createResource ( \"/registry/public/test/file.js\" , \"console.log('Hello World');\" , \"application/json\" ); var resource = repositoryManager . getResource ( \"/registry/public/test/file.js\" ); var content = resource . getText (); response . println ( content ); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/rest-service/","text":"REST Service Steps Create a project rest-service . Then create a JavaScript service named rs-service.js . Within the service code, enter the following content: var rs = require ( \"http/v4/rs\" ); rs . service () // serve GET HTTP requests sent to resource path \"\" . resource ( \"\" ) . get ( function ( ctx , request , response ) { response . println ( \"Hello World!\" ); }) // serve GET HTTP requests sent to resource path \"hello/{name}\" e.g \"hello/John\" . resource ( \"hello/{name}\" ) . get ( function ( ctx , request , response ) { let name = ctx . pathParameters . name ; response . println ( \"Hello \" + name + \"!\" ); }) . execute (); For more information, see the API documentation and the guide here .","title":"REST Service"},{"location":"basic/rest-service/#rest-service","text":"","title":"REST Service"},{"location":"basic/rest-service/#steps","text":"Create a project rest-service . Then create a JavaScript service named rs-service.js . Within the service code, enter the following content: var rs = require ( \"http/v4/rs\" ); rs . service () // serve GET HTTP requests sent to resource path \"\" . resource ( \"\" ) . get ( function ( ctx , request , response ) { response . println ( \"Hello World!\" ); }) // serve GET HTTP requests sent to resource path \"hello/{name}\" e.g \"hello/John\" . resource ( \"hello/{name}\" ) . get ( function ( ctx , request , response ) { let name = ctx . pathParameters . name ; response . println ( \"Hello \" + name + \"!\" ); }) . execute (); For more information, see the API documentation and the guide here .","title":"Steps"},{"location":"basic/soap-client/","text":"SOAP - Client Steps Create a project soap . Create a JavaScript service with the name soap-client.js . Enter the following content: var soap = require ( \"net/v4/soap\" ); var response = require ( \"http/v4/response\" ); response . setContentType ( \"text/plain; charset=UTF-8\" ); var requestMessage = soap . createMessage (); var part = requestMessage . getPart (); var envelope = part . getEnvelope (); envelope . addNamespaceDeclaration ( \"ws\" , \"http://ws.cdyne.com/\" ); var body = envelope . getBody (); var resolveIPElement = body . addChildElement ( \"ResolveIP\" , \"ws\" ); var ipAddressElement = resolveIPElement . addChildElement ( \"ipAddress\" , \"ws\" ); ipAddressElement . addTextNode ( \"213.239.203.158\" ); var licenseKeyElement = resolveIPElement . addChildElement ( \"licenseKey\" , \"ws\" ); licenseKeyElement . addTextNode ( \"\" ); var mimeHeaders = requestMessage . getMimeHeaders (); mimeHeaders . addHeader ( \"SOAPAction\" , \"http://ws.cdyne.com/ResolveIP\" ); requestMessage . save (); response . println ( \"Request: \" + requestMessage . getText ()); var responseMessage = soap . call ( requestMessage , \"http://ws.cdyne.com/ip2geo/ip2geo.asmx\" ); response . println ( \"Response: \" + responseMessage . getText ()); var responsePart = responseMessage . getPart (); var responseEnvelope = responsePart . getEnvelope (); var responseBody = responseEnvelope . getBody (); var childElements = responseBody . getChildElements (); printElements ( childElements ); response . flush (); response . close (); function printElements ( childElements ) { childElements . forEach ( function ( element ) { if ( element . isSOAPElement ()) { var name = element . getElementName (); response . print ( name . getLocalName ()); response . print ( \": \" ); response . println ( JSON . stringify ( element . getValue ())); printElements ( element . getChildElements ()); } }); } For more information, see the API documentation.","title":"SOAP - Client"},{"location":"basic/soap-client/#soap-client","text":"","title":"SOAP - Client"},{"location":"basic/soap-client/#steps","text":"Create a project soap . Create a JavaScript service with the name soap-client.js . Enter the following content: var soap = require ( \"net/v4/soap\" ); var response = require ( \"http/v4/response\" ); response . setContentType ( \"text/plain; charset=UTF-8\" ); var requestMessage = soap . createMessage (); var part = requestMessage . getPart (); var envelope = part . getEnvelope (); envelope . addNamespaceDeclaration ( \"ws\" , \"http://ws.cdyne.com/\" ); var body = envelope . getBody (); var resolveIPElement = body . addChildElement ( \"ResolveIP\" , \"ws\" ); var ipAddressElement = resolveIPElement . addChildElement ( \"ipAddress\" , \"ws\" ); ipAddressElement . addTextNode ( \"213.239.203.158\" ); var licenseKeyElement = resolveIPElement . addChildElement ( \"licenseKey\" , \"ws\" ); licenseKeyElement . addTextNode ( \"\" ); var mimeHeaders = requestMessage . getMimeHeaders (); mimeHeaders . addHeader ( \"SOAPAction\" , \"http://ws.cdyne.com/ResolveIP\" ); requestMessage . save (); response . println ( \"Request: \" + requestMessage . getText ()); var responseMessage = soap . call ( requestMessage , \"http://ws.cdyne.com/ip2geo/ip2geo.asmx\" ); response . println ( \"Response: \" + responseMessage . getText ()); var responsePart = responseMessage . getPart (); var responseEnvelope = responsePart . getEnvelope (); var responseBody = responseEnvelope . getBody (); var childElements = responseBody . getChildElements (); printElements ( childElements ); response . flush (); response . close (); function printElements ( childElements ) { childElements . forEach ( function ( element ) { if ( element . isSOAPElement ()) { var name = element . getElementName (); response . print ( name . getLocalName ()); response . print ( \": \" ); response . println ( JSON . stringify ( element . getValue ())); printElements ( element . getChildElements ()); } }); } For more information, see the API documentation.","title":"Steps"},{"location":"basic/soap-server/","text":"SOAP - Server Steps Create a project soap . Create a JavaScript service with the name soap-server.js . Enter the following content: var soap = require ( \"net/v4/soap\" ); var request = require ( \"http/v4/request\" ); var response = require ( \"http/v4/response\" ); var xml = require ( \"utils/v4/xml\" ); // Parse SOAP request var message = soap . parseRequest (); var requestPart = message . getPart (); var requestEnvelope = requestPart . getEnvelope (); var requestBody = requestEnvelope . getBody (); var childElements = requestBody . getChildElements (); printElements ( childElements ); response . setContentType ( \"text/xml; charset=utf-8\" ); var json = { \"soap:Envelope\" : { \"-xmlns:soap\" : \"http://schemas.xmlsoap.org/soap/envelope/\" , \"-xmlns:xsd\" : \"http://www.w3.org/2001/XMLSchema\" , \"-xmlns:xsi\" : \"http://www.w3.org/2001/XMLSchema-instance\" , \"soap:Body\" : { ResolveIPResponse : { \"-xmlns\" : \"http://ws.cdyne.com/\" , ResolveIPResult : { Country : \"Germany\" , Organization : {}, Latitude : \"51.2993\" , Longitude : \"9.490997\" , AreaCode : \"0\" , TimeZone : {}, HasDaylightSavings : \"false\" , Certainty : \"90\" , RegionName : {}, CountryCode : \"DE\" , }, }, }, }, }; var payload = xml . fromJson ( JSON . stringify ( json )); response . println ( payload ); response . flush (); response . close (); function printElements ( childElements ) { childElements . forEach ( function ( element ) { if ( element . isSOAPElement ()) { var name = element . getElementName (); console . log ( name . getLocalName () + \": \" + element . getValue ()); printElements ( element . getChildElements ()); } }); } For more information, see the API documentation.","title":"SOAP - Server"},{"location":"basic/soap-server/#soap-server","text":"","title":"SOAP - Server"},{"location":"basic/soap-server/#steps","text":"Create a project soap . Create a JavaScript service with the name soap-server.js . Enter the following content: var soap = require ( \"net/v4/soap\" ); var request = require ( \"http/v4/request\" ); var response = require ( \"http/v4/response\" ); var xml = require ( \"utils/v4/xml\" ); // Parse SOAP request var message = soap . parseRequest (); var requestPart = message . getPart (); var requestEnvelope = requestPart . getEnvelope (); var requestBody = requestEnvelope . getBody (); var childElements = requestBody . getChildElements (); printElements ( childElements ); response . setContentType ( \"text/xml; charset=utf-8\" ); var json = { \"soap:Envelope\" : { \"-xmlns:soap\" : \"http://schemas.xmlsoap.org/soap/envelope/\" , \"-xmlns:xsd\" : \"http://www.w3.org/2001/XMLSchema\" , \"-xmlns:xsi\" : \"http://www.w3.org/2001/XMLSchema-instance\" , \"soap:Body\" : { ResolveIPResponse : { \"-xmlns\" : \"http://ws.cdyne.com/\" , ResolveIPResult : { Country : \"Germany\" , Organization : {}, Latitude : \"51.2993\" , Longitude : \"9.490997\" , AreaCode : \"0\" , TimeZone : {}, HasDaylightSavings : \"false\" , Certainty : \"90\" , RegionName : {}, CountryCode : \"DE\" , }, }, }, }, }; var payload = xml . fromJson ( JSON . stringify ( json )); response . println ( payload ); response . flush (); response . close (); function printElements ( childElements ) { childElements . forEach ( function ( element ) { if ( element . isSOAPElement ()) { var name = element . getElementName (); console . log ( name . getLocalName () + \": \" + element . getValue ()); printElements ( element . getChildElements ()); } }); } For more information, see the API documentation.","title":"Steps"},{"location":"basic/url-decode/","text":"URL - UTF-8 Decoding Steps Create a project utils-url . Create a JavaScript service with the name url-decode.js . Enter the following content: var url = require ( \"utils/v4/url\" ); var response = require ( \"http/v4/response\" ); var input = \"http%3A%2F%2Fwww.dirigible.io%2F\" ; var result = url . decode ( input , \"UTF-8\" ); console . log ( \"Decoded URL: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"URL - UTF-8 Decoding"},{"location":"basic/url-decode/#url-utf-8-decoding","text":"","title":"URL - UTF-8 Decoding"},{"location":"basic/url-decode/#steps","text":"Create a project utils-url . Create a JavaScript service with the name url-decode.js . Enter the following content: var url = require ( \"utils/v4/url\" ); var response = require ( \"http/v4/response\" ); var input = \"http%3A%2F%2Fwww.dirigible.io%2F\" ; var result = url . decode ( input , \"UTF-8\" ); console . log ( \"Decoded URL: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/url-encode/","text":"URL - UTF-8 Encoding Steps Create a project utils-url . Create a JavaScript service with the name url-encode.js . Enter the following content: var url = require ( \"utils/v4/url\" ); var response = require ( \"http/v4/response\" ); var input = \"http://www.dirigible.io/\" ; var result = url . encode ( input , \"UTF-8\" ); console . log ( \"Encoded URL: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"URL - UTF-8 Encoding"},{"location":"basic/url-encode/#url-utf-8-encoding","text":"","title":"URL - UTF-8 Encoding"},{"location":"basic/url-encode/#steps","text":"Create a project utils-url . Create a JavaScript service with the name url-encode.js . Enter the following content: var url = require ( \"utils/v4/url\" ); var response = require ( \"http/v4/response\" ); var input = \"http://www.dirigible.io/\" ; var result = url . encode ( input , \"UTF-8\" ); console . log ( \"Encoded URL: \" + result ); response . println ( JSON . stringify ( result )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"basic/uuid-random-generation/","text":"UUID - Random Generation Steps Create a project utils-uuid . Create a JavaScript service with the name uuid-random-generator.js . Enter the following content: var uuid = require ( \"utils/v4/uuid\" ); var response = require ( \"http/v4/response\" ); var generated = uuid . random (); console . log ( generated ); uuid . validate ( generated ); console . log ( \"Randomly Generated UUID: \" + generated ); response . println ( JSON . stringify ( \"Randomly Generated UUID: \" + generated )); response . flush (); response . close (); For more information, see the API documentation.","title":"UUID - Random Generation"},{"location":"basic/uuid-random-generation/#uuid-random-generation","text":"","title":"UUID - Random Generation"},{"location":"basic/uuid-random-generation/#steps","text":"Create a project utils-uuid . Create a JavaScript service with the name uuid-random-generator.js . Enter the following content: var uuid = require ( \"utils/v4/uuid\" ); var response = require ( \"http/v4/response\" ); var generated = uuid . random (); console . log ( generated ); uuid . validate ( generated ); console . log ( \"Randomly Generated UUID: \" + generated ); response . println ( JSON . stringify ( \"Randomly Generated UUID: \" + generated )); response . flush (); response . close (); For more information, see the API documentation.","title":"Steps"},{"location":"complex/bookstore/","text":"Bookstore Application This sample shows how to create a simple web application for managing a single entity called Books . It contains a database table definition, a RESTful service and a web page for managing the instances via user interface. Steps Project Create a project babylon_project Database Descriptor Then create a database table description named BABYLON_BOOKS.table under the folder data Replace the service code with the following content: { \"name\" : \"BABYLON_BOOKS\" , \"type\" : \"TABLE\" , \"columns\" : [ { \"name\" : \"BOOK_ID\" , \"type\" : \"INTEGER\" , \"length\" : \"0\" , \"primaryKey\" : \"true\" , \"identity\" : \"true\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_ISBN\" , \"type\" : \"CHAR\" , \"length\" : \"13\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_TITLE\" , \"type\" : \"VARCHAR\" , \"length\" : \"120\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_PUBLISHER\" , \"type\" : \"VARCHAR\" , \"length\" : \"120\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_DATE\" , \"type\" : \"DATE\" , \"length\" : \"20\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_PRICE\" , \"type\" : \"DOUBLE\" , \"length\" : \"20\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" } ], \"dependencies\" : [] } Data Access Object Create a JavaScript service named Books.js under the folder dao . Replace the service code with the following content: var daoApi = require ( 'db/v4/dao' ); var dao = daoApi . create ({ 'table' : 'BABYLON_BOOKS' , 'properties' : [ { 'name' : 'id' , 'column' : 'BOOK_ID' , 'type' : 'INTEGER' , 'id' : true , 'required' : true }, { 'name' : 'isbn' , 'column' : 'BOOK_ISBN' , 'type' : 'CHAR' , 'id' : false , 'required' : false }, { 'name' : 'title' , 'column' : 'BOOK_TITLE' , 'type' : 'VARCHAR' , 'id' : false , 'required' : false }, { 'name' : 'publisher' , 'column' : 'BOOK_PUBLISHER' , 'type' : 'VARCHAR' , 'id' : false , 'required' : false }, { 'name' : 'date' , 'column' : 'BOOK_DATE' , 'type' : 'DATE' , 'id' : false , 'required' : true }, { 'name' : 'price' , 'column' : 'BOOK_PRICE' , 'type' : 'DOUBLE' , 'id' : false , 'required' : true }] }); exports . list = function ( settings ) { return dao . list ( settings ); }; exports . get = function ( id ) { return dao . find ( id ); }; exports . create = function ( entity ) { return dao . insert ( entity ); }; exports . update = function ( entity ) { return dao . update ( entity ); }; exports . delete = function ( id ) { dao . remove ( id ); }; RESTful Service Then create a Books.js service file under the folder service Replace the content with the following code: var rs = require ( 'http/v4/rs' ); var dao = require ( 'babylon_project/dao/Books' ); var response = require ( 'http/v4/response' ); // HTTP 200 var sendResponseOk = function ( entity ) { sendResponse ( 200 , entity ); }; // HTTP 201 var sendResponseCreated = function ( entity ) { sendResponse ( 201 , entity ); }; // HTTP 200 var sendResponseNoContent = function () { sendResponse ( 204 ); }; // HTTP 400 var sendResponseBadRequest = function ( message ) { sendResponse ( 404 , { 'code' : 400 , 'message' : message }); }; // HTTP 404 var sendResponseNotFound = function ( message ) { sendResponse ( 404 , { 'code' : 404 , 'message' : message }); }; // Generic var sendResponse = function ( status , body ) { response . setContentType ( 'application/json' ); response . setStatus ( status ); if ( body ) { response . println ( JSON . stringify ( body )); } }; rs . service () . resource ( '' ) . get ( function () { var entities = dao . list (); sendResponseOk ( entities ); }) . resource ( '{id}' ) . get ( function ( ctx ) { var id = ctx . pathParameters . id ; var entity = dao . get ( id ); if ( entity ) { sendResponseOk ( entity ); } else { sendResponseNotFound ( 'Books not found' ); } }) . resource ( '' ) . post ( function ( ctx , request , response ) { var entity = request . getJSON (); entity . id = dao . create ( entity ); response . setHeader ( 'Content-Location' , '/services/v4/js/babylon_project/service/Books.js/' + entity . id ); sendResponseCreated ( entity ); }) . resource ( '{id}' ) . put ( function ( ctx , request ) { var entity = request . getJSON (); entity . id = ctx . pathParameters . id ; dao . update ( entity ); sendResponseOk ( entity ); }) . resource ( '{id}' ) . delete ( function ( ctx ) { var id = ctx . pathParameters . id ; var entity = dao . get ( id ); if ( entity ) { dao . delete ( id ); sendResponseNoContent (); } else { sendResponseNotFound ( 'Books not found' ); } }) . execute (); User Interface Then create a index.html web page under the folder view Replace the content with the following code: <!DOCTYPE html> < html lang = \"en\" ng-app = \"page\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v4/core/theme/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < link type = \"image/png\" rel = \"shortcut icon\" href = \"/services/v4/web/resources/images/favicon.png\" /> </ head > < body ng-controller = \"PageController\" > < div class = \"page-header\" > < h1 > Manage Books </ h1 > </ div > < div class = \"container\" > < button type = \"button\" ng-click = \"openNewDialog()\" class = \"btn btn-lg btn-primary pull-right\" > New </ button > < table class = \"table product-table\" > < thead > < tr > < th > # </ th > < th class = \"text-capitalize\" > id </ th > < th class = \"text-capitalize\" > isbn </ th > < th class = \"text-capitalize\" > title </ th > < th class = \"text-capitalize\" > publisher </ th > < th class = \"text-capitalize\" > date </ th > < th class = \"text-capitalize\" > price </ th > < th ></ th > </ tr > </ thead > < tbody > < tr ng-repeat = \"next in data\" > < td > {{$index + 1}} </ td > < td > {{next.id}} </ td > < td > {{next.isbn}} </ td > < td > {{next.title}} </ td > < td > {{next.publisher}} </ td > < td > {{next.date}} </ td > < td > {{next.price}} </ td > < td > < i class = \"close fa fa-2x fa-remove\" ng-click = \"openDeleteDialog(next)\" ></ i > < i class = \"close fa fa-2x fa-pencil\" ng-click = \"openEditDialog(next)\" style = \"margin-right: 0.5em\" ></ i > </ td > </ tr > </ tbody > </ table > </ div > < div class = \"modal fade\" id = \"entityModal\" tabindex = \"-1\" role = \"dialog\" aria-hidden = \"true\" > < div class = \"modal-dialog\" role = \"document\" > < div class = \"modal-content\" > < div class = \"modal-header\" > < h3 ng-show = \"actionType === 'new'\" class = \"modal-title\" id = \"exampleModalLabel\" > Create entity </ h3 > < h3 ng-show = \"actionType === 'update'\" class = \"modal-title\" id = \"exampleModalLabel\" > Update entity </ h3 > < h3 ng-show = \"actionType === 'delete'\" class = \"modal-title\" id = \"exampleModalLabel\" > Delete entity </ h3 > < button type = \"button\" class = \"close\" data-dismiss = \"modal\" aria-label = \"Close\" > < span aria-hidden = \"true\" > &times; </ span > </ button > </ div > < div class = \"modal-body\" > < form ng-hide = \"actionType === 'delete'\" > < div class = \"form-group\" > < label > ISBN </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter isbn\" ng-model = \"entity.isbn\" > </ div > < div class = \"form-group\" > < label > Title </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter title\" ng-model = \"entity.title\" > </ div > < div class = \"form-group\" > < label > Publisher </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter publisher\" ng-model = \"entity.publisher\" > </ div > < div class = \"form-group\" > < label > Date </ label > < input type = \"date\" class = \"form-control\" placeholder = \"Enter date\" ng-model = \"entity.date\" > </ div > < div class = \"form-group\" > < label > price </ label > < input type = \"number\" class = \"form-control\" placeholder = \"Enter price\" ng-model = \"entity.price\" > </ div > </ form > < div ng-show = \"actionType === 'delete'\" > You are going to delete < b > Books </ b > with < b > id = {{entity.id}} </ b > . </ div > </ div > < div class = \"modal-footer\" > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'new'\" ng-click = \"create()\" > Save </ button > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'update'\" ng-click = \"update()\" > Update </ button > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'delete'\" ng-click = \"delete()\" > Delete </ button > < button type = \"button\" class = \"btn btn-danger\" data-dismiss = \"modal\" > Close </ button > </ div > </ div > </ div > </ div > < script type = \"text/javascript\" src = \"/services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" async ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > < script type = \"text/javascript\" src = \"controller.js\" ></ script > </ body > </ html > Create the controller file as controller.js under the same view folder next to the index.html Replace the content with the following code: angular . module ( 'page' , []); angular . module ( 'page' ). controller ( 'PageController' , function ( $scope , $http ) { var api = '/services/v4/js/babylon_project/service/Books.js' ; function load () { $http . get ( api ) . success ( function ( data ) { $scope . data = data ; }); } load (); $scope . openNewDialog = function () { $scope . actionType = 'new' ; $scope . entity = {}; toggleEntityModal (); }; $scope . openEditDialog = function ( entity ) { $scope . actionType = 'update' ; $scope . entity = entity ; toggleEntityModal (); }; $scope . openDeleteDialog = function ( entity ) { $scope . actionType = 'delete' ; $scope . entity = entity ; toggleEntityModal (); }; $scope . close = function () { load (); toggleEntityModal (); }; $scope . create = function () { $http . post ( api , JSON . stringify ( $scope . entity )) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }); }; $scope . update = function () { $http . put ( api + '/' + $scope . entity . id , JSON . stringify ( $scope . entity )) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }) }; $scope . delete = function () { $http . delete ( api + '/' + $scope . entity . id ) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }); }; function toggleEntityModal () { $ ( '#entityModal' ). modal ( 'toggle' ); } }); Publish and Preview Publish the project Select the index.html in the Workspace view In the Preview window you should see the web page for books management. Try to enter a few book descriptions to test how it works. For more information, see the API documentation.","title":"Bookstore Application"},{"location":"complex/bookstore/#bookstore-application","text":"This sample shows how to create a simple web application for managing a single entity called Books . It contains a database table definition, a RESTful service and a web page for managing the instances via user interface.","title":"Bookstore Application"},{"location":"complex/bookstore/#steps","text":"","title":"Steps"},{"location":"complex/bookstore/#project","text":"Create a project babylon_project","title":"Project"},{"location":"complex/bookstore/#database-descriptor","text":"Then create a database table description named BABYLON_BOOKS.table under the folder data Replace the service code with the following content: { \"name\" : \"BABYLON_BOOKS\" , \"type\" : \"TABLE\" , \"columns\" : [ { \"name\" : \"BOOK_ID\" , \"type\" : \"INTEGER\" , \"length\" : \"0\" , \"primaryKey\" : \"true\" , \"identity\" : \"true\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_ISBN\" , \"type\" : \"CHAR\" , \"length\" : \"13\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_TITLE\" , \"type\" : \"VARCHAR\" , \"length\" : \"120\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_PUBLISHER\" , \"type\" : \"VARCHAR\" , \"length\" : \"120\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_DATE\" , \"type\" : \"DATE\" , \"length\" : \"20\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" }, { \"name\" : \"BOOK_PRICE\" , \"type\" : \"DOUBLE\" , \"length\" : \"20\" , \"primaryKey\" : \"false\" , \"identity\" : \"false\" , \"precision\" : \"\" , \"scale\" : \"\" } ], \"dependencies\" : [] }","title":"Database Descriptor"},{"location":"complex/bookstore/#data-access-object","text":"Create a JavaScript service named Books.js under the folder dao . Replace the service code with the following content: var daoApi = require ( 'db/v4/dao' ); var dao = daoApi . create ({ 'table' : 'BABYLON_BOOKS' , 'properties' : [ { 'name' : 'id' , 'column' : 'BOOK_ID' , 'type' : 'INTEGER' , 'id' : true , 'required' : true }, { 'name' : 'isbn' , 'column' : 'BOOK_ISBN' , 'type' : 'CHAR' , 'id' : false , 'required' : false }, { 'name' : 'title' , 'column' : 'BOOK_TITLE' , 'type' : 'VARCHAR' , 'id' : false , 'required' : false }, { 'name' : 'publisher' , 'column' : 'BOOK_PUBLISHER' , 'type' : 'VARCHAR' , 'id' : false , 'required' : false }, { 'name' : 'date' , 'column' : 'BOOK_DATE' , 'type' : 'DATE' , 'id' : false , 'required' : true }, { 'name' : 'price' , 'column' : 'BOOK_PRICE' , 'type' : 'DOUBLE' , 'id' : false , 'required' : true }] }); exports . list = function ( settings ) { return dao . list ( settings ); }; exports . get = function ( id ) { return dao . find ( id ); }; exports . create = function ( entity ) { return dao . insert ( entity ); }; exports . update = function ( entity ) { return dao . update ( entity ); }; exports . delete = function ( id ) { dao . remove ( id ); };","title":"Data Access Object"},{"location":"complex/bookstore/#restful-service","text":"Then create a Books.js service file under the folder service Replace the content with the following code: var rs = require ( 'http/v4/rs' ); var dao = require ( 'babylon_project/dao/Books' ); var response = require ( 'http/v4/response' ); // HTTP 200 var sendResponseOk = function ( entity ) { sendResponse ( 200 , entity ); }; // HTTP 201 var sendResponseCreated = function ( entity ) { sendResponse ( 201 , entity ); }; // HTTP 200 var sendResponseNoContent = function () { sendResponse ( 204 ); }; // HTTP 400 var sendResponseBadRequest = function ( message ) { sendResponse ( 404 , { 'code' : 400 , 'message' : message }); }; // HTTP 404 var sendResponseNotFound = function ( message ) { sendResponse ( 404 , { 'code' : 404 , 'message' : message }); }; // Generic var sendResponse = function ( status , body ) { response . setContentType ( 'application/json' ); response . setStatus ( status ); if ( body ) { response . println ( JSON . stringify ( body )); } }; rs . service () . resource ( '' ) . get ( function () { var entities = dao . list (); sendResponseOk ( entities ); }) . resource ( '{id}' ) . get ( function ( ctx ) { var id = ctx . pathParameters . id ; var entity = dao . get ( id ); if ( entity ) { sendResponseOk ( entity ); } else { sendResponseNotFound ( 'Books not found' ); } }) . resource ( '' ) . post ( function ( ctx , request , response ) { var entity = request . getJSON (); entity . id = dao . create ( entity ); response . setHeader ( 'Content-Location' , '/services/v4/js/babylon_project/service/Books.js/' + entity . id ); sendResponseCreated ( entity ); }) . resource ( '{id}' ) . put ( function ( ctx , request ) { var entity = request . getJSON (); entity . id = ctx . pathParameters . id ; dao . update ( entity ); sendResponseOk ( entity ); }) . resource ( '{id}' ) . delete ( function ( ctx ) { var id = ctx . pathParameters . id ; var entity = dao . get ( id ); if ( entity ) { dao . delete ( id ); sendResponseNoContent (); } else { sendResponseNotFound ( 'Books not found' ); } }) . execute ();","title":"RESTful Service"},{"location":"complex/bookstore/#user-interface","text":"Then create a index.html web page under the folder view Replace the content with the following code: <!DOCTYPE html> < html lang = \"en\" ng-app = \"page\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v4/core/theme/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < link type = \"image/png\" rel = \"shortcut icon\" href = \"/services/v4/web/resources/images/favicon.png\" /> </ head > < body ng-controller = \"PageController\" > < div class = \"page-header\" > < h1 > Manage Books </ h1 > </ div > < div class = \"container\" > < button type = \"button\" ng-click = \"openNewDialog()\" class = \"btn btn-lg btn-primary pull-right\" > New </ button > < table class = \"table product-table\" > < thead > < tr > < th > # </ th > < th class = \"text-capitalize\" > id </ th > < th class = \"text-capitalize\" > isbn </ th > < th class = \"text-capitalize\" > title </ th > < th class = \"text-capitalize\" > publisher </ th > < th class = \"text-capitalize\" > date </ th > < th class = \"text-capitalize\" > price </ th > < th ></ th > </ tr > </ thead > < tbody > < tr ng-repeat = \"next in data\" > < td > {{$index + 1}} </ td > < td > {{next.id}} </ td > < td > {{next.isbn}} </ td > < td > {{next.title}} </ td > < td > {{next.publisher}} </ td > < td > {{next.date}} </ td > < td > {{next.price}} </ td > < td > < i class = \"close fa fa-2x fa-remove\" ng-click = \"openDeleteDialog(next)\" ></ i > < i class = \"close fa fa-2x fa-pencil\" ng-click = \"openEditDialog(next)\" style = \"margin-right: 0.5em\" ></ i > </ td > </ tr > </ tbody > </ table > </ div > < div class = \"modal fade\" id = \"entityModal\" tabindex = \"-1\" role = \"dialog\" aria-hidden = \"true\" > < div class = \"modal-dialog\" role = \"document\" > < div class = \"modal-content\" > < div class = \"modal-header\" > < h3 ng-show = \"actionType === 'new'\" class = \"modal-title\" id = \"exampleModalLabel\" > Create entity </ h3 > < h3 ng-show = \"actionType === 'update'\" class = \"modal-title\" id = \"exampleModalLabel\" > Update entity </ h3 > < h3 ng-show = \"actionType === 'delete'\" class = \"modal-title\" id = \"exampleModalLabel\" > Delete entity </ h3 > < button type = \"button\" class = \"close\" data-dismiss = \"modal\" aria-label = \"Close\" > < span aria-hidden = \"true\" > &times; </ span > </ button > </ div > < div class = \"modal-body\" > < form ng-hide = \"actionType === 'delete'\" > < div class = \"form-group\" > < label > ISBN </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter isbn\" ng-model = \"entity.isbn\" > </ div > < div class = \"form-group\" > < label > Title </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter title\" ng-model = \"entity.title\" > </ div > < div class = \"form-group\" > < label > Publisher </ label > < input type = \"text\" class = \"form-control\" placeholder = \"Enter publisher\" ng-model = \"entity.publisher\" > </ div > < div class = \"form-group\" > < label > Date </ label > < input type = \"date\" class = \"form-control\" placeholder = \"Enter date\" ng-model = \"entity.date\" > </ div > < div class = \"form-group\" > < label > price </ label > < input type = \"number\" class = \"form-control\" placeholder = \"Enter price\" ng-model = \"entity.price\" > </ div > </ form > < div ng-show = \"actionType === 'delete'\" > You are going to delete < b > Books </ b > with < b > id = {{entity.id}} </ b > . </ div > </ div > < div class = \"modal-footer\" > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'new'\" ng-click = \"create()\" > Save </ button > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'update'\" ng-click = \"update()\" > Update </ button > < button type = \"button\" class = \"btn btn-primary\" ng-show = \"actionType === 'delete'\" ng-click = \"delete()\" > Delete </ button > < button type = \"button\" class = \"btn btn-danger\" data-dismiss = \"modal\" > Close </ button > </ div > </ div > </ div > </ div > < script type = \"text/javascript\" src = \"/services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" async ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > < script type = \"text/javascript\" src = \"controller.js\" ></ script > </ body > </ html > Create the controller file as controller.js under the same view folder next to the index.html Replace the content with the following code: angular . module ( 'page' , []); angular . module ( 'page' ). controller ( 'PageController' , function ( $scope , $http ) { var api = '/services/v4/js/babylon_project/service/Books.js' ; function load () { $http . get ( api ) . success ( function ( data ) { $scope . data = data ; }); } load (); $scope . openNewDialog = function () { $scope . actionType = 'new' ; $scope . entity = {}; toggleEntityModal (); }; $scope . openEditDialog = function ( entity ) { $scope . actionType = 'update' ; $scope . entity = entity ; toggleEntityModal (); }; $scope . openDeleteDialog = function ( entity ) { $scope . actionType = 'delete' ; $scope . entity = entity ; toggleEntityModal (); }; $scope . close = function () { load (); toggleEntityModal (); }; $scope . create = function () { $http . post ( api , JSON . stringify ( $scope . entity )) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }); }; $scope . update = function () { $http . put ( api + '/' + $scope . entity . id , JSON . stringify ( $scope . entity )) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }) }; $scope . delete = function () { $http . delete ( api + '/' + $scope . entity . id ) . success ( function ( data ) { load (); toggleEntityModal (); }). error ( function ( data ) { alert ( JSON . stringify ( data )); }); }; function toggleEntityModal () { $ ( '#entityModal' ). modal ( 'toggle' ); } });","title":"User Interface"},{"location":"complex/bookstore/#publish-and-preview","text":"Publish the project Select the index.html in the Workspace view In the Preview window you should see the web page for books management. Try to enter a few book descriptions to test how it works. For more information, see the API documentation.","title":"Publish and Preview"},{"location":"complex/embedded/","text":"Embedded Dirigible Sample class showing how to embed Dirigible into an arbitrary Java application. Steps Create a Java project Create a folder \"content\" Create sub-folder \"project1\" under the \"content\" folder Create a file named \"hello1.js\" under the \"project1\" folder with the following content console . log ( 'Hello World!' ); Create a Java class named \"MyApp\" with the following content: import java.io.IOException ; import org.eclipse.dirigible.commons.api.context.ContextException ; import org.eclipse.dirigible.commons.api.scripting.ScriptingException ; import org.eclipse.dirigible.runtime.core.embed.EmbeddedDirigible ; public class MyApp { public static void main ( String [] args ) { // create a Dirigible instance EmbeddedDirigible dirigible = new EmbeddedDirigible (); try { // initialize the Dirigible instance dirigible . initialize (); // import the content under the specified folder to the Dirigible's registry dirigible . load ( \"./content\" ); // execute a given service module dirigible . executeJavaScript ( \"project1/hello1.js\" ); // or more generic dirigible.execute(dirigible.ENGINE_TYPE_JAVASCRIPT, \"project1/hello1.js\"); // or richer dirigible.execute(dirigible.ENGINE_TYPE_JAVASCRIPT, \"project1/hello1.js\", context, request, response); } catch ( IOException | ScriptingException | ContextException e ) { e . printStackTrace (); } finally { // destroy the Dirigible instance dirigible . destroy (); System . exit ( 0 ); } } } Run it as a Java application You have to be able to find the following log record in the system output [main] INFO org.eclipse.dirigible.api.v3.core.Console - Hello World!","title":"Embedded Dirigible"},{"location":"complex/embedded/#embedded-dirigible","text":"Sample class showing how to embed Dirigible into an arbitrary Java application.","title":"Embedded Dirigible"},{"location":"complex/embedded/#steps","text":"Create a Java project Create a folder \"content\" Create sub-folder \"project1\" under the \"content\" folder Create a file named \"hello1.js\" under the \"project1\" folder with the following content console . log ( 'Hello World!' ); Create a Java class named \"MyApp\" with the following content: import java.io.IOException ; import org.eclipse.dirigible.commons.api.context.ContextException ; import org.eclipse.dirigible.commons.api.scripting.ScriptingException ; import org.eclipse.dirigible.runtime.core.embed.EmbeddedDirigible ; public class MyApp { public static void main ( String [] args ) { // create a Dirigible instance EmbeddedDirigible dirigible = new EmbeddedDirigible (); try { // initialize the Dirigible instance dirigible . initialize (); // import the content under the specified folder to the Dirigible's registry dirigible . load ( \"./content\" ); // execute a given service module dirigible . executeJavaScript ( \"project1/hello1.js\" ); // or more generic dirigible.execute(dirigible.ENGINE_TYPE_JAVASCRIPT, \"project1/hello1.js\"); // or richer dirigible.execute(dirigible.ENGINE_TYPE_JAVASCRIPT, \"project1/hello1.js\", context, request, response); } catch ( IOException | ScriptingException | ContextException e ) { e . printStackTrace (); } finally { // destroy the Dirigible instance dirigible . destroy (); System . exit ( 0 ); } } } Run it as a Java application You have to be able to find the following log record in the system output [main] INFO org.eclipse.dirigible.api.v3.core.Console - Hello World!","title":"Steps"},{"location":"complex/file-upload/","text":"File Upload Steps Create a project file_upload_project Then create a JavaScript service named my_file_upload.js Replace the service code with the following content: File Upload Handler var upload = require ( 'http/v4/upload' ); var request = require ( 'http/v4/request' ); var response = require ( 'http/v4/response' ); if ( request . getMethod () === \"POST\" ) { if ( upload . isMultipartContent ()) { var fileItems = upload . parseRequest (); for ( i = 0 ; i < fileItems . size (); i ++ ) { var fileItem = fileItems . get ( i ); if ( ! fileItem . isFormField ()) { response . println ( \"File Name: \" + fileItem . getName ()); response . println ( \"File Bytes (as text): \" + String . fromCharCode . apply ( null , fileItem . getBytes ())); } else { response . println ( \"Field Name: \" + fileItem . getFieldName ()); response . println ( \"Field Text: \" + fileItem . getText ()); } } } else { response . println ( \"The request's content must be 'multipart'\" ); } } else if ( request . getMethod () === \"GET\" ) { response . println ( \"Use POST request.\" ); } response . flush (); response . close (); Then create a HTML5 page named my_upload.html Replace the content with the following HTML code: File Upload Frontend < html > < body > < form action = \"/services/v4/js/file_upload_project/my_file_upload.js\" method = \"post\" enctype = \"multipart/form-data\" > < label for = \"file\" > Filename: </ label > < input type = \"file\" name = \"file\" id = \"file\" multiple > < br > < input type = \"submit\" name = \"submit\" value = \"Submit\" > </ form > </ body > </ html > Publish the project Select the my_upload.html file in the Workspace view and try to test by uploading a file in the Preview For more information, see the API documentation.","title":"File Upload"},{"location":"complex/file-upload/#file-upload","text":"","title":"File Upload"},{"location":"complex/file-upload/#steps","text":"Create a project file_upload_project Then create a JavaScript service named my_file_upload.js Replace the service code with the following content:","title":"Steps"},{"location":"complex/file-upload/#file-upload-handler","text":"var upload = require ( 'http/v4/upload' ); var request = require ( 'http/v4/request' ); var response = require ( 'http/v4/response' ); if ( request . getMethod () === \"POST\" ) { if ( upload . isMultipartContent ()) { var fileItems = upload . parseRequest (); for ( i = 0 ; i < fileItems . size (); i ++ ) { var fileItem = fileItems . get ( i ); if ( ! fileItem . isFormField ()) { response . println ( \"File Name: \" + fileItem . getName ()); response . println ( \"File Bytes (as text): \" + String . fromCharCode . apply ( null , fileItem . getBytes ())); } else { response . println ( \"Field Name: \" + fileItem . getFieldName ()); response . println ( \"Field Text: \" + fileItem . getText ()); } } } else { response . println ( \"The request's content must be 'multipart'\" ); } } else if ( request . getMethod () === \"GET\" ) { response . println ( \"Use POST request.\" ); } response . flush (); response . close (); Then create a HTML5 page named my_upload.html Replace the content with the following HTML code:","title":"File Upload Handler"},{"location":"complex/file-upload/#file-upload-frontend","text":"< html > < body > < form action = \"/services/v4/js/file_upload_project/my_file_upload.js\" method = \"post\" enctype = \"multipart/form-data\" > < label for = \"file\" > Filename: </ label > < input type = \"file\" name = \"file\" id = \"file\" multiple > < br > < input type = \"submit\" name = \"submit\" value = \"Submit\" > </ form > </ body > </ html > Publish the project Select the my_upload.html file in the Workspace view and try to test by uploading a file in the Preview For more information, see the API documentation.","title":"File Upload Frontend"},{"location":"complex/job-console/","text":"Scheduled Job Steps Create a project job_console_project Then create a JavaScript service named my_job_handler.js Replace the service code with the following content: console . log ( \"Hello from My Job!\" ); Then create a Scheduled Job named my_job.job Replace the content with the following JSON code: { \"expression\" : \"0/10 * * * * ?\" , \"handler\" : \"job_console_project/my_job_handler.js\" , \"description\" : \"My Job\" } Publish the project After 10s in the Console view you should see the following lines: [2018-05-14T12:05:00.061Z] [INFO] Hello from My Job! Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Scheduled Job"},{"location":"complex/job-console/#scheduled-job","text":"","title":"Scheduled Job"},{"location":"complex/job-console/#steps","text":"Create a project job_console_project Then create a JavaScript service named my_job_handler.js Replace the service code with the following content: console . log ( \"Hello from My Job!\" ); Then create a Scheduled Job named my_job.job Replace the content with the following JSON code: { \"expression\" : \"0/10 * * * * ?\" , \"handler\" : \"job_console_project/my_job_handler.js\" , \"description\" : \"My Job\" } Publish the project After 10s in the Console view you should see the following lines: [2018-05-14T12:05:00.061Z] [INFO] Hello from My Job! Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Steps"},{"location":"complex/kafka/","text":"Kafka Producer and Counsmer Prerequisites Run a local Kafka server following the steps (1 and 2) from here: https://kafka.apache.org/quickstart Steps Create a project kafka_project Then create a JavaScript service named my_kafka_handler.js Replace the service code with the following content: Handler exports . onMessage = function ( message ) { console . log ( \"Hello from My Kafka Listener! Message: \" + message ); }; exports . onError = function ( error ) { console . error ( \"Error from My Kafka Listener! Error: \" + error ); }; Then create a Kafka Consumer named my_kafka_consumer.js Replace the file content with the following code: var consumer = require ( \"kafka/consumer\" ); consumer . topic ( \"topic1\" , \"{}\" ). startListening ( \"kafka_project/my_kafka_handler\" , 1000 ); Then create another back-end service which will play the role of a trigger my_kafka_producer.js Replace the trigger content with the following code: var producer = require ( \"kafka/producer\" ); producer . topic ( \"topic1\" , \"{}\" ). send ( \"key1\" , \"value1\" ); Publish the project Select the my_kafka_producer.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: 2020-11-01 23:33:54.272 [INFO ] [Thread-275] o.e.dirigible.api.v3.core.Console - Hello from My Kafka Listener! Message: {\"topic\":\"topic1\",\"partition\":0,\"offset\":29,\"timestamp\":1604266434251,\"timestampType\":\"CREATE_TIME\",\"serializedKeySize\":4,\"serializedValueSize\":6,\"headers\":{\"headers\":[],\"isReadOnly\":false},\"key\":\"key1\",\"value\":\"value1\",\"leaderEpoch\":{\"value\":0}} Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Kafka Producer and Consumer"},{"location":"complex/kafka/#kafka-producer-and-counsmer","text":"","title":"Kafka Producer and Counsmer"},{"location":"complex/kafka/#prerequisites","text":"Run a local Kafka server following the steps (1 and 2) from here: https://kafka.apache.org/quickstart","title":"Prerequisites"},{"location":"complex/kafka/#steps","text":"Create a project kafka_project Then create a JavaScript service named my_kafka_handler.js Replace the service code with the following content:","title":"Steps"},{"location":"complex/kafka/#handler","text":"exports . onMessage = function ( message ) { console . log ( \"Hello from My Kafka Listener! Message: \" + message ); }; exports . onError = function ( error ) { console . error ( \"Error from My Kafka Listener! Error: \" + error ); }; Then create a Kafka Consumer named my_kafka_consumer.js Replace the file content with the following code: var consumer = require ( \"kafka/consumer\" ); consumer . topic ( \"topic1\" , \"{}\" ). startListening ( \"kafka_project/my_kafka_handler\" , 1000 ); Then create another back-end service which will play the role of a trigger my_kafka_producer.js Replace the trigger content with the following code: var producer = require ( \"kafka/producer\" ); producer . topic ( \"topic1\" , \"{}\" ). send ( \"key1\" , \"value1\" ); Publish the project Select the my_kafka_producer.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: 2020-11-01 23:33:54.272 [INFO ] [Thread-275] o.e.dirigible.api.v3.core.Console - Hello from My Kafka Listener! Message: {\"topic\":\"topic1\",\"partition\":0,\"offset\":29,\"timestamp\":1604266434251,\"timestampType\":\"CREATE_TIME\",\"serializedKeySize\":4,\"serializedValueSize\":6,\"headers\":{\"headers\":[],\"isReadOnly\":false},\"key\":\"key1\",\"value\":\"value1\",\"leaderEpoch\":{\"value\":0}} Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Handler"},{"location":"complex/listener-queue/","text":"Listener of a Queue Steps Create a project message_queue_listener_project Then create a JavaScript service named my_listener_handler.js Replace the service code with the following content: Handler exports . onMessage = function ( message ) { console . log ( \"Hello from My Listener! Message: \" + message ); }; exports . onError = function ( error ) { console . error ( \"Error from My Listener! Error: \" + error ); }; Then create a Message Listener named my_listener.listener Replace the file content with the following JSON code: { \"name\" : \"message_queue_listener_project/my_queue\" , \"type\" : \"Q\" , \"handler\" : \"message_queue_listener_project/my_listener_handler.js\" , \"description\" : \"My Listener\" } Then create another back-end service which will play the role of a trigger my_trigger.js Replace the trigger content with the following code: var producer = require ( 'messaging/v3/producer' ); var message = \"*** I am a message created at: \" + new Date () + \" ***\" ; producer . queue ( \"message_queue_listener_project/my_queue\" ). send ( message ); console . log ( \"Hello from My Trigger! Message: \" + message ); Publish the project Select the my_trigger.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: [2018-05-14T11:57:13.197Z] [INFO] Hello from My Listener! Message: I am a message created at: Mon May 14 2018 14:57:13 GMT+0300 (EEST) [2018-05-14T11:57:13.174Z] [INFO] Hello from My Trigger! Message: I am a message created at: Mon May 14 2018 14:57:13 GMT+0300 (EEST) Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Listener of a Queue"},{"location":"complex/listener-queue/#listener-of-a-queue","text":"","title":"Listener of a Queue"},{"location":"complex/listener-queue/#steps","text":"Create a project message_queue_listener_project Then create a JavaScript service named my_listener_handler.js Replace the service code with the following content:","title":"Steps"},{"location":"complex/listener-queue/#handler","text":"exports . onMessage = function ( message ) { console . log ( \"Hello from My Listener! Message: \" + message ); }; exports . onError = function ( error ) { console . error ( \"Error from My Listener! Error: \" + error ); }; Then create a Message Listener named my_listener.listener Replace the file content with the following JSON code: { \"name\" : \"message_queue_listener_project/my_queue\" , \"type\" : \"Q\" , \"handler\" : \"message_queue_listener_project/my_listener_handler.js\" , \"description\" : \"My Listener\" } Then create another back-end service which will play the role of a trigger my_trigger.js Replace the trigger content with the following code: var producer = require ( 'messaging/v3/producer' ); var message = \"*** I am a message created at: \" + new Date () + \" ***\" ; producer . queue ( \"message_queue_listener_project/my_queue\" ). send ( message ); console . log ( \"Hello from My Trigger! Message: \" + message ); Publish the project Select the my_trigger.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: [2018-05-14T11:57:13.197Z] [INFO] Hello from My Listener! Message: I am a message created at: Mon May 14 2018 14:57:13 GMT+0300 (EEST) [2018-05-14T11:57:13.174Z] [INFO] Hello from My Trigger! Message: I am a message created at: Mon May 14 2018 14:57:13 GMT+0300 (EEST) Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Handler"},{"location":"complex/master-repository/","text":"Master Repository This sample will guide you how to run an Eclipse Dirigible instance with a pre-defined content. This content is bundled in a Zip file with a specific Repository structure. You can easily get one by exporting the Repository from an existing instance via the Snapshot view (in the Repository perspective). A sample content file with a single project with a single service you can find at: repository-snapshot-20180820034353.zip . Steps Copy the above zip file in a directory e.g. /home/dirigible/master_sample Download (or build and copy) to the same directory the standalone executable dirigible-desktop-all-XXX.jar Set the environment variables: export DIRIGIBLE_MASTER_REPOSITORY_PROVIDER=zip export DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION=/home/dirigible/master_sample/repository-snapshot-20180820034353.zip Run with: java -jar dirigible-desktop-all-XXX.jar Enter with the nickname: dirigible You should have already available project \"my_project\" in your workspace, with a service \"hello.js\" The service is even published already, so you can directly execute it by accessing the location: http://localhost:8080/services/v4/js/my_project/hello.js Note: This is the simplest way (from the life-cycle management PoV) to run an Eclipse Dirigible application. For the master repository you can use a Zip file (as it is shown above), File System based Repository located by a Path to its root folder or a Jar file built into or accessible by the default class loader.","title":"Master Repository"},{"location":"complex/master-repository/#master-repository","text":"This sample will guide you how to run an Eclipse Dirigible instance with a pre-defined content. This content is bundled in a Zip file with a specific Repository structure. You can easily get one by exporting the Repository from an existing instance via the Snapshot view (in the Repository perspective). A sample content file with a single project with a single service you can find at: repository-snapshot-20180820034353.zip .","title":"Master Repository"},{"location":"complex/master-repository/#steps","text":"Copy the above zip file in a directory e.g. /home/dirigible/master_sample Download (or build and copy) to the same directory the standalone executable dirigible-desktop-all-XXX.jar Set the environment variables: export DIRIGIBLE_MASTER_REPOSITORY_PROVIDER=zip export DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION=/home/dirigible/master_sample/repository-snapshot-20180820034353.zip Run with: java -jar dirigible-desktop-all-XXX.jar Enter with the nickname: dirigible You should have already available project \"my_project\" in your workspace, with a service \"hello.js\" The service is even published already, so you can directly execute it by accessing the location: http://localhost:8080/services/v4/js/my_project/hello.js Note: This is the simplest way (from the life-cycle management PoV) to run an Eclipse Dirigible application. For the master repository you can use a Zip file (as it is shown above), File System based Repository located by a Path to its root folder or a Jar file built into or accessible by the default class loader.","title":"Steps"},{"location":"complex/process-console/","text":"BPMN Process Steps Create a project bpmn_process_project Then create a JavaScript service named my_delegate.js with the following content: console . info ( \"Hello from the JavaScript Delegate!\" ); var process = require ( 'bpm/v4/process' ); var execution = process . getExecutionContext (); process . setVariable ( execution . getId (), 'variable2' , 'value2' ); try { console . info ( \"variable1: \" + process . getVariable ( execution . getId (), 'variable1' )); console . info ( \"variable2: \" + process . getVariable ( execution . getId (), 'variable2' )); } catch ( e ) { console . error ( e . message ); } Then create a Business Process Model (via the New popup menu) named my_process.bpmn Double-click on this file to open the corresponding BPMN editor. There should be shown on the diagram a Start Event , connected to a MyServiceTask , connected to an End Event . Select the MyServiceTask. In the Properties section below the diagram, find the Class fields property and click on it. In the Class fields dialog find and click on the field handler . Change its value from myproject/mydelegate.js to bpmn_process_project/my_delegate.js and click save. Click on the Save button on the top-left corner of the editor with Name - MyProcess and Key - myprocess Publish the project Then create a JavaScript service named my_trigger.js which will be used to start the just defined process Enter the following code in it: var process = require ( 'bpm/v4/process' ); process . start ( 'myprocess' , { \"variable1\" : \"value1\" }); Select the my_trigger.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: [2018-05-14T14:25:16.791Z] [DEBUG] Done starting a BPMN process by key: myprocess [2018-05-14T14:25:16.773Z] [INFO] variable2: value2 [2018-05-14T14:25:16.772Z] [INFO] variable1: value1 [2018-05-14T14:25:16.751Z] [INFO] Hello from the JavaScript Delegate! [2018-05-14T14:25:16.585Z] [DEBUG] Starting a BPMN process by key: myprocess Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"BPMN Process"},{"location":"complex/process-console/#bpmn-process","text":"","title":"BPMN Process"},{"location":"complex/process-console/#steps","text":"Create a project bpmn_process_project Then create a JavaScript service named my_delegate.js with the following content: console . info ( \"Hello from the JavaScript Delegate!\" ); var process = require ( 'bpm/v4/process' ); var execution = process . getExecutionContext (); process . setVariable ( execution . getId (), 'variable2' , 'value2' ); try { console . info ( \"variable1: \" + process . getVariable ( execution . getId (), 'variable1' )); console . info ( \"variable2: \" + process . getVariable ( execution . getId (), 'variable2' )); } catch ( e ) { console . error ( e . message ); } Then create a Business Process Model (via the New popup menu) named my_process.bpmn Double-click on this file to open the corresponding BPMN editor. There should be shown on the diagram a Start Event , connected to a MyServiceTask , connected to an End Event . Select the MyServiceTask. In the Properties section below the diagram, find the Class fields property and click on it. In the Class fields dialog find and click on the field handler . Change its value from myproject/mydelegate.js to bpmn_process_project/my_delegate.js and click save. Click on the Save button on the top-left corner of the editor with Name - MyProcess and Key - myprocess Publish the project Then create a JavaScript service named my_trigger.js which will be used to start the just defined process Enter the following code in it: var process = require ( 'bpm/v4/process' ); process . start ( 'myprocess' , { \"variable1\" : \"value1\" }); Select the my_trigger.js file in the Workspace view to be able to trigger the invocation of this service via the Preview view In the Console view you should see the following lines: [2018-05-14T14:25:16.791Z] [DEBUG] Done starting a BPMN process by key: myprocess [2018-05-14T14:25:16.773Z] [INFO] variable2: value2 [2018-05-14T14:25:16.772Z] [INFO] variable1: value1 [2018-05-14T14:25:16.751Z] [INFO] Hello from the JavaScript Delegate! [2018-05-14T14:25:16.585Z] [DEBUG] Starting a BPMN process by key: myprocess Note: the log messages in the Console view are in a reverse order - the newest are on top For more information, see the API documentation.","title":"Steps"},{"location":"complex/rbac-for-cms/","text":"RBAC for CMS This sample shows how to enable the Role Based Access Management for the Content Management System in Eclipse Dirigible. Steps Set the environment variable: export DIRIGIBLE_CMS_ROLES_ENABLED=true before staring the Dirigible instance Note: for SAP Cloud Platform Neo use the deploy parameter: -DDIRIGIBLE_CMS_ROLES_ENABLED=true Open Dirigible WebIDE and go to Documents perspective Create sub-folder \"private\" under the \"root\" folder Create sub-folder \"shared\" under the \"root\" folder Upload a text file named \"secret.txt\" under the \"private\" folder with the following content This is a top secret information accessible only by users with the role Operator! Upload a text file named \"billboard.txt\" under the \"shared\" folder with the following content This is a public notice accessible by Everyone. Click on Preview icon next to the files. You should be able to see the content of both of them. Open the Workspace perspective in the WebIDE Create a project named \"cms_permissions\" Create an *.access file via the popup menu New->Access Constraints Open the file with editor Delete the sample record Click New button Fill the form as follows: Path: /private Method: READ Scope: CMIS Roles: Operator Click Save button The content of the file should look like: { \"constraints\": [ { \"path\": \"/private\", \"method\": \"READ\", \"scope\": \"CMIS\", \"roles\": [ \"Operator\" ] } ] } Note: You can inspect that be closing the editor and then use Open With from the popup menu on the same file, but choosing Orion editor option Publish the project manually via the popup menu on the project level (in case the Auto-Publish is disabled) After a while open the Operations perspective and select the Access view You should be able to identify a line similar like this: /cms_permissions/private.access CMIS /private READ Operator Aug 17, 2018 3:33:00 PM guest Open the Preview of the file secret: http://localhost:8080/services/v3/js/ide-documents/api/read/document/preview?path=/private/secret.txt Only the users who has the role Operator should be able to see the content of the file","title":"RBAC for CMS"},{"location":"complex/rbac-for-cms/#rbac-for-cms","text":"This sample shows how to enable the Role Based Access Management for the Content Management System in Eclipse Dirigible.","title":"RBAC for CMS"},{"location":"complex/rbac-for-cms/#steps","text":"Set the environment variable: export DIRIGIBLE_CMS_ROLES_ENABLED=true before staring the Dirigible instance Note: for SAP Cloud Platform Neo use the deploy parameter: -DDIRIGIBLE_CMS_ROLES_ENABLED=true Open Dirigible WebIDE and go to Documents perspective Create sub-folder \"private\" under the \"root\" folder Create sub-folder \"shared\" under the \"root\" folder Upload a text file named \"secret.txt\" under the \"private\" folder with the following content This is a top secret information accessible only by users with the role Operator! Upload a text file named \"billboard.txt\" under the \"shared\" folder with the following content This is a public notice accessible by Everyone. Click on Preview icon next to the files. You should be able to see the content of both of them. Open the Workspace perspective in the WebIDE Create a project named \"cms_permissions\" Create an *.access file via the popup menu New->Access Constraints Open the file with editor Delete the sample record Click New button Fill the form as follows: Path: /private Method: READ Scope: CMIS Roles: Operator Click Save button The content of the file should look like: { \"constraints\": [ { \"path\": \"/private\", \"method\": \"READ\", \"scope\": \"CMIS\", \"roles\": [ \"Operator\" ] } ] } Note: You can inspect that be closing the editor and then use Open With from the popup menu on the same file, but choosing Orion editor option Publish the project manually via the popup menu on the project level (in case the Auto-Publish is disabled) After a while open the Operations perspective and select the Access view You should be able to identify a line similar like this: /cms_permissions/private.access CMIS /private READ Operator Aug 17, 2018 3:33:00 PM guest Open the Preview of the file secret: http://localhost:8080/services/v3/js/ide-documents/api/read/document/preview?path=/private/secret.txt Only the users who has the role Operator should be able to see the content of the file","title":"Steps"},{"location":"complex/shell-command/","text":"Shell Command Steps Create a project shell_command_project Then create a file named my_command.sh Replace the code with the following content: uname -an echo variable1=$variable1 Then create a Command named my_command.command Replace the content with the following JSON code: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" :[ { \"os\" : \"mac\" , \"command\" : \"sh shell_command_project/my_command.sh\" }, { \"os\" : \"linux\" , \"command\" : \"sh shell_command_project/my_command.sh\" } ], \"set\" :{ \"variable1\" : \"value1\" }, \"unset\" :[ \"variable2\" ] } Publish the project Select the *.command file in the Workspace explorer and inspect the result in the Preview: Darwin XXXXXXXXXXXXX 17.7.0 Darwin Kernel Version 17.7.0: Thu Jun 21 22:53:14 PDT 2018; root:xnu-4570.71.2~1/RELEASE_X86_64 x86_64 variable1=value1 Note: The working folder is set to the registry/public space under the file-based Repository. You can execute an arbitrary command e.g. even Node, Python, Julia, etc., by using the dirigible projects' content published and available under the registry space. For this case the given framework has to be setup in advance and the entry point executable to be added to the PATH environment variable. The standard output is redirected to the service response. For more information, see the API documentation.","title":"Shell Command"},{"location":"complex/shell-command/#shell-command","text":"","title":"Shell Command"},{"location":"complex/shell-command/#steps","text":"Create a project shell_command_project Then create a file named my_command.sh Replace the code with the following content: uname -an echo variable1=$variable1 Then create a Command named my_command.command Replace the content with the following JSON code: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" :[ { \"os\" : \"mac\" , \"command\" : \"sh shell_command_project/my_command.sh\" }, { \"os\" : \"linux\" , \"command\" : \"sh shell_command_project/my_command.sh\" } ], \"set\" :{ \"variable1\" : \"value1\" }, \"unset\" :[ \"variable2\" ] } Publish the project Select the *.command file in the Workspace explorer and inspect the result in the Preview: Darwin XXXXXXXXXXXXX 17.7.0 Darwin Kernel Version 17.7.0: Thu Jun 21 22:53:14 PDT 2018; root:xnu-4570.71.2~1/RELEASE_X86_64 x86_64 variable1=value1 Note: The working folder is set to the registry/public space under the file-based Repository. You can execute an arbitrary command e.g. even Node, Python, Julia, etc., by using the dirigible projects' content published and available under the registry space. For this case the given framework has to be setup in advance and the entry point executable to be added to the PATH environment variable. The standard output is redirected to the service response. For more information, see the API documentation.","title":"Steps"},{"location":"includes/","text":"Setup in Tomcat Deploy Eclipse Dirigible in Apache Tomcat web container. In this case the built-in H2 database is used. Prerequisites Download the Tomcat binary . More information about how to deploy on Tomcat can be found here . JDK 11 or JDK 13 - OpenJDK versions can be found here . macOS Linux Windows Install ttyd : brew install ttyd Linux support is built-in. More info about ttyd can be found at: ttyd You may experience certain functional limitations, if you decide to run the Web IDE locally on Windows using Tomcat: Limitations related to the Create symbolic links policy . Some tests in local builds of Dirigible may fail on Windows due to the same policy restriction. You may grant your user account access to create symbolic links by editing the policy: Go to (WIN + R) > gpedit.msc Navigate to: Computer Configuration -> Windows Settings -> Security Settings -> Local Policies -> User Rights Assignment -> Create Symbolic links . Add your Windows user account to the policy. Note : Editing this policy may make your machine vulnerable to symbolic link attacks as noted here . Alternative of the Windows setup would be to follow the Setup as a Docker Image . Steps Download ROOT.war for Tomcat from: download.dirigible.io Note For local test & development purposes, we recommend the server-all distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the Dirigible's ROOT.war to $TOMCAT/webapps folder. Configure the target Database setup, if needed: Local (H2) PostgreSQL MySQL HANA Sybase ASE No additional setup is needed. Install postgresql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Create a default database for Eclipse Dirigible: sudo -i -u postgres createdb dirigible_database Create a system user for the Eclipse Dirigible database: psql dirigible_database create user dirigible_system with password 'dirigible1234'; grant all on database dirigible_database to dirigible_system; Datasource configuration: Download the postgresql JDBC driver version 4.1 from here . Copy the postgresql-*.jar file to the <TOMCAT_HOME>/lib directory. Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=POSTGRES export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=POSTGRES export POSTGRES_DRIVER=org.postgresql.Driver export POSTGRES_URL=jdbc:postgresql://localhost:5432/dirigible_database export POSTGRES_USERNAME=dirigible_system export POSTGRES_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=org.postgresql.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:postgresql://localhost:5432/dirigible_database export DIRIGIBLE_SCHEDULER_DATABASE_USER=dirigible_system export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=true export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=true export DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE=true Install mysql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install mysql-server sudo mysql\\_install\\_db sudo /usr/bin/mysql\\_secure\\_installation Create the default database for Dirigible: sudo -i -u postgres createdb dirigible_database Create a system user for the Eclipse Dirigible database: mysql -u root -p CREATE DATABASE dirigible_database; CREATE USER 'dirigible_system'@'localhost' IDENTIFIED BY 'dirigible1234'; GRANT ALL PRIVILEGES ON dirigible_database.* TO 'dirigible_system'@'localhost' WITH GRANT OPTION; Datasource configuration: Download the mysql JDBC driver version 5.1 from here . Copy the mysql-*.jar file to the <TOMCAT_HOME>/lib directory. Open the file <TOMCAT_HOME>/conf/context.xml and add the following within the context: <Resource name= \"jdbc/DefaultDB\" auth= \"Container\" type= \"javax.sql.DataSource\" maxActive= \"100\" maxIdle= \"30\" maxWait= \"10000\" username= \"dirigible_system\" password= \"dirigible1234\" driverClassName= \"com.mysql.jdbc.Driver\" url= \"jdbc:mysql://localhost:3306/dirigible_database?useUnicode=true&amp;characterEncoding=UTF-8\" /> web.xml - make sure the initial parameter jndiDefaultDataSource is uncommented: <init-param> <param-name> jndiDefaultDataSource </param-name> <param-value> java:comp/env/jdbc/DefaultDB </param-value> </init-param> Also, the initial parameter jdbcAutoCommit must be set to false (by default). <init-param> <param-name> jdbcAutoCommit </param-name> <param-value> false </param-value> </init-param> The type of the datasource is jndi instead of local . <init-param> <param-name> defaultDataSourceType </param-name> <param-value> jndi </param-value> </init-param> Lastly, the resource reference for the datasource has to be uncommented. <resource-ref> <res-ref-name> jdbc/DefaultDB </res-ref-name> <res-type> javax.sql.DataSource </res-type> <res-auth> Container </res-auth> </resource-ref> Install HANA Express . Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<host>:<port> export HANA_USERNAME=<user> export HANA_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sap.db.jdbc.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:sap://<host>:<port> export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=false Remember to replace the <host> , <port> , <user> , <password> placeholders. How to setup a test environment on Amazon: Select Image Size: t2.medium Security Group: TCP Custom, 5000 Download Sybase ASE Express from here . Transfer: scp -i dirigible-aws.pem ASE_Suite.linuxamd64.tgz ec2-user@<ip-address>:~ scp -i dirigible-aws.pem apache-tomcat-XXX.zip ec2-user@<ip-address>:~ scp -i dirigible-aws.pem ROOT.war ec2-user@<ip-address>:~ scp -i dirigible-aws.pem jdk-8u144-linux-x64.tar.gz ec2-user@<ip-address>:~ Prepare OS: sudo mkdir -p /opt/sybase sudo mkdir -p /var/sybase sudo groupadd sybase sudo useradd -g sybase -d /opt/sybase sybase sudo passwd sybase sudo chown sybase:sybase /opt/sybase sudo chown sybase:sybase /var/sybase Login: ssh ec2-user@<ip-address> -i dirigible-aws.pem Setup: su - sybase mkdir install cd install cp /home/ec2-user/ASE_Suite.linuxamd64.tgz . tar -xvf ASE_Suite.linuxamd64.tgz ./setup.bin -i console Parameters: Choose Install Folder -> use: /opt/sybase Choose Install Set -> 1- Typical Software License Type Selection -> 2- Install Express Edition of SAP Adaptive Server Enterprise End-user License Agreement -> 1) All regions Configure New Servers -> [X] 1 - Configure new SAP ASE Configure Servers with Different User Account -> 2- No SAP ASE Name ASE160 System Administrator's Password ****** Enable SAP ASE for SAP ASE Cockpit monitoring false Technical user tech_user Technical user password ******** Host Name ip-<internal-ip-address>.eu-central-1.comp Port Number 5000 Application Type Mixed (OLTP/DSS) Create sample databases false Page Size 4k Error Log /opt/sybase/ASE-16_0/install/ASE1 Default Language <use default> Default Character Set <use default> Default Sort Order <use default> Master Device /opt/sybase/data/master.dat Master Device Size (MB) 500 Master Database Size (MB) 250 System Procedure Device /opt/sybase/data/sysprocs.dat System Procedure Device Size (MB) 500 System Procedure Database Size (MB) 500 System Device /opt/sybase/data/sybsysdb.dat System Device Size (MB) 100 System Database Size (MB) 100 Tempdb Device /opt/sybase/data/tempdbdev.dat Tempdb Device Size (MB) 1000 Tempdb Database Size (MB) 1000 Enable PCI false Optimize SAP ASE Configuration false Show Servers: /opt/sybase/ASE-16_0/install/showserver Prepare Test Environment: cd /opt/sybase/install cp /home/ec2-user/apache-tomcat-XXX.zip . cp /home/ec2-user/jdk-8u144-linux-x64.tar.gz . unzip apache-tomcat-XXX.zip tar -xvf jdk-8u144-linux-x64.tar.gz export JAVA_HOME=/opt/sybase/install/jdk1.8.0_144 Add the provided JDBC driver to the lib folder: cp /opt/sybase/shared/lib/jconn4.jar /home/ec2-user/apache-tomcat-XXX/lib Useful actions in case of issues: Start Server: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/sybase/OCS-16_0/lib3p64 export LANG=C cd /opt/sybase/ASE-16_0/bin ./startserver -f /opt/sybase/ASE-16_0/install/RUN_ASE160 Stop Server: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 shutdown with nowait go Kill Hanging Requests: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 sp_who go kill spid Uninstall: cd /opt/sybase/sybuninstall/ASESuite ./uninstall -i console Set the environment variables export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=SYBASE export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=SYBASE export SYBASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export SYBASE_URL=jdbc:sybase:Tds:<host>:<port>?ServiceName=<database> export SYBASE_USERNAME=<user> export SYBASE_PASSWORD=<password> export SYBASE_CONNECTION_PROPERTIES=\"DYNAMIC_PREPARE=true;SSL_TRUST_ALL_CERTS=true;JCONNECT_VERSION=0;ENABLE_SSL=true;\" export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export DIRIGIBLE_SCHEDULER_DATABASE_URL=\"jdbc:sybase:Tds:<host>:<port>?ServiceName=<database>&DYNAMIC_PREPARE=true&JCONNECT_VERSION=0&ENABLE_SSL=true&SSL_TRUST_ALL_CERTS=true\" export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.SybaseDelegate Remember to replace the <host> , <port> , <user> , <password> placeholders._ Start the Tomcat server. Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible Manager App In case you want to use Apache Tomcat's Manager App to deploy the ROOT.war file, you have to increase the file size limit for upload (e.g. to 200MB): conf\\server.xml <Connector port= \"8080\" protocol= \"HTTP/1.1\" connectionTimeout= \"20000\" redirectPort= \"8443\" maxPostSize= \"209715200\" /> webapps\\manager\\WEB-INF\\web.xml <web-app> ... <servlet> ... <multipart-config> <file-size-threshold> 0 </file-size-threshold> <max-file-size> 209715200 </max-file-size> <max-request-size> 209715200 </max-request-size> </multipart-config> ... </servlet> ... </web-app>","title":"Tomcat"},{"location":"includes/#setup-in-tomcat","text":"Deploy Eclipse Dirigible in Apache Tomcat web container. In this case the built-in H2 database is used. Prerequisites Download the Tomcat binary . More information about how to deploy on Tomcat can be found here . JDK 11 or JDK 13 - OpenJDK versions can be found here . macOS Linux Windows Install ttyd : brew install ttyd Linux support is built-in. More info about ttyd can be found at: ttyd You may experience certain functional limitations, if you decide to run the Web IDE locally on Windows using Tomcat: Limitations related to the Create symbolic links policy . Some tests in local builds of Dirigible may fail on Windows due to the same policy restriction. You may grant your user account access to create symbolic links by editing the policy: Go to (WIN + R) > gpedit.msc Navigate to: Computer Configuration -> Windows Settings -> Security Settings -> Local Policies -> User Rights Assignment -> Create Symbolic links . Add your Windows user account to the policy. Note : Editing this policy may make your machine vulnerable to symbolic link attacks as noted here . Alternative of the Windows setup would be to follow the Setup as a Docker Image .","title":"Setup in Tomcat"},{"location":"includes/#steps","text":"Download ROOT.war for Tomcat from: download.dirigible.io Note For local test & development purposes, we recommend the server-all distribution. Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the Dirigible's ROOT.war to $TOMCAT/webapps folder. Configure the target Database setup, if needed: Local (H2) PostgreSQL MySQL HANA Sybase ASE No additional setup is needed. Install postgresql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Create a default database for Eclipse Dirigible: sudo -i -u postgres createdb dirigible_database Create a system user for the Eclipse Dirigible database: psql dirigible_database create user dirigible_system with password 'dirigible1234'; grant all on database dirigible_database to dirigible_system; Datasource configuration: Download the postgresql JDBC driver version 4.1 from here . Copy the postgresql-*.jar file to the <TOMCAT_HOME>/lib directory. Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=POSTGRES export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=POSTGRES export POSTGRES_DRIVER=org.postgresql.Driver export POSTGRES_URL=jdbc:postgresql://localhost:5432/dirigible_database export POSTGRES_USERNAME=dirigible_system export POSTGRES_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=org.postgresql.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:postgresql://localhost:5432/dirigible_database export DIRIGIBLE_SCHEDULER_DATABASE_USER=dirigible_system export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=true export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=true export DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE=true Install mysql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install mysql-server sudo mysql\\_install\\_db sudo /usr/bin/mysql\\_secure\\_installation Create the default database for Dirigible: sudo -i -u postgres createdb dirigible_database Create a system user for the Eclipse Dirigible database: mysql -u root -p CREATE DATABASE dirigible_database; CREATE USER 'dirigible_system'@'localhost' IDENTIFIED BY 'dirigible1234'; GRANT ALL PRIVILEGES ON dirigible_database.* TO 'dirigible_system'@'localhost' WITH GRANT OPTION; Datasource configuration: Download the mysql JDBC driver version 5.1 from here . Copy the mysql-*.jar file to the <TOMCAT_HOME>/lib directory. Open the file <TOMCAT_HOME>/conf/context.xml and add the following within the context: <Resource name= \"jdbc/DefaultDB\" auth= \"Container\" type= \"javax.sql.DataSource\" maxActive= \"100\" maxIdle= \"30\" maxWait= \"10000\" username= \"dirigible_system\" password= \"dirigible1234\" driverClassName= \"com.mysql.jdbc.Driver\" url= \"jdbc:mysql://localhost:3306/dirigible_database?useUnicode=true&amp;characterEncoding=UTF-8\" /> web.xml - make sure the initial parameter jndiDefaultDataSource is uncommented: <init-param> <param-name> jndiDefaultDataSource </param-name> <param-value> java:comp/env/jdbc/DefaultDB </param-value> </init-param> Also, the initial parameter jdbcAutoCommit must be set to false (by default). <init-param> <param-name> jdbcAutoCommit </param-name> <param-value> false </param-value> </init-param> The type of the datasource is jndi instead of local . <init-param> <param-name> defaultDataSourceType </param-name> <param-value> jndi </param-value> </init-param> Lastly, the resource reference for the datasource has to be uncommented. <resource-ref> <res-ref-name> jdbc/DefaultDB </res-ref-name> <res-type> javax.sql.DataSource </res-type> <res-auth> Container </res-auth> </resource-ref> Install HANA Express . Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<host>:<port> export HANA_USERNAME=<user> export HANA_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sap.db.jdbc.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:sap://<host>:<port> export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=false Remember to replace the <host> , <port> , <user> , <password> placeholders. How to setup a test environment on Amazon: Select Image Size: t2.medium Security Group: TCP Custom, 5000 Download Sybase ASE Express from here . Transfer: scp -i dirigible-aws.pem ASE_Suite.linuxamd64.tgz ec2-user@<ip-address>:~ scp -i dirigible-aws.pem apache-tomcat-XXX.zip ec2-user@<ip-address>:~ scp -i dirigible-aws.pem ROOT.war ec2-user@<ip-address>:~ scp -i dirigible-aws.pem jdk-8u144-linux-x64.tar.gz ec2-user@<ip-address>:~ Prepare OS: sudo mkdir -p /opt/sybase sudo mkdir -p /var/sybase sudo groupadd sybase sudo useradd -g sybase -d /opt/sybase sybase sudo passwd sybase sudo chown sybase:sybase /opt/sybase sudo chown sybase:sybase /var/sybase Login: ssh ec2-user@<ip-address> -i dirigible-aws.pem Setup: su - sybase mkdir install cd install cp /home/ec2-user/ASE_Suite.linuxamd64.tgz . tar -xvf ASE_Suite.linuxamd64.tgz ./setup.bin -i console Parameters: Choose Install Folder -> use: /opt/sybase Choose Install Set -> 1- Typical Software License Type Selection -> 2- Install Express Edition of SAP Adaptive Server Enterprise End-user License Agreement -> 1) All regions Configure New Servers -> [X] 1 - Configure new SAP ASE Configure Servers with Different User Account -> 2- No SAP ASE Name ASE160 System Administrator's Password ****** Enable SAP ASE for SAP ASE Cockpit monitoring false Technical user tech_user Technical user password ******** Host Name ip-<internal-ip-address>.eu-central-1.comp Port Number 5000 Application Type Mixed (OLTP/DSS) Create sample databases false Page Size 4k Error Log /opt/sybase/ASE-16_0/install/ASE1 Default Language <use default> Default Character Set <use default> Default Sort Order <use default> Master Device /opt/sybase/data/master.dat Master Device Size (MB) 500 Master Database Size (MB) 250 System Procedure Device /opt/sybase/data/sysprocs.dat System Procedure Device Size (MB) 500 System Procedure Database Size (MB) 500 System Device /opt/sybase/data/sybsysdb.dat System Device Size (MB) 100 System Database Size (MB) 100 Tempdb Device /opt/sybase/data/tempdbdev.dat Tempdb Device Size (MB) 1000 Tempdb Database Size (MB) 1000 Enable PCI false Optimize SAP ASE Configuration false Show Servers: /opt/sybase/ASE-16_0/install/showserver Prepare Test Environment: cd /opt/sybase/install cp /home/ec2-user/apache-tomcat-XXX.zip . cp /home/ec2-user/jdk-8u144-linux-x64.tar.gz . unzip apache-tomcat-XXX.zip tar -xvf jdk-8u144-linux-x64.tar.gz export JAVA_HOME=/opt/sybase/install/jdk1.8.0_144 Add the provided JDBC driver to the lib folder: cp /opt/sybase/shared/lib/jconn4.jar /home/ec2-user/apache-tomcat-XXX/lib Useful actions in case of issues: Start Server: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/sybase/OCS-16_0/lib3p64 export LANG=C cd /opt/sybase/ASE-16_0/bin ./startserver -f /opt/sybase/ASE-16_0/install/RUN_ASE160 Stop Server: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 shutdown with nowait go Kill Hanging Requests: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 sp_who go kill spid Uninstall: cd /opt/sybase/sybuninstall/ASESuite ./uninstall -i console Set the environment variables export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=SYBASE export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=SYBASE export SYBASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export SYBASE_URL=jdbc:sybase:Tds:<host>:<port>?ServiceName=<database> export SYBASE_USERNAME=<user> export SYBASE_PASSWORD=<password> export SYBASE_CONNECTION_PROPERTIES=\"DYNAMIC_PREPARE=true;SSL_TRUST_ALL_CERTS=true;JCONNECT_VERSION=0;ENABLE_SSL=true;\" export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export DIRIGIBLE_SCHEDULER_DATABASE_URL=\"jdbc:sybase:Tds:<host>:<port>?ServiceName=<database>&DYNAMIC_PREPARE=true&JCONNECT_VERSION=0&ENABLE_SSL=true&SSL_TRUST_ALL_CERTS=true\" export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.SybaseDelegate Remember to replace the <host> , <port> , <user> , <password> placeholders._ Start the Tomcat server. Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible","title":"Steps"},{"location":"includes/#manager-app","text":"In case you want to use Apache Tomcat's Manager App to deploy the ROOT.war file, you have to increase the file size limit for upload (e.g. to 200MB): conf\\server.xml <Connector port= \"8080\" protocol= \"HTTP/1.1\" connectionTimeout= \"20000\" redirectPort= \"8443\" maxPostSize= \"209715200\" /> webapps\\manager\\WEB-INF\\web.xml <web-app> ... <servlet> ... <multipart-config> <file-size-threshold> 0 </file-size-threshold> <max-file-size> 209715200 </max-file-size> <max-request-size> 209715200 </max-request-size> </multipart-config> ... </servlet> ... </web-app>","title":"Manager App"},{"location":"includes/cloud-foundry/","text":"Setup in Cloud Foundry Deploy Eclipse Dirigible in SAP BTP[^1], Cloud Foundry environment. [^1]: SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. Prerequisites Install Cloud Foundry Command Line Interface . Access to SAP BTP account (the Trial landscape can be accessed here ). Steps Set the SAP BTP Cloud Foundry API host: cf api <cloud-foundry-api-host> Log in to the SAP BTP, Cloud Foundry environment with: cf login Create XSUAA service instance: Copy and paste the following content into xs-security.json : { \"xsappname\" : \"<applicationName>-xsuaa\" , \"tenant-mode\" : \"shared\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"Dirigible Developer\" , \"description\" : \"Dirigible Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Dirigible Operator\" , \"description\" : \"Dirigible Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <applicationName> placeholder with your application name, e.g. dirigible . Create a XSUAA service instance: cf create-service xsuaa application <applicationName>-xsuaa -c xs-security.json Note Use the same <applicationName> as in the previous step. Deploy Eclipse Dirigible: Docker Buildpack cf push dirigible \\ --docker-image=dirigiblelabs/dirigible-sap-cf:latest \\ --hostname dirigible-<org-name> \\ -m 2G -k 2G Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Bind the XSUAA service instance to the Eclipse Dirigible deployment: cf bind-service dirigible <applicationName>-xsuaa Note Replace the <applicationName> placeholder with the application name used in the previous steps. Restart the dirigible deployment: cf restart dirigible Download the sap-cf-all binaries from the downloads site: download.dirigible.io Unzip the downloaded archieve to extract the ROOT.war file. Create manifest.yaml file in the same directory where the ROOT.war is located: applications : - name : dirigible host : dirigible-<org-name> memory : 2G buildpack : sap_java_buildpack path : ROOT.war env : JBP_CONFIG_COMPONENTS : \"jres: ['com.sap.xs.java.buildpack.jdk.SAPMachineJDK']\" JBP_CONFIG_SAP_MACHINE_JRE : 'jre: { version: 11.+ }' services : - <applicationName>-xsuaa Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Replace the <applicationName> placeholder with the application name used in the previous steps. Deploy with: cf push Assign the Developer and Operator roles. Log in. Additional Materials Step-by-step tutorial can be found here .","title":"Cloud Foundry"},{"location":"includes/cloud-foundry/#setup-in-cloud-foundry","text":"Deploy Eclipse Dirigible in SAP BTP[^1], Cloud Foundry environment. [^1]: SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. Prerequisites Install Cloud Foundry Command Line Interface . Access to SAP BTP account (the Trial landscape can be accessed here ).","title":"Setup in Cloud Foundry"},{"location":"includes/cloud-foundry/#steps","text":"Set the SAP BTP Cloud Foundry API host: cf api <cloud-foundry-api-host> Log in to the SAP BTP, Cloud Foundry environment with: cf login Create XSUAA service instance: Copy and paste the following content into xs-security.json : { \"xsappname\" : \"<applicationName>-xsuaa\" , \"tenant-mode\" : \"shared\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"Dirigible Developer\" , \"description\" : \"Dirigible Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Dirigible Operator\" , \"description\" : \"Dirigible Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <applicationName> placeholder with your application name, e.g. dirigible . Create a XSUAA service instance: cf create-service xsuaa application <applicationName>-xsuaa -c xs-security.json Note Use the same <applicationName> as in the previous step. Deploy Eclipse Dirigible: Docker Buildpack cf push dirigible \\ --docker-image=dirigiblelabs/dirigible-sap-cf:latest \\ --hostname dirigible-<org-name> \\ -m 2G -k 2G Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Bind the XSUAA service instance to the Eclipse Dirigible deployment: cf bind-service dirigible <applicationName>-xsuaa Note Replace the <applicationName> placeholder with the application name used in the previous steps. Restart the dirigible deployment: cf restart dirigible Download the sap-cf-all binaries from the downloads site: download.dirigible.io Unzip the downloaded archieve to extract the ROOT.war file. Create manifest.yaml file in the same directory where the ROOT.war is located: applications : - name : dirigible host : dirigible-<org-name> memory : 2G buildpack : sap_java_buildpack path : ROOT.war env : JBP_CONFIG_COMPONENTS : \"jres: ['com.sap.xs.java.buildpack.jdk.SAPMachineJDK']\" JBP_CONFIG_SAP_MACHINE_JRE : 'jre: { version: 11.+ }' services : - <applicationName>-xsuaa Note Replace the <org-name> placeholder with your subaccount's Subdomain value. Replace the <applicationName> placeholder with the application name used in the previous steps. Deploy with: cf push Assign the Developer and Operator roles. Log in. Additional Materials Step-by-step tutorial can be found here .","title":"Steps"},{"location":"includes/docker/","text":"Setup as a Docker Image Deploy Eclipse Dirigible in Docker. Prerequisites Install Docker . Steps Pull the Dirigible Docker image: docker pull dirigiblelabs/dirigible-all:latest Start the container: Run with Mounted Volume with Environment Configurations with Java Debugging Options docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest docker run --name dirigible \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest docker run --name dirigible \\ -e DIRIGIBLE_BRANDING_NAME=\"My Web IDE\" \\ -e DIRIGIBLE_BRANDING_BRAND=\"WebIDE\" \\ -e DIRIGIBLE_BRANDING_BRAND_URL=\"https://www.eclipse.org\" \\ -e DIRIGIBLE_THEME_DEFAULT=\"fiori\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Note The complete list of Dirigible environment variables could be found here . docker run --name dirigible \\ -e JPDA_ADDRESS=0.0.0.0:8000 \\ -e JPDA_TRANSPORT=dt_socket \\ --rm -p 8000:8000 -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible Stop the container: docker stop dirigible Contribution Optionally, you can enhance and customize the Dockerfile artifacts from here , or any of the other Docker releases: anonymous-all anonymous-runtime openshift-all sap-cf-all sap-cf-runtime sap-kyma-all sap-kyma-runtime server-all server-runtime server-keycloak-all server-runtime-keycloak trial-all Note: Most of the packages contains two files: Dockerfile-base and Dockerfile . Usually you would want to extend the Dockerfile , except in some special cases.","title":"Docker"},{"location":"includes/docker/#setup-as-a-docker-image","text":"Deploy Eclipse Dirigible in Docker. Prerequisites Install Docker .","title":"Setup as a Docker Image"},{"location":"includes/docker/#steps","text":"Pull the Dirigible Docker image: docker pull dirigiblelabs/dirigible-all:latest Start the container: Run with Mounted Volume with Environment Configurations with Java Debugging Options docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest docker run --name dirigible \\ -v <your-local-directory>:/usr/local/tomcat/target \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest docker run --name dirigible \\ -e DIRIGIBLE_BRANDING_NAME=\"My Web IDE\" \\ -e DIRIGIBLE_BRANDING_BRAND=\"WebIDE\" \\ -e DIRIGIBLE_BRANDING_BRAND_URL=\"https://www.eclipse.org\" \\ -e DIRIGIBLE_THEME_DEFAULT=\"fiori\" \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Note The complete list of Dirigible environment variables could be found here . docker run --name dirigible \\ -e JPDA_ADDRESS=0.0.0.0:8000 \\ -e JPDA_TRANSPORT=dt_socket \\ --rm -p 8000:8000 -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Open a web browser and go to: http://localhost:8080/ Note The default user name and password are dirigible/dirigible Stop the container: docker stop dirigible Contribution Optionally, you can enhance and customize the Dockerfile artifacts from here , or any of the other Docker releases: anonymous-all anonymous-runtime openshift-all sap-cf-all sap-cf-runtime sap-kyma-all sap-kyma-runtime server-all server-runtime server-keycloak-all server-runtime-keycloak trial-all Note: Most of the packages contains two files: Dockerfile-base and Dockerfile . Usually you would want to extend the Dockerfile , except in some special cases.","title":"Steps"},{"location":"includes/helm/","text":"Setup with Helm You can deploy Dirigible via Helm Chart in a Kubernetes cluster. Prerequisites Helm Kubernetes Cluster on IaaS provider of your choice Steps Add the Eclipse Dirigible Helm repository: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update Verify Eclipse Dirigible Helm chart: helm pull dirigible/dirigible --prov curl -o ~/.gnupg/pubring.gpg https://eclipse.github.io/dirigible/charts/pubring.gpg helm verify dirigible-<version>.tgz You shoul see message: Signed by: Using Key With Fingerprint: Chart Hash Verified: Basic: helm install dirigible dirigible/dirigible Access This will install Eclipse Dirigible Deployment and Service with ClusterIP only. To access the Dirigible instance execute the command that was printed in the console. Example: export POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/name=dirigible,app.kubernetes.io/instance=dirigible\" -o jsonpath=\"{.items[0].metadata.name}\") echo \"Visit http://127.0.0.1:8080 to use your application\" kubectl --namespace default port-forward $POD_NAME 8080:8080 Navigate to: http://127.0.0.1:8080 Login with: dirigible / dirigible Kubernetes: Basic Istio PostgreSQL PostgreSQL & Keycloak helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> This will expose the Dirigible instance through Ingress host ( http://... ). Prerequisites Install Istio . kubectl label namespace default istio-injection=enabled helm install dirigible dirigible/dirigible \\ --set istio.enabled=true This will install Eclipse Dirigible Deployment , Service with ClusterIP only and Istio Gateway and Virtual Service . To access the Dirigible instance execute the command that was printed in the console. kubectl get svc istio-ingressgateway -n istio-system \\ -o jsonpath=\"{.status.loadBalancer.ingress[*].hostname}\" helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> \\ --set database.enabled=true This will install also PostgreSQL database with 1Gi storage and update the Dirigible datasource configuration to consume the database. helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> \\ --set database.enabled=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true In addition Keycloak will be deployed and configured. Disable HTTPS In some cases you might want to disable the \"Required HTTPS\" for Keycloak. Login to the PostgreSQL Pod: kubectl exec -it keycloak-database-<pod-uuid> /bin/bash Connect to the keycloak database: psql --u keycloak Set the ssl_required to NONE : update REALM set ssl_required='NONE' where id = 'master'; Restart the Keycloak pod to apply the updated configuration: kubectl delete pod keycloak-<pod-uuid> Now the Required HTTPS should be disabled and the keycloak instance should be accessible via http:// Kyma: Basic PostgreSQL PostgreSQL & Keycloak helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding . The appropriate roles should be assigned to the user. helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> \\ --set database.enabled=true This will install also PostgreSQL database with 1Gi storage and update the Dirigible datasource configuration to consume the database. helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> \\ --set database.enabled=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true In addition Keycloak will be deployed and configured. Disable HTTPS In some cases you might want to disable the \"Required HTTPS\" for Keycloak. Login to the PostgreSQL Pod: kubectl exec -it keycloak-database-<pod-uuid> /bin/bash Connect to the keycloak database: psql --u keycloak Set the ssl_required to NONE : update REALM set ssl_required='NONE' where id = 'master'; Restart the Keycloak pod to apply the updated configuration: kubectl delete pod keycloak-<pod-uuid> Now the Required HTTPS should be disabled and the keycloak instance should be accessible via http:// Uninstall: helm uninstall dirigible Configuration The following table lists all the configurable parameters expose by the Dirigible chart and their default values. Generic Name Description Default dirigible.image Custom Dirigible image \"\" image.repository Dirigible image repo dirigiblelabs/dirigible-all image.repositoryKyma Dirigible Kyma image repo dirigiblelabs/dirigible-sap-kyma image.repositoryKeycloak Dirigible Keycloak image repo dirigiblelabs/dirigible-keycloak image.pullPolicy Image pull policy IfNotPresent service.type Service type ClusterIP service.port Service port 8080 replicaCount Number of replicas 1 imagePullSecrets Image pull secrets [] nameOverride Name override \"\" fullnameOverride Fullname override \"\" podSecurityContext Pod security context {} nodeSelector Node selector {} tolerations Tolerations [] affinity Affinity {} resources Resources {} Basic Name Description Default volume.enabled Volume to be mounted true volume.storage Volume storage size 1Gi database.enabled Database to be deployed false database.image Database image postgres:13 database.driver Database JDBC driver org.postgresql.Driver database.storage Database storage size 1Gi database.username Database username dirigible database.password Database password dirigible ingress.enabled Ingress to be created false ingress.annotations Ingress annotations {} ingress.host Ingress host \"\" ingress.tls Ingress tls false Istio Name Description Default istio.enabled Istio to be enable false istio.gatewayName Istio gateway name gateway istio.serversPortNumber Istio servers port number 80 istio.serversPortName Istio servers port name http istio.serversPortProtocol Istio servers port protocol HTTP istio.serversHost Istio servers host * istio.virtualserviceName Istio virtual service name dirigible istio.virtualserviceHosts Istio virtual service hosts * istio.virtualserviceGateways Istio virtual service gateway gateway istio.virtualserviceDestination Istio virtual service destination dirigible istio.virtualservicePort Istio virtual service port 8080 Kyma Name Description Default kyma.enabled Kyma environment to be used false kyma.apirule.enabled Kyma ApiRule to be created true kyma.apirule.host Kyma host to be used in ApiRule \"\" Keycloak Name Description Default keycloak.enabled Keycloak environment to be used false keycloak.install Keycloak to be installed false keycloak.name Keycloak deployment name keycloak keycloak.image Keycloak image jboss/keycloak:12.0.4 keycloak.username Keycloak username admin keycloak.password Keycloak password admin keycloak.replicaCount Keycloak number of replicas 1 keycloak.realm Keycloak realm to be set master keycloak.clientId Keycloak clientId to be used dirigible keycloak.database.enabled Keycloak database to be used false keycloak.database.enabled Keycloak database to be used true keycloak.database.image Keycloak database image postgres:13 keycloak.database.storage Keycloak database storage size 1Gi keycloak.database.username Keycloak database username keycloak keycloak.database.password Keycloak database password keycloak Usage Specify the parameters you which to customize using the --set argument to the helm install command. For instance, helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=my-ingress-host.com The above command sets the ingress.host to my-ingress-host.com . Alternatively, a YAML file that specifies the values for the above parameters can be provided while installing the chart. For example, helm install dirigible dirigible/dirigible --values values.yaml Tip You can use the default values.yaml .","title":"Helm"},{"location":"includes/helm/#setup-with-helm","text":"You can deploy Dirigible via Helm Chart in a Kubernetes cluster. Prerequisites Helm Kubernetes Cluster on IaaS provider of your choice","title":"Setup with Helm"},{"location":"includes/helm/#steps","text":"Add the Eclipse Dirigible Helm repository: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update Verify Eclipse Dirigible Helm chart: helm pull dirigible/dirigible --prov curl -o ~/.gnupg/pubring.gpg https://eclipse.github.io/dirigible/charts/pubring.gpg helm verify dirigible-<version>.tgz You shoul see message: Signed by: Using Key With Fingerprint: Chart Hash Verified: Basic: helm install dirigible dirigible/dirigible Access This will install Eclipse Dirigible Deployment and Service with ClusterIP only. To access the Dirigible instance execute the command that was printed in the console. Example: export POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/name=dirigible,app.kubernetes.io/instance=dirigible\" -o jsonpath=\"{.items[0].metadata.name}\") echo \"Visit http://127.0.0.1:8080 to use your application\" kubectl --namespace default port-forward $POD_NAME 8080:8080 Navigate to: http://127.0.0.1:8080 Login with: dirigible / dirigible Kubernetes: Basic Istio PostgreSQL PostgreSQL & Keycloak helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> This will expose the Dirigible instance through Ingress host ( http://... ). Prerequisites Install Istio . kubectl label namespace default istio-injection=enabled helm install dirigible dirigible/dirigible \\ --set istio.enabled=true This will install Eclipse Dirigible Deployment , Service with ClusterIP only and Istio Gateway and Virtual Service . To access the Dirigible instance execute the command that was printed in the console. kubectl get svc istio-ingressgateway -n istio-system \\ -o jsonpath=\"{.status.loadBalancer.ingress[*].hostname}\" helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> \\ --set database.enabled=true This will install also PostgreSQL database with 1Gi storage and update the Dirigible datasource configuration to consume the database. helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=<ingress-host> \\ --set database.enabled=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true In addition Keycloak will be deployed and configured. Disable HTTPS In some cases you might want to disable the \"Required HTTPS\" for Keycloak. Login to the PostgreSQL Pod: kubectl exec -it keycloak-database-<pod-uuid> /bin/bash Connect to the keycloak database: psql --u keycloak Set the ssl_required to NONE : update REALM set ssl_required='NONE' where id = 'master'; Restart the Keycloak pod to apply the updated configuration: kubectl delete pod keycloak-<pod-uuid> Now the Required HTTPS should be disabled and the keycloak instance should be accessible via http:// Kyma: Basic PostgreSQL PostgreSQL & Keycloak helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> This will install additionally an ApiRule and XSUAA ServiceInstance and ServiceBinding . The appropriate roles should be assigned to the user. helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> \\ --set database.enabled=true This will install also PostgreSQL database with 1Gi storage and update the Dirigible datasource configuration to consume the database. helm install dirigible dirigible/dirigible \\ --set kyma.enabled=true \\ --set kyma.apirule.host=<kyma-host> \\ --set database.enabled=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true In addition Keycloak will be deployed and configured. Disable HTTPS In some cases you might want to disable the \"Required HTTPS\" for Keycloak. Login to the PostgreSQL Pod: kubectl exec -it keycloak-database-<pod-uuid> /bin/bash Connect to the keycloak database: psql --u keycloak Set the ssl_required to NONE : update REALM set ssl_required='NONE' where id = 'master'; Restart the Keycloak pod to apply the updated configuration: kubectl delete pod keycloak-<pod-uuid> Now the Required HTTPS should be disabled and the keycloak instance should be accessible via http:// Uninstall: helm uninstall dirigible","title":"Steps"},{"location":"includes/helm/#configuration","text":"The following table lists all the configurable parameters expose by the Dirigible chart and their default values.","title":"Configuration"},{"location":"includes/helm/#generic","text":"Name Description Default dirigible.image Custom Dirigible image \"\" image.repository Dirigible image repo dirigiblelabs/dirigible-all image.repositoryKyma Dirigible Kyma image repo dirigiblelabs/dirigible-sap-kyma image.repositoryKeycloak Dirigible Keycloak image repo dirigiblelabs/dirigible-keycloak image.pullPolicy Image pull policy IfNotPresent service.type Service type ClusterIP service.port Service port 8080 replicaCount Number of replicas 1 imagePullSecrets Image pull secrets [] nameOverride Name override \"\" fullnameOverride Fullname override \"\" podSecurityContext Pod security context {} nodeSelector Node selector {} tolerations Tolerations [] affinity Affinity {} resources Resources {}","title":"Generic"},{"location":"includes/helm/#basic","text":"Name Description Default volume.enabled Volume to be mounted true volume.storage Volume storage size 1Gi database.enabled Database to be deployed false database.image Database image postgres:13 database.driver Database JDBC driver org.postgresql.Driver database.storage Database storage size 1Gi database.username Database username dirigible database.password Database password dirigible ingress.enabled Ingress to be created false ingress.annotations Ingress annotations {} ingress.host Ingress host \"\" ingress.tls Ingress tls false","title":"Basic"},{"location":"includes/helm/#istio","text":"Name Description Default istio.enabled Istio to be enable false istio.gatewayName Istio gateway name gateway istio.serversPortNumber Istio servers port number 80 istio.serversPortName Istio servers port name http istio.serversPortProtocol Istio servers port protocol HTTP istio.serversHost Istio servers host * istio.virtualserviceName Istio virtual service name dirigible istio.virtualserviceHosts Istio virtual service hosts * istio.virtualserviceGateways Istio virtual service gateway gateway istio.virtualserviceDestination Istio virtual service destination dirigible istio.virtualservicePort Istio virtual service port 8080","title":"Istio"},{"location":"includes/helm/#kyma","text":"Name Description Default kyma.enabled Kyma environment to be used false kyma.apirule.enabled Kyma ApiRule to be created true kyma.apirule.host Kyma host to be used in ApiRule \"\"","title":"Kyma"},{"location":"includes/helm/#keycloak","text":"Name Description Default keycloak.enabled Keycloak environment to be used false keycloak.install Keycloak to be installed false keycloak.name Keycloak deployment name keycloak keycloak.image Keycloak image jboss/keycloak:12.0.4 keycloak.username Keycloak username admin keycloak.password Keycloak password admin keycloak.replicaCount Keycloak number of replicas 1 keycloak.realm Keycloak realm to be set master keycloak.clientId Keycloak clientId to be used dirigible keycloak.database.enabled Keycloak database to be used false keycloak.database.enabled Keycloak database to be used true keycloak.database.image Keycloak database image postgres:13 keycloak.database.storage Keycloak database storage size 1Gi keycloak.database.username Keycloak database username keycloak keycloak.database.password Keycloak database password keycloak","title":"Keycloak"},{"location":"includes/helm/#usage","text":"Specify the parameters you which to customize using the --set argument to the helm install command. For instance, helm install dirigible dirigible/dirigible \\ --set ingress.enabled=true \\ --set ingress.host=my-ingress-host.com The above command sets the ingress.host to my-ingress-host.com . Alternatively, a YAML file that specifies the values for the above parameters can be provided while installing the chart. For example, helm install dirigible dirigible/dirigible --values values.yaml Tip You can use the default values.yaml .","title":"Usage"},{"location":"includes/kubernetes/","text":"Setup in Kubernetes You can deploy Dirigible Docker images, for example dirigiblelabs/dirigible-tomcat , in a Kubernetes cluster. Prerequisites Install kubectl . Access to Kubernetes Cluster on IaaS provider of your choice. Steps Create deployment configuration file: deployment.yaml Pod Deployment Deployment with PVC apiVersion : v1 kind : Pod metadata : name : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" volumeMounts : - name : dirigible-data mountPath : /usr/local/tomcat/dirigible/repository volumes : - name : dirigible-data persistentVolumeClaim : claimName : \"dirigible-data\" -- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-data spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Create service configuration file: service.yaml Service Ingress apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible apiVersion : extensions/v1beta1 apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dirigible spec : rules : - host : dirigible.<kubernetes-ingress-host> http : paths : - path : / backend : serviceName : dirigible servicePort : 8080 Note Replace <kubernetes-ingress-host> with your Ingress host. Deploy to the Kubernetes Cluster with: kubectl apply -f deployment.yml kubectl apply -f service.yml Open a web browser and go to: http://dirigible.<kubernetes-ingress-host> Note Replace <kubernetes-ingress-host> with your Ingress host. Login with user dirigible and password dirigible , which are set by default in the Docker image ( dirigiblelabs/dirigible-tomcat ) used above. Helm The helm package manager could be used to install Eclipse Dirigible via Helm Chart . Example: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update helm install dirigible dirigible/dirigible More about the setup with Helm can be found here .","title":"Kubernetes"},{"location":"includes/kubernetes/#setup-in-kubernetes","text":"You can deploy Dirigible Docker images, for example dirigiblelabs/dirigible-tomcat , in a Kubernetes cluster. Prerequisites Install kubectl . Access to Kubernetes Cluster on IaaS provider of your choice.","title":"Setup in Kubernetes"},{"location":"includes/kubernetes/#steps","text":"Create deployment configuration file: deployment.yaml Pod Deployment Deployment with PVC apiVersion : v1 kind : Pod metadata : name : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" volumeMounts : - name : dirigible-data mountPath : /usr/local/tomcat/dirigible/repository volumes : - name : dirigible-data persistentVolumeClaim : claimName : \"dirigible-data\" -- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-data spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use a stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Create service configuration file: service.yaml Service Ingress apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible apiVersion : extensions/v1beta1 apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dirigible spec : rules : - host : dirigible.<kubernetes-ingress-host> http : paths : - path : / backend : serviceName : dirigible servicePort : 8080 Note Replace <kubernetes-ingress-host> with your Ingress host. Deploy to the Kubernetes Cluster with: kubectl apply -f deployment.yml kubectl apply -f service.yml Open a web browser and go to: http://dirigible.<kubernetes-ingress-host> Note Replace <kubernetes-ingress-host> with your Ingress host. Login with user dirigible and password dirigible , which are set by default in the Docker image ( dirigiblelabs/dirigible-tomcat ) used above. Helm The helm package manager could be used to install Eclipse Dirigible via Helm Chart . Example: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update helm install dirigible dirigible/dirigible More about the setup with Helm can be found here .","title":"Steps"},{"location":"includes/kyma/","text":"Setup in Kyma Deploy Eclipse Dirigible in SAP BTP[^1], Kyma environment. [^1]: SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. Prerequisites Install kubectl - this step is optional. Access to SAP BTP account (the Trial landscape can be accessed here ). Steps Access the SAP BTP, Kyma environment via the SAP BTP cockpit: Deploy Eclipse Dirigible: Copy and paste the following content into deployment.yaml : apiVersion : apps/v1 kind : Deployment metadata : name : dirigible namespace : default spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-sap-kyma:latest imagePullPolicy : Always env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://dirigible.<your-kyma-cluster-host> volumeMounts : - name : dirigible-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : dirigible protocol : TCP volumes : - name : dirigible-volume persistentVolumeClaim : claimName : dirigible-claim --- apiVersion : v1 kind : Service metadata : labels : app : dirigible name : dirigible namespace : default spec : ports : - name : dirigible port : 8080 protocol : TCP targetPort : 8080 selector : app : dirigible type : ClusterIP --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-claim spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi --- apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : dirigible namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : dirigible.<your-kyma-cluster-host> name : dirigible port : 8080 Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com )._ Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Navigate to your Kyma dashboard and select the default namespace. Click on the Deploy new resource button and select the deployment.yaml file. Note Alternatively the kubectl -f deployment.yaml could be used to deploy the resources. Create XSUAA service instance: From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Authorization & Trust Management service. Create new service instance. Provide the following additional parameters. { \"xsappname\" : \"dirigible-xsuaa\" , \"oauth2-configuration\" : { \"token-validity\" : 7200 , \"redirect-uris\" : [ \"https://dirigible.<your-kyma-cluster-host>\" ] }, \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"Dirigible Developer\" , \"description\" : \"Dirigible Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Dirigible Operator\" , \"description\" : \"Dirigible Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com ). Bind the servce instance to the dirigible application. Assign the Developer and Operator roles. Log in. Additional Materials The helm package manager could be used to install Eclipse Dirigible via Helm Chart . Example: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update helm install dirigible dirigible/dirigible More about the setup with Helm can be found here . Step by step tutorial can be found here .","title":"Kyma"},{"location":"includes/kyma/#setup-in-kyma","text":"Deploy Eclipse Dirigible in SAP BTP[^1], Kyma environment. [^1]: SAP Cloud Platform is called SAP Business Technology Platform (SAP BTP) as of 2021. Prerequisites Install kubectl - this step is optional. Access to SAP BTP account (the Trial landscape can be accessed here ).","title":"Setup in Kyma"},{"location":"includes/kyma/#steps","text":"Access the SAP BTP, Kyma environment via the SAP BTP cockpit: Deploy Eclipse Dirigible: Copy and paste the following content into deployment.yaml : apiVersion : apps/v1 kind : Deployment metadata : name : dirigible namespace : default spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-sap-kyma:latest imagePullPolicy : Always env : - name : DIRIGIBLE_THEME_DEFAULT value : fiori - name : DIRIGIBLE_HOST value : https://dirigible.<your-kyma-cluster-host> volumeMounts : - name : dirigible-volume mountPath : /usr/local/tomcat/target/dirigible/repository ports : - containerPort : 8080 name : dirigible protocol : TCP volumes : - name : dirigible-volume persistentVolumeClaim : claimName : dirigible-claim --- apiVersion : v1 kind : Service metadata : labels : app : dirigible name : dirigible namespace : default spec : ports : - name : dirigible port : 8080 protocol : TCP targetPort : 8080 selector : app : dirigible type : ClusterIP --- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-claim spec : accessModes : - ReadWriteOnce resources : requests : storage : 1Gi --- apiVersion : gateway.kyma-project.io/v1alpha1 kind : APIRule metadata : name : dirigible namespace : default spec : gateway : kyma-gateway.kyma-system.svc.cluster.local rules : - accessStrategies : - config : {} handler : noop methods : - GET - POST - PUT - PATCH - DELETE - HEAD path : /.* service : host : dirigible.<your-kyma-cluster-host> name : dirigible port : 8080 Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com )._ Eclipse Dirigible versions Instead of using the latest tag (version), for production and development use cases it is recomended to use stable release version: All released versions can be found here . All Eclipse Dirigible Docker images and tags (versions) can be found here . Navigate to your Kyma dashboard and select the default namespace. Click on the Deploy new resource button and select the deployment.yaml file. Note Alternatively the kubectl -f deployment.yaml could be used to deploy the resources. Create XSUAA service instance: From the Kyma dashboard, go to Service Management \u2192 Catalog . Find the Authorization & Trust Management service. Create new service instance. Provide the following additional parameters. { \"xsappname\" : \"dirigible-xsuaa\" , \"oauth2-configuration\" : { \"token-validity\" : 7200 , \"redirect-uris\" : [ \"https://dirigible.<your-kyma-cluster-host>\" ] }, \"scopes\" : [ { \"name\" : \"$XSAPPNAME.Developer\" , \"description\" : \"Developer scope\" }, { \"name\" : \"$XSAPPNAME.Operator\" , \"description\" : \"Operator scope\" } ], \"role-templates\" : [ { \"name\" : \"Developer\" , \"description\" : \"Developer related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Operator\" , \"description\" : \"Operator related roles\" , \"scope-references\" : [ \"$XSAPPNAME.Operator\" ] } ], \"role-collections\" : [ { \"name\" : \"Dirigible Developer\" , \"description\" : \"Dirigible Developer\" , \"role-template-references\" : [ \"$XSAPPNAME.Developer\" ] }, { \"name\" : \"Dirigible Operator\" , \"description\" : \"Dirigible Operator\" , \"role-template-references\" : [ \"$XSAPPNAME.Operator\" ] } ] } Note Replace the <your-kyma-cluster-host> placeholder with your Kyma cluster host (e.g. c-xxxxxxx.kyma.xxx.xxx.xxx.ondemand.com ). Bind the servce instance to the dirigible application. Assign the Developer and Operator roles. Log in. Additional Materials The helm package manager could be used to install Eclipse Dirigible via Helm Chart . Example: helm repo add dirigible https://eclipse.github.io/dirigible helm repo update helm install dirigible dirigible/dirigible More about the setup with Helm can be found here . Step by step tutorial can be found here .","title":"Steps"},{"location":"includes/setup-environment-variables/","text":"Environment Variables Configuration Types Based on the layer, they are defined, configuration variables have the following priorities: Runtime Environment Deployment Module Highest precedence: No rebuild or restart of the application is required when configuration is changed. The Configuration API could be used to apply changes in the Runtime configuration. Second precedence: No rebuild is required when configuration is changed, however the application should be restarted, to apply the environment changes. Usually the Environment configurations are provided during the application deployment, as part of application descriptor (e.g. Define environment variable for container in Kubernetes or in Cloud Foundry App Manifest ) . Third precedence: Rebuild and re-deployment is required. \"Default\" deployment ( ROOT.war ) configuration variables are taken from dirigible.properties properties file (sample could be found here ) . Lowest precedence: Rebuild and re-deployment is required. \"Default\" module (e.g. dirigible-database-custom.jar , dirigible-database-h2.jar ) configuration variables are taken from dirigible-xxx.properties properties files (sample could be found here and here ) Note The precedence order means that, if the there is an Environment variable with name DIRIGIBLE_TEST and Runtime variable with the same name, the Runtime variable will have high prority and will be applied. All applied configuration values could be found under the Configurations View . Configuration Parameters Anonymous Access Parameter Description Default* DIRIGIBLE_ANONYMOUS_USER_NAME_PROPERTY_NAME The name of the property, that will be used to retrieve the anonymous user name (e.g. MY_USER_VARIABLE) - Branding Parameter Description Default* DIRIGIBLE_BRANDING_NAME The brand name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND The branding name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND_URL The branding URL https://www.dirigible.io DIRIGIBLE_BRANDING_ICON The branding icon ../../../../services/v4/web/resources/images/favicon.png DIRIGIBLE_BRANDING_WELCOME_PAGE_DEFAULT The branding welcome page ../../../../services/v4/web/ide/welcome.html DIRIGIBLE_BRANDING_HELP_ITEMS The list of the custom help menu items (comma separated) - Branding - Help Items Note Replace CUSTOM_ITEM with the actual name set by DIRIGIBLE_BRANDING_HELP_ITEMS e.g. ITEM1 Parameter Description Default* DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_NAME The name of the custom help item - DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_URL The url of the custom help item - DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_ORDER (Optional) The order of the custom help item 0 DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_DIVIDER (Optional) Whether to set divider after the custom help item false OAuth Parameter Description Default* DIRIGIBLE_OAUTH_AUTHORIZE_URL The OAuth authorization URL (e.g. https://my-oauth-server/oauth/authorize ) - DIRIGIBLE_OAUTH_TOKEN_URL The OAuth token URL (e.g. https://my-oauth-server/oauth/token ) - DIRIGIBLE_OAUTH_CLIENT_ID The OAuth clientid (e.g. sb-xxx-yyy ) - DIRIGIBLE_OAUTH_CLIENT_SECRET The OAuth clientsecret (e.g. PID/cpkD8aZzbGaa6+muYYOOMWPDeM1ug/sQ5ZF... ) - DIRIGIBLE_OAUTH_VERIFICATION_KEY The OAuth verificationkey (e.g. -----BEGIN PUBLIC KEY-----MIIBIjANBgkqhki... ) - DIRIGIBLE_OAUTH_APPLICATION_NAME The application name (e.g. dirigible-xxx ) - DIRIGIBLE_OAUTH_APPLICATION_HOST The application host (e.g. https://my-application-host ) - DIRIGIBLE_OAUTH_ISSUER The OAuth issuer (e.g. http://xxx.localhost:8080/uaa/oauth/token ) - DIRIGIBLE_OAUTH_CHECK_ISSUER_ENABLED Sets whether the JWT verifier should check the token issuer true Git Parameter Description Default* DIRIGIBLE_GIT_ROOT_FOLDER The external folder that will be used for synchronizing git projects - Registry Parameter Description Default* DIRIGIBLE_REGISTRY_EXTERNAL_FOLDER The external folder that will be used for synchronizing the public registry - DIRIGIBLE_REGISTRY_IMPORT_WORKSPACE The external folder that will be imported into the public registry - Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_PROVIDER The name of the repository provider used in this instance local or database DIRIGIBLE_REPOSITORY_CACHE_ENABLED Enable the usage of the repository cache true Database Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_DATABASE_DATASOURCE_NAME The name of the data source, which will be used to store the repository artifacts DefaultDB Local Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER The location of the root folder where the repository artifacts will be stored . DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false Master Repository Parameter Description Default* DIRIGIBLE_MASTER_REPOSITORY_PROVIDER The name of the master repository provider used in this instance ( filesystem , zip or jar ) - DIRIGIBLE_MASTER_REPOSITORY_ROOT_FOLDER The location of the root folder where the master repository artifacts will be loaded from . DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION The location of the zip file where the master repository artifacts will be loaded from (e.g. /User/data/my-repo.zip ) - DIRIGIBLE_MASTER_REPOSITORY_JAR_PATH The JAR path location of the zip file where the master repository artifacts will be loaded from (e.g. /org/dirigible/example/my-repo.zip ) - Note The JAR path is absolute inside the class path Repository Search Parameter Description Default* DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER The location of the root folder to be used by the indexing engine . DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false DIRIGIBLE_REPOSITORY_SEARCH_INDEX_LOCATION The sub-folder under the root folder where the index files will be stored dirigible/repository/index Database Parameter Description Default* DIRIGIBLE_DATABASE_PROVIDER The name of the database provider which will be used in this instance ( local , managed or custom ) local DIRIGIBLE_DATABASE_DEFAULT_SET_AUTO_COMMIT The AUTO_COMMIT data source parameter true DIRIGIBLE_DATABASE_DEFAULT_MAX_CONNECTIONS_COUNT The MAX_CONNECTIONS_COUNT data source parameter 8 DIRIGIBLE_DATABASE_DEFAULT_WAIT_TIMEOUT The WAIT_TIMEOUT data source parameter 500 DIRIGIBLE_DATABASE_DEFAULT_WAIT_COUNT The WAIT_COUNT data source parameter 5 DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES The list of the custom data sources names used in this instance DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT The name of the primary data source used in this instance DefaultDB DIRIGIBLE_DATABASE_DATASOURCE_NAME_SYSTEM The name of the system data source used in this instance SystemDB DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE The names of the tables, views and columns to be considered as case sensitive false Database - Custom Note Replace CUSTOM_NAME with the actual name set by DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES e.g. POSTGRES_DRIVER Parameter Description Default* CUSTOM_NAME_DRIVER The Driver name of the custom datasource (e.g. org.postgresql.Driver ) - CUSTOM_NAME_URL The URL of the custom datasource (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - CUSTOM_NAME_USERNAME The User Name of the custom datasource - CUSTOM_NAME_PASSWORD The Password of the custom datasource - CUSTOM_NAME_CONNECTION_PROPERTIES The additional connection properties if any - Database Derby Parameter Description Default* DIRIGIBLE_DATABASE_DERBY_ROOT_FOLDER_DEFAULT The location used by Derby database ./target/dirigible/derby Database H2 Parameter Description Default* DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT The location used by H2 database ./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_DRIVER The Driver used by H2 database org.h2.Driver DIRIGIBLE_DATABASE_H2_URL The URL used by H2 database jdbc:h2:./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_USERNAME The Username used by H2 database sa DIRIGIBLE_DATABASE_H2_PASSWORD The Password used by H2 database - Persistence Parameter Description Default* DIRIGIBLE_PERSISTENCE_CREATE_TABLE_ON_USE Whether the table to be created automatically on use if it does not exist true MongoDB Parameter Description Default* DIRIGIBLE_MONGODB_CLIENT_URI The location used by MongoDB server mongodb://localhost:27017 DIRIGIBLE_MONGODB_DATABASE_DEFAULT The default database name db Scheduler Parameter Description Default* DIRIGIBLE_SCHEDULER_MEMORY_STORE Whether Quartz to use in-memory job store false DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_TYPE The type of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_NAME The name of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE The name of the JDBC delegate used by Quartz, if not the default one org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.impl.jdbcjobstore.StdJDBCDelegate (for fully JDBC-compliant drivers) org.quartz.impl.jdbcjobstore.MSSQLDelegate (for Microsoft SQL Server, and Sybase) org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.impl.jdbcjobstore.WebLogicDelegate (for WebLogic drivers) org.quartz.impl.jdbcjobstore.oracle.OracleDelegate org.quartz.impl.jdbcjobstore.oracle.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.oracle.weblogic.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.CloudscapeDelegate org.quartz.impl.jdbcjobstore.DB2v6Delegate org.quartz.impl.jdbcjobstore.DB2v7Delegate org.quartz.impl.jdbcjobstore.DB2v8Delegate org.quartz.impl.jdbcjobstore.HSQLDBDelegate org.quartz.impl.jdbcjobstore.PointbaseDelegate org.quartz.impl.jdbcjobstore.SybaseDelegate Synchronizer Parameter Description Default* DIRIGIBLE_SYNCHRONIZER_IGNORE_DEPENDENCIES Whether to ignore dependencies for synchronizers, e.g. for tests purposes false Job Expression Parameter Description Default* DIRIGIBLE_JOB_EXPRESSION_BPM BPM synchronizer job config 0/50 * * * * ? DIRIGIBLE_JOB_EXPRESSION_DATA_STRUCTURES Data structures job synchronizer config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_EXTENSIONS Extension synchronizer job config 0/10 * * * * ? DIRIGIBLE_JOB_EXPRESSION_JOBS Jobs synchronizer job config 0/15 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MESSAGING Messaging synchronizer job config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MIGRATIONS Migration synchronizer job config 0/55 * * * * ? DIRIGIBLE_JOB_EXPRESSION_ODATA OData synchronizer job config 0/45 * * * * ? DIRIGIBLE_JOB_EXPRESSION_PUBLISHER Publisher synchronizer job config 0/5 * * * * ? DIRIGIBLE_JOB_EXPRESSION_SECURITY Security synchronizer job config 0/20 * * * * ? DIRIGIBLE_JOB_EXPRESSION_REGISTRY Registry synchronizer job config 0/35 * * * * ? DIRIGIBLE_JOB_DEFAULT_TIMEOUT Default timeout in minutes 3 Runtime Core Parameter Description Default* DIRIGIBLE_HOME_URL The home URL where the user to be redirected on access /services/v4/web/ide/index.html Vert.x Parameter Description Default* DIRIGIBLE_VERTX_PORT The Vert.x server port, if used 8888 CMS Parameter Description Default* DIRIGIBLE_CMS_PROVIDER The type of the CMS provider used in this instance (e.g. internal , managed or database ) internal DIRIGIBLE_CMS_ROLES_ENABLED Whether the RBAC over the CMS content to be enabled true CMS - Internal Parameter Description Default* DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER The location of the CMS internal repository target DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false CMS - Managed Parameter Description Default* DIRIGIBLE_CMS_MANAGED_CONFIGURATION_JNDI_NAME The JNDI name of the managed CMS repository java:comp/env/EcmService in case of SAP package DIRIGIBLE_CMS_MANAGED_CONFIGURATION_AUTH_METHOD The authentication method (e.g. key or destination ) key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_NAME The name of the repository cmis:dirigible DIRIGIBLE_CMS_MANAGED_CONFIGURATION_KEY The key of the repository cmis:dirigible:key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_DESTINATION The name of the destination where the name and the key for the repository are stored (e.g. CMIS_DESTINATION ) - DIRIGIBLE_CONNECTIVITY_CONFIGURATION_JNDI_NAME The JNDI name of the connectivity configuration serivce java:comp/env/connectivity/Configuration in case of SAP package CMS Database Parameter Description Default* DIRIGIBLE_CMS_DATABASE_DATASOURCE_TYPE Type of the database for CMS repository (e.g. local , managed , custom , dynamic ) managed DIRIGIBLE_CMS_DATABASE_DATASOURCE_NAME The datasource name DefaultDB BPM Parameter Description Default* DIRIGIBLE_BPM_PROVIDER The provider of the BPM engine (e.g. internal , managed , remote ) internal BPM - Flowable Parameter Description Default* DIRIGIBLE_FLOWABLE_DATABASE_DRIVER The driver of the Flowable engine (e.g. org.postgresql.Driver ) - DIRIGIBLE_FLOWABLE_DATABASE_URL The URL of the Flowable engine (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - DIRIGIBLE_FLOWABLE_DATABASE_USER The user of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_PASSWORD The driver of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_DATASOURCE_NAME The datasource name of the Flowable engine, if any configured - DIRIGIBLE_FLOWABLE_DATABASE_SCHEMA_UPDATE Whether to materialize the database layout or not true DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in H2 (e.g. true (DefaultDB) or false (H2)) true Mail Parameter Description Default* DIRIGIBLE_MAIL_USERNAME Mailbox username - DIRIGIBLE_MAIL_PASSWORD Mailbox password - DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL Mail transport protocol smtps DIRIGIBLE_MAIL_SMTPS_HOST Mailbox SMTPS host - DIRIGIBLE_MAIL_SMTPS_PORT Mailbox SMTPS port - DIRIGIBLE_MAIL_SMTPS_AUTH Enable/disable mailbox SMTPS authentication - DIRIGIBLE_MAIL_SMTP_HOST Mailbox SMTP host - DIRIGIBLE_MAIL_SMTP_PORT Mailbox SMTP port - DIRIGIBLE_MAIL_SMTP_AUTH Enable/disable mailbox SMTP authentication - Messaging Parameter Description Default* DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in KahaDB (e.g. true (DefaultDB) or false (KahaDB)) true Kafka Parameter Description Default* DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER The Kafka server location localhost:9092 DIRIGIBLE_KAFKA_ACKS The number of brokers that must receive the record before considering the write as successful all DIRIGIBLE_KAFKA_KEY_SERIALIZER The Key serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_VALUE_SERIALIZER The Value serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED Whether Auto Commit is enabled true DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL Auto Commit interval in ms 1000 Engines JavaScript Parameter Description Default* DIRIGIBLE_JAVASCRIPT_ENGINE_TYPE_DEFAULT The type of the JavaScript engine provider used in this instance (e.g. graalvm , rhino , nashorn or v8 ) graalvm since 5.0 GraalVM Parameter Description Default* DIRIGIBLE_JAVASCRIPT_GRAALVM_DEBUGGER_PORT The GraalVM debugger port 8081 and 0.0.0.0:8081 in Docker environment DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_HOST_ACCESS Whether GraalVM can load classes form custom packages true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_THREAD Whether GraalVM can create threads true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_PROCESS Whether GraalVM can make IO operations true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_IO Whether GraalVM can make IO operations true DIRIGIBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_NASHORN Whether GraalVM has enabled compatibility mode for Nashorn true DIRIGIBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_MOZILLA Whether GraalVM has enabled compatibility mode for Mozilla false OData Parameter Description Default* DIRIGIBLE_ODATA_HANDLER_EXECUTOR_TYPE The type of the JavaScript engine to be used for event handlers in OData DIRIGIBLE_ODATA_HANDLER_EXECUTOR_ON_EVENT The location of the wrapper helper to be used for event handlers in OData Operations Logs Parameter Description Default* DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT The folder where the log files are stored in ../logs DIRIGIBLE_EXEC_COMMAND_LOGGING_ENABLED Whether to log the executed command by the exec API false Look & Feel Theme Parameter Description Default* DIRIGIBLE_THEME_DEFAULT The name of the default name Default Destinations Parameter Description Default* DIRIGIBLE_DESTINATIONS_PROVIDER The name of the Destinations Service provider used in this instance local or managed DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER The location of the Destinations internal repository target DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false DIRIGIBLE_DESTINATION_CLIENT_ID The Destination Service instance client id - DIRIGIBLE_DESTINATION_CLIENT_SECRET The Destination Service instance client secret - DIRIGIBLE_DESTINATION_URL The Destination Service instance url - DIRIGIBLE_DESTINATION_URI The Destination Service instance uri - Terminal Parameter Description Default* DIRIGIBLE_TERMINAL_ENABLED Whether the Terminal view is enabled true","title":"Environment Variables"},{"location":"includes/setup-environment-variables/#environment-variables","text":"","title":"Environment Variables"},{"location":"includes/setup-environment-variables/#configuration-types","text":"Based on the layer, they are defined, configuration variables have the following priorities: Runtime Environment Deployment Module Highest precedence: No rebuild or restart of the application is required when configuration is changed. The Configuration API could be used to apply changes in the Runtime configuration. Second precedence: No rebuild is required when configuration is changed, however the application should be restarted, to apply the environment changes. Usually the Environment configurations are provided during the application deployment, as part of application descriptor (e.g. Define environment variable for container in Kubernetes or in Cloud Foundry App Manifest ) . Third precedence: Rebuild and re-deployment is required. \"Default\" deployment ( ROOT.war ) configuration variables are taken from dirigible.properties properties file (sample could be found here ) . Lowest precedence: Rebuild and re-deployment is required. \"Default\" module (e.g. dirigible-database-custom.jar , dirigible-database-h2.jar ) configuration variables are taken from dirigible-xxx.properties properties files (sample could be found here and here ) Note The precedence order means that, if the there is an Environment variable with name DIRIGIBLE_TEST and Runtime variable with the same name, the Runtime variable will have high prority and will be applied. All applied configuration values could be found under the Configurations View .","title":"Configuration Types"},{"location":"includes/setup-environment-variables/#configuration-parameters","text":"","title":"Configuration Parameters"},{"location":"includes/setup-environment-variables/#anonymous-access","text":"Parameter Description Default* DIRIGIBLE_ANONYMOUS_USER_NAME_PROPERTY_NAME The name of the property, that will be used to retrieve the anonymous user name (e.g. MY_USER_VARIABLE) -","title":"Anonymous Access"},{"location":"includes/setup-environment-variables/#branding","text":"Parameter Description Default* DIRIGIBLE_BRANDING_NAME The brand name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND The branding name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND_URL The branding URL https://www.dirigible.io DIRIGIBLE_BRANDING_ICON The branding icon ../../../../services/v4/web/resources/images/favicon.png DIRIGIBLE_BRANDING_WELCOME_PAGE_DEFAULT The branding welcome page ../../../../services/v4/web/ide/welcome.html DIRIGIBLE_BRANDING_HELP_ITEMS The list of the custom help menu items (comma separated) -","title":"Branding"},{"location":"includes/setup-environment-variables/#branding-help-items","text":"Note Replace CUSTOM_ITEM with the actual name set by DIRIGIBLE_BRANDING_HELP_ITEMS e.g. ITEM1 Parameter Description Default* DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_NAME The name of the custom help item - DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_URL The url of the custom help item - DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_ORDER (Optional) The order of the custom help item 0 DIRIGIBLE_BRANDING_HELP_ITEM_CUSTOM_ITEM_DIVIDER (Optional) Whether to set divider after the custom help item false","title":"Branding - Help Items"},{"location":"includes/setup-environment-variables/#oauth","text":"Parameter Description Default* DIRIGIBLE_OAUTH_AUTHORIZE_URL The OAuth authorization URL (e.g. https://my-oauth-server/oauth/authorize ) - DIRIGIBLE_OAUTH_TOKEN_URL The OAuth token URL (e.g. https://my-oauth-server/oauth/token ) - DIRIGIBLE_OAUTH_CLIENT_ID The OAuth clientid (e.g. sb-xxx-yyy ) - DIRIGIBLE_OAUTH_CLIENT_SECRET The OAuth clientsecret (e.g. PID/cpkD8aZzbGaa6+muYYOOMWPDeM1ug/sQ5ZF... ) - DIRIGIBLE_OAUTH_VERIFICATION_KEY The OAuth verificationkey (e.g. -----BEGIN PUBLIC KEY-----MIIBIjANBgkqhki... ) - DIRIGIBLE_OAUTH_APPLICATION_NAME The application name (e.g. dirigible-xxx ) - DIRIGIBLE_OAUTH_APPLICATION_HOST The application host (e.g. https://my-application-host ) - DIRIGIBLE_OAUTH_ISSUER The OAuth issuer (e.g. http://xxx.localhost:8080/uaa/oauth/token ) - DIRIGIBLE_OAUTH_CHECK_ISSUER_ENABLED Sets whether the JWT verifier should check the token issuer true","title":"OAuth"},{"location":"includes/setup-environment-variables/#git","text":"Parameter Description Default* DIRIGIBLE_GIT_ROOT_FOLDER The external folder that will be used for synchronizing git projects -","title":"Git"},{"location":"includes/setup-environment-variables/#registry","text":"Parameter Description Default* DIRIGIBLE_REGISTRY_EXTERNAL_FOLDER The external folder that will be used for synchronizing the public registry - DIRIGIBLE_REGISTRY_IMPORT_WORKSPACE The external folder that will be imported into the public registry -","title":"Registry"},{"location":"includes/setup-environment-variables/#repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_PROVIDER The name of the repository provider used in this instance local or database DIRIGIBLE_REPOSITORY_CACHE_ENABLED Enable the usage of the repository cache true","title":"Repository"},{"location":"includes/setup-environment-variables/#database-repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_DATABASE_DATASOURCE_NAME The name of the data source, which will be used to store the repository artifacts DefaultDB","title":"Database Repository"},{"location":"includes/setup-environment-variables/#local-repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER The location of the root folder where the repository artifacts will be stored . DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false","title":"Local Repository"},{"location":"includes/setup-environment-variables/#master-repository","text":"Parameter Description Default* DIRIGIBLE_MASTER_REPOSITORY_PROVIDER The name of the master repository provider used in this instance ( filesystem , zip or jar ) - DIRIGIBLE_MASTER_REPOSITORY_ROOT_FOLDER The location of the root folder where the master repository artifacts will be loaded from . DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION The location of the zip file where the master repository artifacts will be loaded from (e.g. /User/data/my-repo.zip ) - DIRIGIBLE_MASTER_REPOSITORY_JAR_PATH The JAR path location of the zip file where the master repository artifacts will be loaded from (e.g. /org/dirigible/example/my-repo.zip ) - Note The JAR path is absolute inside the class path","title":"Master Repository"},{"location":"includes/setup-environment-variables/#repository-search","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER The location of the root folder to be used by the indexing engine . DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false DIRIGIBLE_REPOSITORY_SEARCH_INDEX_LOCATION The sub-folder under the root folder where the index files will be stored dirigible/repository/index","title":"Repository Search"},{"location":"includes/setup-environment-variables/#database","text":"Parameter Description Default* DIRIGIBLE_DATABASE_PROVIDER The name of the database provider which will be used in this instance ( local , managed or custom ) local DIRIGIBLE_DATABASE_DEFAULT_SET_AUTO_COMMIT The AUTO_COMMIT data source parameter true DIRIGIBLE_DATABASE_DEFAULT_MAX_CONNECTIONS_COUNT The MAX_CONNECTIONS_COUNT data source parameter 8 DIRIGIBLE_DATABASE_DEFAULT_WAIT_TIMEOUT The WAIT_TIMEOUT data source parameter 500 DIRIGIBLE_DATABASE_DEFAULT_WAIT_COUNT The WAIT_COUNT data source parameter 5 DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES The list of the custom data sources names used in this instance DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT The name of the primary data source used in this instance DefaultDB DIRIGIBLE_DATABASE_DATASOURCE_NAME_SYSTEM The name of the system data source used in this instance SystemDB DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE The names of the tables, views and columns to be considered as case sensitive false","title":"Database"},{"location":"includes/setup-environment-variables/#database-custom","text":"Note Replace CUSTOM_NAME with the actual name set by DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES e.g. POSTGRES_DRIVER Parameter Description Default* CUSTOM_NAME_DRIVER The Driver name of the custom datasource (e.g. org.postgresql.Driver ) - CUSTOM_NAME_URL The URL of the custom datasource (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - CUSTOM_NAME_USERNAME The User Name of the custom datasource - CUSTOM_NAME_PASSWORD The Password of the custom datasource - CUSTOM_NAME_CONNECTION_PROPERTIES The additional connection properties if any -","title":"Database - Custom"},{"location":"includes/setup-environment-variables/#database-derby","text":"Parameter Description Default* DIRIGIBLE_DATABASE_DERBY_ROOT_FOLDER_DEFAULT The location used by Derby database ./target/dirigible/derby","title":"Database Derby"},{"location":"includes/setup-environment-variables/#database-h2","text":"Parameter Description Default* DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT The location used by H2 database ./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_DRIVER The Driver used by H2 database org.h2.Driver DIRIGIBLE_DATABASE_H2_URL The URL used by H2 database jdbc:h2:./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_USERNAME The Username used by H2 database sa DIRIGIBLE_DATABASE_H2_PASSWORD The Password used by H2 database -","title":"Database H2"},{"location":"includes/setup-environment-variables/#persistence","text":"Parameter Description Default* DIRIGIBLE_PERSISTENCE_CREATE_TABLE_ON_USE Whether the table to be created automatically on use if it does not exist true","title":"Persistence"},{"location":"includes/setup-environment-variables/#mongodb","text":"Parameter Description Default* DIRIGIBLE_MONGODB_CLIENT_URI The location used by MongoDB server mongodb://localhost:27017 DIRIGIBLE_MONGODB_DATABASE_DEFAULT The default database name db","title":"MongoDB"},{"location":"includes/setup-environment-variables/#scheduler","text":"Parameter Description Default* DIRIGIBLE_SCHEDULER_MEMORY_STORE Whether Quartz to use in-memory job store false DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_TYPE The type of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_NAME The name of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE The name of the JDBC delegate used by Quartz, if not the default one org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.impl.jdbcjobstore.StdJDBCDelegate (for fully JDBC-compliant drivers) org.quartz.impl.jdbcjobstore.MSSQLDelegate (for Microsoft SQL Server, and Sybase) org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.impl.jdbcjobstore.WebLogicDelegate (for WebLogic drivers) org.quartz.impl.jdbcjobstore.oracle.OracleDelegate org.quartz.impl.jdbcjobstore.oracle.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.oracle.weblogic.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.CloudscapeDelegate org.quartz.impl.jdbcjobstore.DB2v6Delegate org.quartz.impl.jdbcjobstore.DB2v7Delegate org.quartz.impl.jdbcjobstore.DB2v8Delegate org.quartz.impl.jdbcjobstore.HSQLDBDelegate org.quartz.impl.jdbcjobstore.PointbaseDelegate org.quartz.impl.jdbcjobstore.SybaseDelegate","title":"Scheduler"},{"location":"includes/setup-environment-variables/#synchronizer","text":"Parameter Description Default* DIRIGIBLE_SYNCHRONIZER_IGNORE_DEPENDENCIES Whether to ignore dependencies for synchronizers, e.g. for tests purposes false","title":"Synchronizer"},{"location":"includes/setup-environment-variables/#job-expression","text":"Parameter Description Default* DIRIGIBLE_JOB_EXPRESSION_BPM BPM synchronizer job config 0/50 * * * * ? DIRIGIBLE_JOB_EXPRESSION_DATA_STRUCTURES Data structures job synchronizer config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_EXTENSIONS Extension synchronizer job config 0/10 * * * * ? DIRIGIBLE_JOB_EXPRESSION_JOBS Jobs synchronizer job config 0/15 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MESSAGING Messaging synchronizer job config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MIGRATIONS Migration synchronizer job config 0/55 * * * * ? DIRIGIBLE_JOB_EXPRESSION_ODATA OData synchronizer job config 0/45 * * * * ? DIRIGIBLE_JOB_EXPRESSION_PUBLISHER Publisher synchronizer job config 0/5 * * * * ? DIRIGIBLE_JOB_EXPRESSION_SECURITY Security synchronizer job config 0/20 * * * * ? DIRIGIBLE_JOB_EXPRESSION_REGISTRY Registry synchronizer job config 0/35 * * * * ? DIRIGIBLE_JOB_DEFAULT_TIMEOUT Default timeout in minutes 3","title":"Job Expression"},{"location":"includes/setup-environment-variables/#runtime-core","text":"Parameter Description Default* DIRIGIBLE_HOME_URL The home URL where the user to be redirected on access /services/v4/web/ide/index.html","title":"Runtime Core"},{"location":"includes/setup-environment-variables/#vertx","text":"Parameter Description Default* DIRIGIBLE_VERTX_PORT The Vert.x server port, if used 8888","title":"Vert.x"},{"location":"includes/setup-environment-variables/#cms","text":"Parameter Description Default* DIRIGIBLE_CMS_PROVIDER The type of the CMS provider used in this instance (e.g. internal , managed or database ) internal DIRIGIBLE_CMS_ROLES_ENABLED Whether the RBAC over the CMS content to be enabled true","title":"CMS"},{"location":"includes/setup-environment-variables/#cms-internal","text":"Parameter Description Default* DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER The location of the CMS internal repository target DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false","title":"CMS - Internal"},{"location":"includes/setup-environment-variables/#cms-managed","text":"Parameter Description Default* DIRIGIBLE_CMS_MANAGED_CONFIGURATION_JNDI_NAME The JNDI name of the managed CMS repository java:comp/env/EcmService in case of SAP package DIRIGIBLE_CMS_MANAGED_CONFIGURATION_AUTH_METHOD The authentication method (e.g. key or destination ) key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_NAME The name of the repository cmis:dirigible DIRIGIBLE_CMS_MANAGED_CONFIGURATION_KEY The key of the repository cmis:dirigible:key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_DESTINATION The name of the destination where the name and the key for the repository are stored (e.g. CMIS_DESTINATION ) - DIRIGIBLE_CONNECTIVITY_CONFIGURATION_JNDI_NAME The JNDI name of the connectivity configuration serivce java:comp/env/connectivity/Configuration in case of SAP package","title":"CMS - Managed"},{"location":"includes/setup-environment-variables/#cms-database","text":"Parameter Description Default* DIRIGIBLE_CMS_DATABASE_DATASOURCE_TYPE Type of the database for CMS repository (e.g. local , managed , custom , dynamic ) managed DIRIGIBLE_CMS_DATABASE_DATASOURCE_NAME The datasource name DefaultDB","title":"CMS Database"},{"location":"includes/setup-environment-variables/#bpm","text":"Parameter Description Default* DIRIGIBLE_BPM_PROVIDER The provider of the BPM engine (e.g. internal , managed , remote ) internal","title":"BPM"},{"location":"includes/setup-environment-variables/#bpm-flowable","text":"Parameter Description Default* DIRIGIBLE_FLOWABLE_DATABASE_DRIVER The driver of the Flowable engine (e.g. org.postgresql.Driver ) - DIRIGIBLE_FLOWABLE_DATABASE_URL The URL of the Flowable engine (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - DIRIGIBLE_FLOWABLE_DATABASE_USER The user of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_PASSWORD The driver of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_DATASOURCE_NAME The datasource name of the Flowable engine, if any configured - DIRIGIBLE_FLOWABLE_DATABASE_SCHEMA_UPDATE Whether to materialize the database layout or not true DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in H2 (e.g. true (DefaultDB) or false (H2)) true","title":"BPM - Flowable"},{"location":"includes/setup-environment-variables/#mail","text":"Parameter Description Default* DIRIGIBLE_MAIL_USERNAME Mailbox username - DIRIGIBLE_MAIL_PASSWORD Mailbox password - DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL Mail transport protocol smtps DIRIGIBLE_MAIL_SMTPS_HOST Mailbox SMTPS host - DIRIGIBLE_MAIL_SMTPS_PORT Mailbox SMTPS port - DIRIGIBLE_MAIL_SMTPS_AUTH Enable/disable mailbox SMTPS authentication - DIRIGIBLE_MAIL_SMTP_HOST Mailbox SMTP host - DIRIGIBLE_MAIL_SMTP_PORT Mailbox SMTP port - DIRIGIBLE_MAIL_SMTP_AUTH Enable/disable mailbox SMTP authentication -","title":"Mail"},{"location":"includes/setup-environment-variables/#messaging","text":"Parameter Description Default* DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in KahaDB (e.g. true (DefaultDB) or false (KahaDB)) true","title":"Messaging"},{"location":"includes/setup-environment-variables/#kafka","text":"Parameter Description Default* DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER The Kafka server location localhost:9092 DIRIGIBLE_KAFKA_ACKS The number of brokers that must receive the record before considering the write as successful all DIRIGIBLE_KAFKA_KEY_SERIALIZER The Key serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_VALUE_SERIALIZER The Value serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED Whether Auto Commit is enabled true DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL Auto Commit interval in ms 1000","title":"Kafka"},{"location":"includes/setup-environment-variables/#engines","text":"","title":"Engines"},{"location":"includes/setup-environment-variables/#javascript","text":"Parameter Description Default* DIRIGIBLE_JAVASCRIPT_ENGINE_TYPE_DEFAULT The type of the JavaScript engine provider used in this instance (e.g. graalvm , rhino , nashorn or v8 ) graalvm since 5.0","title":"JavaScript"},{"location":"includes/setup-environment-variables/#graalvm","text":"Parameter Description Default* DIRIGIBLE_JAVASCRIPT_GRAALVM_DEBUGGER_PORT The GraalVM debugger port 8081 and 0.0.0.0:8081 in Docker environment DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_HOST_ACCESS Whether GraalVM can load classes form custom packages true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_THREAD Whether GraalVM can create threads true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_PROCESS Whether GraalVM can make IO operations true DIRIGIBLE_JAVASCRIPT_GRAALVM_ALLOW_IO Whether GraalVM can make IO operations true DIRIGIBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_NASHORN Whether GraalVM has enabled compatibility mode for Nashorn true DIRIGIBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_MOZILLA Whether GraalVM has enabled compatibility mode for Mozilla false","title":"GraalVM"},{"location":"includes/setup-environment-variables/#odata","text":"Parameter Description Default* DIRIGIBLE_ODATA_HANDLER_EXECUTOR_TYPE The type of the JavaScript engine to be used for event handlers in OData DIRIGIBLE_ODATA_HANDLER_EXECUTOR_ON_EVENT The location of the wrapper helper to be used for event handlers in OData","title":"OData"},{"location":"includes/setup-environment-variables/#operations","text":"","title":"Operations"},{"location":"includes/setup-environment-variables/#logs","text":"Parameter Description Default* DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT The folder where the log files are stored in ../logs DIRIGIBLE_EXEC_COMMAND_LOGGING_ENABLED Whether to log the executed command by the exec API false","title":"Logs"},{"location":"includes/setup-environment-variables/#look-feel","text":"","title":"Look &amp; Feel"},{"location":"includes/setup-environment-variables/#theme","text":"Parameter Description Default* DIRIGIBLE_THEME_DEFAULT The name of the default name Default","title":"Theme"},{"location":"includes/setup-environment-variables/#destinations","text":"Parameter Description Default* DIRIGIBLE_DESTINATIONS_PROVIDER The name of the Destinations Service provider used in this instance local or managed DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER The location of the Destinations internal repository target DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false DIRIGIBLE_DESTINATION_CLIENT_ID The Destination Service instance client id - DIRIGIBLE_DESTINATION_CLIENT_SECRET The Destination Service instance client secret - DIRIGIBLE_DESTINATION_URL The Destination Service instance url - DIRIGIBLE_DESTINATION_URI The Destination Service instance uri -","title":"Destinations"},{"location":"includes/setup-environment-variables/#terminal","text":"Parameter Description Default* DIRIGIBLE_TERMINAL_ENABLED Whether the Terminal view is enabled true","title":"Terminal"},{"location":"tutorial/cloud-foundry/","text":"","title":"Cloud Foundry"},{"location":"tutorial/contributing-to-ide-modules/","text":"Contributing to IDE Modules All IDE modules are located in the DirigibleLabs GitHub organization. Sample repositories, used for showing how to create Dirigible modules, start with sample- . Prerequisites Make sure you have permissions to commit in DirigibleLabs . PR are also accepted. Commit change to DirigibleLabs organization: Go to DirigibleLabs and copy the url to the IDE project you will contribute to. Start dirigible locally (http://localhost:8080/). You can find more information on how to do that here . Go to the Git perspective and click on Clone Project button. Enter the URL of the IDE project and click Clone . The project will appear under the git project list. Go to the Workspace perspective and make your changes. To be 100% sure all changes are saved and applied, right click on the project and select Publish . Now you can test the changes locally. After the changes are tested you can submit them. Open the Git perspective, click on the project and select the Stage tab. Select the changed files and use the down arrow button to stage them. Enter Commit Message . Enter your Username , Email , Password and click Commit and Push . In case your profile has two-factor authentication , for the Password field use your GitHub Personal Access Token (PAT) . See the additional info below. Go to the IDE project github page and make sure your changes were committed. Commit change to Eclipse Dirigible repository: Fork the Eclipse Dirigible git repository into your account. Pull the forked project locally. If you have done this before and now have to push new changes, make sure to checkout the master branch, fetch all changes from the original repository in GitHub and pull them locally. Checkout to a new branch by giving it either a topic name or a name starting with fix- followed by the issue number. Execute mvn clean install -Pcontent in the ide module root directory. You can also execute this for the whole project but that will pull the changes from all modules. Execute mvn clean install in the same module. You should see your changes that you already committed in the DirigibleLabs project. Add, commit and push only the files that you have changed. When committing, never forget to sign off you commit using the -s argument. You can use the git status command, to see all changed files. Create a PR to the master branch. How to generate and get my personal access token Creating a personal access token - GitHub Docs . Select all scopes. Copy and save your token, because after you navigate off the page, you will not be able to see the token again.","title":"Contributing to IDE Modules"},{"location":"tutorial/contributing-to-ide-modules/#contributing-to-ide-modules","text":"All IDE modules are located in the DirigibleLabs GitHub organization. Sample repositories, used for showing how to create Dirigible modules, start with sample- . Prerequisites Make sure you have permissions to commit in DirigibleLabs . PR are also accepted. Commit change to DirigibleLabs organization: Go to DirigibleLabs and copy the url to the IDE project you will contribute to. Start dirigible locally (http://localhost:8080/). You can find more information on how to do that here . Go to the Git perspective and click on Clone Project button. Enter the URL of the IDE project and click Clone . The project will appear under the git project list. Go to the Workspace perspective and make your changes. To be 100% sure all changes are saved and applied, right click on the project and select Publish . Now you can test the changes locally. After the changes are tested you can submit them. Open the Git perspective, click on the project and select the Stage tab. Select the changed files and use the down arrow button to stage them. Enter Commit Message . Enter your Username , Email , Password and click Commit and Push . In case your profile has two-factor authentication , for the Password field use your GitHub Personal Access Token (PAT) . See the additional info below. Go to the IDE project github page and make sure your changes were committed. Commit change to Eclipse Dirigible repository: Fork the Eclipse Dirigible git repository into your account. Pull the forked project locally. If you have done this before and now have to push new changes, make sure to checkout the master branch, fetch all changes from the original repository in GitHub and pull them locally. Checkout to a new branch by giving it either a topic name or a name starting with fix- followed by the issue number. Execute mvn clean install -Pcontent in the ide module root directory. You can also execute this for the whole project but that will pull the changes from all modules. Execute mvn clean install in the same module. You should see your changes that you already committed in the DirigibleLabs project. Add, commit and push only the files that you have changed. When committing, never forget to sign off you commit using the -s argument. You can use the git status command, to see all changed files. Create a PR to the master branch. How to generate and get my personal access token Creating a personal access token - GitHub Docs . Select all scopes. Copy and save your token, because after you navigate off the page, you will not be able to see the token again.","title":"Contributing to IDE Modules"},{"location":"tutorial/docker-image-setup/","text":"","title":"Docker"},{"location":"tutorial/environment-variables/","text":"","title":"Environment Variables"},{"location":"tutorial/generate-application-from-model/","text":"Generate Application from Model This tutorial will guide you through the creation of an entity data model and generation of a full-stack Dirigible application, from this model. Prerequisites Access to the latest version of Eclipse Dirigible (3.2.2+) Overview In this tutorial we will create an entity model of a car service bookings and generate full-stack Dirigible application from it. The complete sample can be found here . Setup Car Service Bookings Create new project car-service-bookings Right click -> New -> Entity Data Model Rename file.edm to car-service-bookings.edm Open car-service-bookings.edm Brands Drag and drop new entity Name it Brands Rename entityId to Id Drag and drop new property Rename property2 to Name Open the properties of the Brands entity Open the General tab Set the Type to Primary Entity Switch to the User Interface tab Set the Layout Type to Manage Master Entites Models Drag and drop new entity Name it Models Rename entityId to Id Drag and drop new property Rename property2 to Name Add new relation between Models and Brands Rename the relation property in the Models entity to BrandId Open the relation properties Set Name to Brand Set Relationship Type to Composition Set Relationship Cardinality to one-to-many Open the properties of the BrandId property Switch to the User Interface tab Set Is Major to Show in form only Open the properties of the Models entity Open the General tab Set the Type to Dependent Entity Swith to the User Interface tab Set the Layout Tab to Manage Details Entities Cars Drag and drop new entity Name it Cars Rename entityId to Id Drag and drop new property Rename property2 to PlateNumber Add new relation between Cars and Models Rename the relation property in the Cars entity to ModelId Open the properties of the ModelId property Open the Data tab Set the Data Type to INTEGER Switch to the User Interface Set Widget Type to Dropdown Set Label to Model Set Dropdown Key to Id Set Dropdown Value to Name > Note : the dropdown key and value refers respectively to the Models:Id and Models:Name values Generation Save the model Right click on car-service-bookings.model and select Generate Set Template to Full-stack Application (AngularJS) Set Extension to car-service Check Embedded mode Set Title to Car Service Set Brand to Car Service Click Generate Publish the project Extensibility Sample view based extension can be found here Wrap up The whole application can be found here Resources Sample Car Service Bookings: sample-v3-car-service-bookings Sample Data: sample-v3-car-service-bookings-data Sample Extension: sample-v3-car-service-bookings-extension","title":"Generate Application from Model"},{"location":"tutorial/generate-application-from-model/#generate-application-from-model","text":"This tutorial will guide you through the creation of an entity data model and generation of a full-stack Dirigible application, from this model.","title":"Generate Application from Model"},{"location":"tutorial/generate-application-from-model/#prerequisites","text":"Access to the latest version of Eclipse Dirigible (3.2.2+)","title":"Prerequisites"},{"location":"tutorial/generate-application-from-model/#overview","text":"In this tutorial we will create an entity model of a car service bookings and generate full-stack Dirigible application from it. The complete sample can be found here .","title":"Overview"},{"location":"tutorial/generate-application-from-model/#setup-car-service-bookings","text":"Create new project car-service-bookings Right click -> New -> Entity Data Model Rename file.edm to car-service-bookings.edm Open car-service-bookings.edm","title":"Setup Car Service Bookings"},{"location":"tutorial/generate-application-from-model/#brands","text":"Drag and drop new entity Name it Brands Rename entityId to Id Drag and drop new property Rename property2 to Name Open the properties of the Brands entity Open the General tab Set the Type to Primary Entity Switch to the User Interface tab Set the Layout Type to Manage Master Entites","title":"Brands"},{"location":"tutorial/generate-application-from-model/#models","text":"Drag and drop new entity Name it Models Rename entityId to Id Drag and drop new property Rename property2 to Name Add new relation between Models and Brands Rename the relation property in the Models entity to BrandId Open the relation properties Set Name to Brand Set Relationship Type to Composition Set Relationship Cardinality to one-to-many Open the properties of the BrandId property Switch to the User Interface tab Set Is Major to Show in form only Open the properties of the Models entity Open the General tab Set the Type to Dependent Entity Swith to the User Interface tab Set the Layout Tab to Manage Details Entities","title":"Models"},{"location":"tutorial/generate-application-from-model/#cars","text":"Drag and drop new entity Name it Cars Rename entityId to Id Drag and drop new property Rename property2 to PlateNumber Add new relation between Cars and Models Rename the relation property in the Cars entity to ModelId Open the properties of the ModelId property Open the Data tab Set the Data Type to INTEGER Switch to the User Interface Set Widget Type to Dropdown Set Label to Model Set Dropdown Key to Id Set Dropdown Value to Name > Note : the dropdown key and value refers respectively to the Models:Id and Models:Name values","title":"Cars"},{"location":"tutorial/generate-application-from-model/#generation","text":"Save the model Right click on car-service-bookings.model and select Generate Set Template to Full-stack Application (AngularJS) Set Extension to car-service Check Embedded mode Set Title to Car Service Set Brand to Car Service Click Generate Publish the project","title":"Generation"},{"location":"tutorial/generate-application-from-model/#extensibility","text":"Sample view based extension can be found here","title":"Extensibility"},{"location":"tutorial/generate-application-from-model/#wrap-up","text":"The whole application can be found here","title":"Wrap up"},{"location":"tutorial/generate-application-from-model/#resources","text":"Sample Car Service Bookings: sample-v3-car-service-bookings Sample Data: sample-v3-car-service-bookings-data Sample Extension: sample-v3-car-service-bookings-extension","title":"Resources"},{"location":"tutorial/helium-custom-stack/","text":"Helium Custom Stack This tutorial will guide you through the creation of a custom Dirigible stack for production. It also explains how to create a facade of a functionality written in Java and to expose it via API bridge to the application layer - JavaScript. Such a custom stack contains only the core components of Dirigible plus the custom services, user interfaces and descriptor files of your Dirigible application. Prerequisites A Dirigible project containing the data artifacts pushed to a repository e.g. https://github.com/dirigiblelabs/sample-v3-helium-data A Dirigible project with the backend services e.g. https://github.com/dirigiblelabs/sample-v3-helium-javascript A Dirigible project for the user interfaces e.g. https://github.com/dirigiblelabs/sample-v3-helium-html Project Structure Create a packaging project - a standard Maven-based project with a parent dependency modules e.g. https://github.com/dirigiblelabs/sample-v3-helium-custom-stack Create three sub-folders under the root: modules - for the parts which are developed with Dirigible itself core - for the plain Java components and API bridges application - for the packaging project The project structure should look like the example below. Components Dirigible's Module Structure Parent Project The project representing a Dirigible's project in the Maven-based parent project structure usually contains only a single file - the pom.xml itself. The parent pom.xml should look like this: <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> org.sonatype.oss </groupId> <artifactId> oss-parent </artifactId> <version> 7 </version> </parent> <name> Helium - Parent </name> <description> Helium Parent </description> <groupId> io.dirigible.helium </groupId> <artifactId> helium-parent </artifactId> <version> 0.0.2-SNAPSHOT </version> <packaging> pom </packaging> <inceptionYear> 2018 </inceptionYear> <licenses> <license> <name> Eclipse Public License - v 1.0 </name> <url> https://www.eclipse.org/legal/epl-v10.html </url> <distribution> repo </distribution> </license> </licenses> <url> http://www.dirigible.io </url> <organization> <name> Eclipse Foundation </name> <url> http://www.eclipse.org </url> </organization> <scm> <url> https://github.com/eclipse/dirigible </url> </scm> <modules> <module> core </module> <module> modules </module> <module> application </module> </modules> <properties> <dirigible.version> 5.7.0 </dirigible.version> <maven.resource.plugin.version> 3.0.2 </maven.resource.plugin.version> <maven.clean.plugin.version> 3.0.0 </maven.clean.plugin.version> <maven.compiler.plugin.version> 2.3.2 </maven.compiler.plugin.version> <maven.scm.plugin.version> 1.9 </maven.scm.plugin.version> <maven.compiler.source> 11 </maven.compiler.source> <maven.compiler.target> 11 </maven.compiler.target> </properties> </project> The Java compiler version is set to 11 (or above) in our case The version of Eclipse Dirigible is set to 5.7.0 or above Modules Project The main goal is to pull the latest sources from the SCM repository (e.g. GitHub) and to put them under the standard resources folder - src/main/resources A modules pom.xml should look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> io.dirigible.helium </groupId> <artifactId> helium-parent </artifactId> <version> 0.0.2-SNAPSHOT </version> <relativePath> ../pom.xml </relativePath> </parent> <name> Helium - Modules </name> <artifactId> helium-modules </artifactId> <version> 0.0.2-SNAPSHOT </version> <packaging> pom </packaging> <scm> <url> ${content.scm.url} </url> <connection> ${content.scm.connection} </connection> <developerConnection> ${content.scm.developerConnection} </developerConnection> </scm> <modules> <module> data </module> <module> javascript </module> <module> html </module> </modules> <properties> <maven.clean.plugin.version> 3.0.0 </maven.clean.plugin.version> <content.repository.name> dirigiblelabs </content.repository.name> <content.project.name> dirigiblelabs </content.project.name> <content.scm.url> https://github.com/dirigiblelabs/${content.repository.name} </content.scm.url> <content.scm.connection> scm:git:git://github.com/dirigiblelabs/${content.repository.name}.git </content.scm.connection> <content.scm.developerConnection> scm:git:https://github.com/dirigiblelabs/${content.repository.name} </content.scm.developerConnection> <content.scm.server> github </content.scm.server> <content.scm.checkoutDirectory> target </content.scm.checkoutDirectory> <content.source.directory> target/${content.project.name} </content.source.directory> <content.output.directory> ${basedir}/src/main/resources/${content.project.name} </content.output.directory> </properties> <profiles> <profile> <id> content </id> <activation> <activeByDefault> false </activeByDefault> </activation> <build> <finalName> ${project.artifactId} </finalName> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-clean-plugin </artifactId> <version> ${maven.clean.plugin.version} </version> <configuration> <filesets> <fileset> <directory> src/main/resources </directory> </fileset> </filesets> </configuration> </plugin> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-scm-plugin </artifactId> <version> ${maven.scm.plugin.version} </version> <configuration> <goals> checkout </goals> <checkoutDirectory> ${content.scm.checkoutDirectory} </checkoutDirectory> <server> ${content.scm.server} </server> </configuration> <executions> <execution> <id> generated-sources </id> <phase> generate-sources </phase> <goals> <goal> checkout </goal> </goals> </execution> </executions> </plugin> <plugin> <artifactId> maven-resources-plugin </artifactId> <version> ${maven.resource.plugin.version} </version> <executions> <execution> <id> copy-content-resources </id> <phase> compile </phase> <goals> <goal> copy-resources </goal> </goals> <configuration> <outputDirectory> ${content.output.directory} </outputDirectory> <resources> <resource> <directory> ${content.source.directory} </directory> <filtering> true </filtering> </resource> </resources> </configuration> </execution> </executions> </plugin> </plugins> </build> </profile> </profiles> </project> https://github.com/dirigiblelabs/sample-v3-helium-custom-stack/blob/master/helium/modules/data/pom.xml The modules project of all the modules defines the profile content with the maven-scm-plugin Maven plugin. It can be triggered by choosing the content profile as: mvn clean install -Pcontent After synchronizing all the content, you should run the regular build for actual packaging: mvn clean install The other modules in these project next to the data module, contain the backend services in JavaScript and the user interface web content. Java Standard Module with API Bridge The Java code can be integrated nicely into the custom stack not only as a side-car 3-thd party component, but also as a custom functionality exposed to the Dirigible's layer via an API bridge. You can have a look at the sub-project here https://github.com/dirigiblelabs/sample-v3-helium-custom-stack/tree/master/helium/core/java The Java side is a facade class which exposes a given functionality to the above layer: package io.dirigible.helium ; public class HeliumFacade { public static final boolean isInert () { return true ; } } In our case it is over-simplified to just return a boolean flag and no input parameters present. In general, you can use more complex functions described here: https://github.com/eclipse/dirigible/wiki/api-v4-guidelines At the JavaScript side you have an API module, which performs the actual call via the Java bridge: exports . isInert = function () { var output = Packages . io . dirigible . helium . HeliumFacade . isInert (); return output ; }; In this way you can use de-facto arbitrary Java class and method from your favorite framework as JavaScript function in Dirigible's layer. The sample module shows how to use the API bridge afterwards: var helium = require ( \"sample/helium\" ); var isInert = JSON . stringify ( helium . isInert ()); console . info ( isInert ); var response = require ( \"http/v4/response\" ); response . println ( \"Is Helium an inert gas? - \" + isInert ); response . flush (); response . close (); Build and Package Once we have all the artifacts in place, we can run the standard build and package command: mvn clean install Then under the application/target folder we can find the ROOT.war file containing all the modules packaged properly in a standard Java Web Application archive. Deploy Now we can use one of the deploy options to setup our application here . Test Open a browser and go to: http://localhost:8080 or at the host you are using, if not the local one. You should be able to see a table with some of the Helium properties as well as the link to the test service for the API bridge.","title":"Helium Custom Stack"},{"location":"tutorial/helium-custom-stack/#helium-custom-stack","text":"This tutorial will guide you through the creation of a custom Dirigible stack for production. It also explains how to create a facade of a functionality written in Java and to expose it via API bridge to the application layer - JavaScript. Such a custom stack contains only the core components of Dirigible plus the custom services, user interfaces and descriptor files of your Dirigible application.","title":"Helium Custom Stack"},{"location":"tutorial/helium-custom-stack/#prerequisites","text":"A Dirigible project containing the data artifacts pushed to a repository e.g. https://github.com/dirigiblelabs/sample-v3-helium-data A Dirigible project with the backend services e.g. https://github.com/dirigiblelabs/sample-v3-helium-javascript A Dirigible project for the user interfaces e.g. https://github.com/dirigiblelabs/sample-v3-helium-html","title":"Prerequisites"},{"location":"tutorial/helium-custom-stack/#project-structure","text":"Create a packaging project - a standard Maven-based project with a parent dependency modules e.g. https://github.com/dirigiblelabs/sample-v3-helium-custom-stack Create three sub-folders under the root: modules - for the parts which are developed with Dirigible itself core - for the plain Java components and API bridges application - for the packaging project The project structure should look like the example below.","title":"Project Structure"},{"location":"tutorial/helium-custom-stack/#components","text":"","title":"Components"},{"location":"tutorial/helium-custom-stack/#dirigibles-module-structure","text":"","title":"Dirigible's Module Structure"},{"location":"tutorial/helium-custom-stack/#parent-project","text":"The project representing a Dirigible's project in the Maven-based parent project structure usually contains only a single file - the pom.xml itself. The parent pom.xml should look like this: <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> org.sonatype.oss </groupId> <artifactId> oss-parent </artifactId> <version> 7 </version> </parent> <name> Helium - Parent </name> <description> Helium Parent </description> <groupId> io.dirigible.helium </groupId> <artifactId> helium-parent </artifactId> <version> 0.0.2-SNAPSHOT </version> <packaging> pom </packaging> <inceptionYear> 2018 </inceptionYear> <licenses> <license> <name> Eclipse Public License - v 1.0 </name> <url> https://www.eclipse.org/legal/epl-v10.html </url> <distribution> repo </distribution> </license> </licenses> <url> http://www.dirigible.io </url> <organization> <name> Eclipse Foundation </name> <url> http://www.eclipse.org </url> </organization> <scm> <url> https://github.com/eclipse/dirigible </url> </scm> <modules> <module> core </module> <module> modules </module> <module> application </module> </modules> <properties> <dirigible.version> 5.7.0 </dirigible.version> <maven.resource.plugin.version> 3.0.2 </maven.resource.plugin.version> <maven.clean.plugin.version> 3.0.0 </maven.clean.plugin.version> <maven.compiler.plugin.version> 2.3.2 </maven.compiler.plugin.version> <maven.scm.plugin.version> 1.9 </maven.scm.plugin.version> <maven.compiler.source> 11 </maven.compiler.source> <maven.compiler.target> 11 </maven.compiler.target> </properties> </project> The Java compiler version is set to 11 (or above) in our case The version of Eclipse Dirigible is set to 5.7.0 or above","title":"Parent Project"},{"location":"tutorial/helium-custom-stack/#modules-project","text":"The main goal is to pull the latest sources from the SCM repository (e.g. GitHub) and to put them under the standard resources folder - src/main/resources A modules pom.xml should look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> io.dirigible.helium </groupId> <artifactId> helium-parent </artifactId> <version> 0.0.2-SNAPSHOT </version> <relativePath> ../pom.xml </relativePath> </parent> <name> Helium - Modules </name> <artifactId> helium-modules </artifactId> <version> 0.0.2-SNAPSHOT </version> <packaging> pom </packaging> <scm> <url> ${content.scm.url} </url> <connection> ${content.scm.connection} </connection> <developerConnection> ${content.scm.developerConnection} </developerConnection> </scm> <modules> <module> data </module> <module> javascript </module> <module> html </module> </modules> <properties> <maven.clean.plugin.version> 3.0.0 </maven.clean.plugin.version> <content.repository.name> dirigiblelabs </content.repository.name> <content.project.name> dirigiblelabs </content.project.name> <content.scm.url> https://github.com/dirigiblelabs/${content.repository.name} </content.scm.url> <content.scm.connection> scm:git:git://github.com/dirigiblelabs/${content.repository.name}.git </content.scm.connection> <content.scm.developerConnection> scm:git:https://github.com/dirigiblelabs/${content.repository.name} </content.scm.developerConnection> <content.scm.server> github </content.scm.server> <content.scm.checkoutDirectory> target </content.scm.checkoutDirectory> <content.source.directory> target/${content.project.name} </content.source.directory> <content.output.directory> ${basedir}/src/main/resources/${content.project.name} </content.output.directory> </properties> <profiles> <profile> <id> content </id> <activation> <activeByDefault> false </activeByDefault> </activation> <build> <finalName> ${project.artifactId} </finalName> <plugins> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-clean-plugin </artifactId> <version> ${maven.clean.plugin.version} </version> <configuration> <filesets> <fileset> <directory> src/main/resources </directory> </fileset> </filesets> </configuration> </plugin> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-scm-plugin </artifactId> <version> ${maven.scm.plugin.version} </version> <configuration> <goals> checkout </goals> <checkoutDirectory> ${content.scm.checkoutDirectory} </checkoutDirectory> <server> ${content.scm.server} </server> </configuration> <executions> <execution> <id> generated-sources </id> <phase> generate-sources </phase> <goals> <goal> checkout </goal> </goals> </execution> </executions> </plugin> <plugin> <artifactId> maven-resources-plugin </artifactId> <version> ${maven.resource.plugin.version} </version> <executions> <execution> <id> copy-content-resources </id> <phase> compile </phase> <goals> <goal> copy-resources </goal> </goals> <configuration> <outputDirectory> ${content.output.directory} </outputDirectory> <resources> <resource> <directory> ${content.source.directory} </directory> <filtering> true </filtering> </resource> </resources> </configuration> </execution> </executions> </plugin> </plugins> </build> </profile> </profiles> </project> https://github.com/dirigiblelabs/sample-v3-helium-custom-stack/blob/master/helium/modules/data/pom.xml The modules project of all the modules defines the profile content with the maven-scm-plugin Maven plugin. It can be triggered by choosing the content profile as: mvn clean install -Pcontent After synchronizing all the content, you should run the regular build for actual packaging: mvn clean install The other modules in these project next to the data module, contain the backend services in JavaScript and the user interface web content.","title":"Modules Project"},{"location":"tutorial/helium-custom-stack/#java-standard-module-with-api-bridge","text":"The Java code can be integrated nicely into the custom stack not only as a side-car 3-thd party component, but also as a custom functionality exposed to the Dirigible's layer via an API bridge. You can have a look at the sub-project here https://github.com/dirigiblelabs/sample-v3-helium-custom-stack/tree/master/helium/core/java The Java side is a facade class which exposes a given functionality to the above layer: package io.dirigible.helium ; public class HeliumFacade { public static final boolean isInert () { return true ; } } In our case it is over-simplified to just return a boolean flag and no input parameters present. In general, you can use more complex functions described here: https://github.com/eclipse/dirigible/wiki/api-v4-guidelines At the JavaScript side you have an API module, which performs the actual call via the Java bridge: exports . isInert = function () { var output = Packages . io . dirigible . helium . HeliumFacade . isInert (); return output ; }; In this way you can use de-facto arbitrary Java class and method from your favorite framework as JavaScript function in Dirigible's layer. The sample module shows how to use the API bridge afterwards: var helium = require ( \"sample/helium\" ); var isInert = JSON . stringify ( helium . isInert ()); console . info ( isInert ); var response = require ( \"http/v4/response\" ); response . println ( \"Is Helium an inert gas? - \" + isInert ); response . flush (); response . close ();","title":"Java Standard Module with API Bridge"},{"location":"tutorial/helium-custom-stack/#build-and-package","text":"Once we have all the artifacts in place, we can run the standard build and package command: mvn clean install Then under the application/target folder we can find the ROOT.war file containing all the modules packaged properly in a standard Java Web Application archive.","title":"Build and Package"},{"location":"tutorial/helium-custom-stack/#deploy","text":"Now we can use one of the deploy options to setup our application here .","title":"Deploy"},{"location":"tutorial/helium-custom-stack/#test","text":"Open a browser and go to: http://localhost:8080 or at the host you are using, if not the local one. You should be able to see a table with some of the Helium properties as well as the link to the test service for the API bridge.","title":"Test"},{"location":"tutorial/helm-setup/","text":"","title":"Helm"},{"location":"tutorial/kubernetes-setup/","text":"","title":"Setup in Kubernetes"},{"location":"tutorial/kyma-setup/","text":"","title":"Kyma"},{"location":"tutorial/tomcat-setup/","text":"","title":"Setup in Tomcat"},{"location":"tutorial/zeus-on-kubernetes-minikube/","text":"Zeus on Kubernetes These tutorials will guide you through the processes of installation of Kubernetes Minikube, deployment of Zeus and building an image with Docker: Setup on Windows on MacOS Start Minikube To run the local Kubernetes cluster execute the following command: minikube start Deploy and Run the Guestbook sample Follow the steps described in this tutorial - https://kubernetes.io/docs/tutorials/stateless-application/guestbook/ Deploy Zeus Deploy Zeus version 3 on Minikube using kubectl by executing: kubectl create -f https://raw.githubusercontent.com/dirigiblelabs/zeus-v3-package/master/zeus/zeus.yml Get the necessary information for access Get IP: minikube ip or directly: minikube dashboard Get port Execute: kubectl get services -n zeus -o go-template='{{range .items}}{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{\"\\n\"}}{{end}}{{end}}{{end}}' or run minikube dashboard Open Zeus Cockpit From the Kubernetes Dashboard: Change the Namespace to zeus (from the sidebar menu) Select Discovery and Load Balancing (from the sidebar menu) Find the Services section and take the port of the Zeus instance. Copy the second port from the Internal endpoints column (e.g. 31111) Construct URL: {IP}:{Port} and open it in Web browser. Create Account Go to Accounts settings (via the sidebar - last icon) Select Partners view and add a new partner details Select the Accounts view and add a new account details Configure the local Cluster Go to Accounts settings (via the sidebar - last icon) Select Clusters view and add a new cluster details as follows Name: e.g. local URL: https://{IP}:8443 Token: from Minikube Dashboard, go to Config and Storage -> Secrets -> Token Account: select from the drop down Register a Container Go to Templates perspective Select the Containers view Enter the following parameters: Name: Dirigible Image: dirigiblelabs/dirigible-tomcat:latest Protocol: TCP Port: 8080 Create a Template Go to Templates perspective Select the Templates section Create a new Template named Dirigible Select the row representing the just created Template Select the Containers section below Create a new reference to the Container created in the previous step Select the Services section Create a new Service with the following details: Name: http Type: NodePort Port: 8080 Deploy the Application Go to Applications perspective Select the Deploy view Click on New button and enter the following details: Cluster: select from the drop down Template: select from the drop down Name: dirigible Undeploying Zeus If you want to undeploy Zeus, execute the following command: kubectl delete -f https://raw.githubusercontent.com/dirigiblelabs/zeus-v3-package/master/zeus/zeus.yml Stop Minikube To stop Minikube run: minikube stop","title":"Zeus on Kubernetes"},{"location":"tutorial/zeus-on-kubernetes-minikube/#zeus-on-kubernetes","text":"These tutorials will guide you through the processes of installation of Kubernetes Minikube, deployment of Zeus and building an image with Docker:","title":"Zeus on Kubernetes"},{"location":"tutorial/zeus-on-kubernetes-minikube/#setup","text":"on Windows on MacOS","title":"Setup"},{"location":"tutorial/zeus-on-kubernetes-minikube/#start-minikube","text":"To run the local Kubernetes cluster execute the following command: minikube start","title":"Start Minikube"},{"location":"tutorial/zeus-on-kubernetes-minikube/#deploy-and-run-the-guestbook-sample","text":"Follow the steps described in this tutorial - https://kubernetes.io/docs/tutorials/stateless-application/guestbook/","title":"Deploy and Run the Guestbook sample"},{"location":"tutorial/zeus-on-kubernetes-minikube/#deploy-zeus","text":"Deploy Zeus version 3 on Minikube using kubectl by executing: kubectl create -f https://raw.githubusercontent.com/dirigiblelabs/zeus-v3-package/master/zeus/zeus.yml Get the necessary information for access Get IP: minikube ip or directly: minikube dashboard Get port Execute: kubectl get services -n zeus -o go-template='{{range .items}}{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{\"\\n\"}}{{end}}{{end}}{{end}}' or run minikube dashboard","title":"Deploy Zeus"},{"location":"tutorial/zeus-on-kubernetes-minikube/#open-zeus-cockpit","text":"From the Kubernetes Dashboard: Change the Namespace to zeus (from the sidebar menu) Select Discovery and Load Balancing (from the sidebar menu) Find the Services section and take the port of the Zeus instance. Copy the second port from the Internal endpoints column (e.g. 31111) Construct URL: {IP}:{Port} and open it in Web browser.","title":"Open Zeus Cockpit"},{"location":"tutorial/zeus-on-kubernetes-minikube/#create-account","text":"Go to Accounts settings (via the sidebar - last icon) Select Partners view and add a new partner details Select the Accounts view and add a new account details","title":"Create Account"},{"location":"tutorial/zeus-on-kubernetes-minikube/#configure-the-local-cluster","text":"Go to Accounts settings (via the sidebar - last icon) Select Clusters view and add a new cluster details as follows Name: e.g. local URL: https://{IP}:8443 Token: from Minikube Dashboard, go to Config and Storage -> Secrets -> Token Account: select from the drop down","title":"Configure the local Cluster"},{"location":"tutorial/zeus-on-kubernetes-minikube/#register-a-container","text":"Go to Templates perspective Select the Containers view Enter the following parameters: Name: Dirigible Image: dirigiblelabs/dirigible-tomcat:latest Protocol: TCP Port: 8080","title":"Register a Container"},{"location":"tutorial/zeus-on-kubernetes-minikube/#create-a-template","text":"Go to Templates perspective Select the Templates section Create a new Template named Dirigible Select the row representing the just created Template Select the Containers section below Create a new reference to the Container created in the previous step Select the Services section Create a new Service with the following details: Name: http Type: NodePort Port: 8080","title":"Create a Template"},{"location":"tutorial/zeus-on-kubernetes-minikube/#deploy-the-application","text":"Go to Applications perspective Select the Deploy view Click on New button and enter the following details: Cluster: select from the drop down Template: select from the drop down Name: dirigible","title":"Deploy the Application"},{"location":"tutorial/zeus-on-kubernetes-minikube/#undeploying-zeus","text":"If you want to undeploy Zeus, execute the following command: kubectl delete -f https://raw.githubusercontent.com/dirigiblelabs/zeus-v3-package/master/zeus/zeus.yml","title":"Undeploying Zeus"},{"location":"tutorial/zeus-on-kubernetes-minikube/#stop-minikube","text":"To stop Minikube run: minikube stop","title":"Stop Minikube"},{"location":"tutorial/zeus-on-macos/","text":"Zeus on Kubernetes with MacOS Prerequisites Have a Homebrew installed - https://docs.brew.sh/Installation Install Kubernetes command-line tool Run the following command: brew install kubectl To verify that the version you\u2019ve installed is up-to-date, run: kubectl version Install Minikube Install Minikube v0.27.0 curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.27.0/minikube-darwin-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/ Additional Steps with Docker Install Docker Install it using Hombrew: brew cask install docker Open Docker.app and continue the installation of the network (Ctrl+Space) Build the image Build an image without uploading it: Set the environment variables with eval $(minikube docker-env) Clone the Zeus packaging project: git clone https://github.com/dirigiblelabs/zeus-v3-package.git Build the image with the Docker daemon of Minikube: cd zeus-v3-package/zeus mvn clean install docker build -t zeus . Set the image in the pod spec like the build tag: zeus Set the imagePullPolicy to Never , otherwise Kubernetes will try to download the image Important note: You have to run eval $(minikube docker-env) on each terminal you want to use, since it only sets the environment variables for the current shell session.","title":"Zeus on Kubernetes with MacOS"},{"location":"tutorial/zeus-on-macos/#zeus-on-kubernetes-with-macos","text":"","title":"Zeus on Kubernetes with MacOS"},{"location":"tutorial/zeus-on-macos/#prerequisites","text":"Have a Homebrew installed - https://docs.brew.sh/Installation","title":"Prerequisites"},{"location":"tutorial/zeus-on-macos/#install-kubernetes-command-line-tool","text":"Run the following command: brew install kubectl To verify that the version you\u2019ve installed is up-to-date, run: kubectl version","title":"Install Kubernetes command-line tool"},{"location":"tutorial/zeus-on-macos/#install-minikube","text":"Install Minikube v0.27.0 curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.27.0/minikube-darwin-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/","title":"Install Minikube"},{"location":"tutorial/zeus-on-macos/#additional-steps-with-docker","text":"","title":"Additional Steps with Docker"},{"location":"tutorial/zeus-on-macos/#install-docker","text":"Install it using Hombrew: brew cask install docker Open Docker.app and continue the installation of the network (Ctrl+Space)","title":"Install Docker"},{"location":"tutorial/zeus-on-macos/#build-the-image","text":"Build an image without uploading it: Set the environment variables with eval $(minikube docker-env) Clone the Zeus packaging project: git clone https://github.com/dirigiblelabs/zeus-v3-package.git Build the image with the Docker daemon of Minikube: cd zeus-v3-package/zeus mvn clean install docker build -t zeus . Set the image in the pod spec like the build tag: zeus Set the imagePullPolicy to Never , otherwise Kubernetes will try to download the image Important note: You have to run eval $(minikube docker-env) on each terminal you want to use, since it only sets the environment variables for the current shell session.","title":"Build the image"},{"location":"tutorial/zeus-on-windows/","text":"Zeus on Kubernetes with Windows OS This tutorial was performed on a PC running Windows 10 Enterprise OS. Prerequisites Have VirtualBox 5.2.12 platform packages installed .NET Framework 4+ (the installation will attempt to install .NET 4.0 if you do not have it installed) Enabled VT-x or AMD-v virtualization (use the Performance tab for the CPU in the Task Manager to verify it) Install Kubernetes command-line tool Install Chocolatey Run the following command: @\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\" If you don't see any errors, you are ready to use Chocolatey! To ensure that Chocolatey is successfully installed, type choco or choco -? . For more information see https://chocolatey.org/install. Install the Kubernetes command-line tool kubectl with Chocolatey Execute the command: choco install kubernetes-cli To verify that the version you\u2019ve installed is up-to-date, run kubectl version Configure kubectl to use a remote Kubernetes cluster: cd C:\\users\\yourusername (Or wherever your %HOME% directory is) mkdir .kube cd .kube New-Item config -type file Edit the config file with a text editor of your choice. Check that kubectl is properly configured by getting the cluster state: kubectl cluster-info Install Minikube Install Minikube v0.26.1 Download the minikube-installer.exe file, and execute the installer. This will automatically add minikube.exe to your path. Additional Steps Install Docker Run CMD as Administrator Navigate to Chocolatey root folder Execute: choco install docker Confirm with y Build the image Build an image without uploading it: Set the environment variables with @FOR /f \"tokens=*\" %i IN ('minikube docker-env') DO @%i Clone the Zeus packaging project using Git Bash by executing: git clone https://github.com/dirigiblelabs/zeus-v3-package.git Build the image with the Docker daemon of Minikube: cd zeus-v3-package/zeus mvn clean install docker build -t zeus . Set the image in the pod spec like the build tag: zeus Set the imagePullPolicy to Never , otherwise Kubernetes will try to download the image Important note: You have to run eval $(minikube docker-env) on each terminal you want to use, since it only sets the environment variables for the current shell session.","title":"Zeus on Kubernetes with Windows OS"},{"location":"tutorial/zeus-on-windows/#zeus-on-kubernetes-with-windows-os","text":"This tutorial was performed on a PC running Windows 10 Enterprise OS.","title":"Zeus on Kubernetes with Windows OS"},{"location":"tutorial/zeus-on-windows/#prerequisites","text":"Have VirtualBox 5.2.12 platform packages installed .NET Framework 4+ (the installation will attempt to install .NET 4.0 if you do not have it installed) Enabled VT-x or AMD-v virtualization (use the Performance tab for the CPU in the Task Manager to verify it)","title":"Prerequisites"},{"location":"tutorial/zeus-on-windows/#install-kubernetes-command-line-tool","text":"Install Chocolatey Run the following command: @\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\" If you don't see any errors, you are ready to use Chocolatey! To ensure that Chocolatey is successfully installed, type choco or choco -? . For more information see https://chocolatey.org/install. Install the Kubernetes command-line tool kubectl with Chocolatey Execute the command: choco install kubernetes-cli To verify that the version you\u2019ve installed is up-to-date, run kubectl version Configure kubectl to use a remote Kubernetes cluster: cd C:\\users\\yourusername (Or wherever your %HOME% directory is) mkdir .kube cd .kube New-Item config -type file Edit the config file with a text editor of your choice. Check that kubectl is properly configured by getting the cluster state: kubectl cluster-info","title":"Install Kubernetes command-line tool"},{"location":"tutorial/zeus-on-windows/#install-minikube","text":"Install Minikube v0.26.1 Download the minikube-installer.exe file, and execute the installer. This will automatically add minikube.exe to your path.","title":"Install Minikube"},{"location":"tutorial/zeus-on-windows/#additional-steps","text":"","title":"Additional Steps"},{"location":"tutorial/zeus-on-windows/#install-docker","text":"Run CMD as Administrator Navigate to Chocolatey root folder Execute: choco install docker Confirm with y","title":"Install Docker"},{"location":"tutorial/zeus-on-windows/#build-the-image","text":"Build an image without uploading it: Set the environment variables with @FOR /f \"tokens=*\" %i IN ('minikube docker-env') DO @%i Clone the Zeus packaging project using Git Bash by executing: git clone https://github.com/dirigiblelabs/zeus-v3-package.git Build the image with the Docker daemon of Minikube: cd zeus-v3-package/zeus mvn clean install docker build -t zeus . Set the image in the pod spec like the build tag: zeus Set the imagePullPolicy to Never , otherwise Kubernetes will try to download the image Important note: You have to run eval $(minikube docker-env) on each terminal you want to use, since it only sets the environment variables for the current shell session.","title":"Build the image"}]}